{"ast":null,"code":"import _asyncToGenerator from \"F:/statvalu/project/AR_DocuExpert_Test/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\n// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\nimport { isNode } from \"@azure/core-http\";\nimport { BlobClient, BlockBlobClient } from \"@azure/storage-blob\";\nimport { SpanStatusCode } from \"@azure/core-tracing\";\nimport { BufferScheduler } from \"../../storage-common/src\";\nimport { AnonymousCredential } from \"./credentials/AnonymousCredential\";\nimport { StorageSharedKeyCredential } from \"./credentials/StorageSharedKeyCredential\";\nimport { DataLakeLeaseClient } from \"./DataLakeLeaseClient\";\nimport { Path } from \"./generated/src/operations\";\nimport { newPipeline, Pipeline } from \"./Pipeline\";\nimport { generateDataLakeSASQueryParameters } from \"./sas/DataLakeSASSignatureValues\";\nimport { StorageClient } from \"./StorageClient\";\nimport { toAccessControlChangeFailureArray, toAclString, toPathGetAccessControlResponse, toPermissionsString, toProperties } from \"./transforms\";\nimport { Batch } from \"./utils/Batch\";\nimport { BLOCK_BLOB_MAX_BLOCKS, DEFAULT_HIGH_LEVEL_CONCURRENCY, ETagAny, FILE_MAX_SINGLE_UPLOAD_THRESHOLD, FILE_MAX_SIZE_BYTES, FILE_UPLOAD_DEFAULT_CHUNK_SIZE, FILE_UPLOAD_MAX_CHUNK_SIZE } from \"./utils/constants\";\nimport { DataLakeAclChangeFailedError } from \"./utils/DataLakeAclChangeFailedError\";\nimport { convertTracingToRequestOptionsBase, createSpan } from \"./utils/tracing\";\nimport { appendToURLPath, appendToURLQuery, getURLPathAndQuery, setURLPath, setURLQueries } from \"./utils/utils.common\";\nimport { fsCreateReadStream, fsStat } from \"./utils/utils.node\";\n/**\n * A DataLakePathClient represents a URL to the Azure Storage path (directory or file).\n */\n\nexport class DataLakePathClient extends StorageClient {\n  constructor(url, credentialOrPipeline, // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.\n\n  /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options */\n  options) {\n    if (credentialOrPipeline instanceof Pipeline) {\n      super(url, credentialOrPipeline);\n    } else {\n      let credential;\n\n      if (credentialOrPipeline === undefined) {\n        credential = new AnonymousCredential();\n      } else {\n        credential = credentialOrPipeline;\n      }\n\n      const pipeline = newPipeline(credential, options);\n      super(url, pipeline);\n    }\n\n    this.pathContext = new Path(this.storageClientContext);\n    this.blobClient = new BlobClient(this.blobEndpointUrl, this.pipeline);\n  }\n  /**\n   * SetAccessControlRecursiveInternal operation sets the Access Control on a path and sub paths.\n   *\n   * @param mode - Mode \\\"set\\\" sets POSIX access control rights on files and directories,\n   *                                                 Mode \\\"modify\\\" modifies one or more POSIX access control rights that pre-exist on files and directories,\n   *                                                 Mode \\\"remove\\\" removes one or more POSIX access control rights that were present earlier on files and directories.\n   * @param acl - The POSIX access control list for the file or directory.\n   * @param options - Optional. Options\n   */\n\n\n  setAccessControlRecursiveInternal(mode, acl, options = {}) {\n    var _this = this;\n\n    return _asyncToGenerator(function* () {\n      if (options.maxBatches !== undefined && options.maxBatches < 1) {\n        throw RangeError(`Options maxBatches must be larger than 0.`);\n      }\n\n      if (options.batchSize !== undefined && options.batchSize < 1) {\n        throw RangeError(`Options batchSize must be larger than 0.`);\n      }\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(`DataLakePathClient-setAccessControlRecursiveInternal`, options);\n      const result = {\n        counters: {\n          failedChangesCount: 0,\n          changedDirectoriesCount: 0,\n          changedFilesCount: 0\n        },\n        continuationToken: undefined\n      };\n\n      try {\n        let continuationToken = options.continuationToken;\n        let batchCounter = 0;\n        let reachMaxBatches = false;\n\n        do {\n          let response;\n\n          try {\n            response = yield _this.pathContext.setAccessControlRecursive(mode, Object.assign(Object.assign(Object.assign({}, options), {\n              acl: toAclString(acl),\n              maxRecords: options.batchSize,\n              continuation: continuationToken,\n              forceFlag: options.continueOnFailure\n            }), convertTracingToRequestOptionsBase(updatedOptions)));\n          } catch (e) {\n            throw new DataLakeAclChangeFailedError(e, continuationToken);\n          }\n\n          batchCounter++;\n          continuationToken = response.continuation; // Update result\n\n          result.continuationToken = continuationToken;\n          result.counters.failedChangesCount += response.failureCount || 0;\n          result.counters.changedDirectoriesCount += response.directoriesSuccessful || 0;\n          result.counters.changedFilesCount += response.filesSuccessful || 0; // Progress event call back\n\n          if (options.onProgress) {\n            const progress = {\n              batchFailures: toAccessControlChangeFailureArray(response.failedEntries),\n              batchCounters: {\n                failedChangesCount: response.failureCount || 0,\n                changedDirectoriesCount: response.directoriesSuccessful || 0,\n                changedFilesCount: response.filesSuccessful || 0\n              },\n              aggregateCounters: result.counters,\n              continuationToken: continuationToken\n            };\n            options.onProgress(progress);\n          }\n\n          reachMaxBatches = options.maxBatches === undefined ? false : batchCounter >= options.maxBatches;\n        } while (continuationToken && !reachMaxBatches);\n\n        return result;\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Name of current file system.\n   *\n   * @readonly\n   */\n\n\n  get fileSystemName() {\n    return this.blobClient.containerName;\n  }\n  /**\n   * Name of current path (directory or file).\n   *\n   * @readonly\n   */\n\n\n  get name() {\n    return this.blobClient.name;\n  }\n  /**\n   * Convert current DataLakePathClient to DataLakeDirectoryClient if current path is a directory.\n   *\n   */\n  // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.\n\n  /* eslint-disable-next-line @azure/azure-sdk/ts-naming-subclients */\n\n\n  toDirectoryClient() {\n    return new DataLakeDirectoryClient(this.dfsEndpointUrl, this.pipeline);\n  }\n  /**\n   * Convert current DataLakePathClient to DataLakeFileClient if current path is a file.\n   *\n   */\n  // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.\n\n  /* eslint-disable-next-line @azure/azure-sdk/ts-naming-subclients */\n\n\n  toFileClient() {\n    return new DataLakeFileClient(this.dfsEndpointUrl, this.pipeline);\n  }\n  /**\n   * Get a {@link DataLakeLeaseClient} that manages leases on the path (directory or file).\n   *\n   * @param proposeLeaseId - Optional. Initial proposed lease Id.\n   */\n\n\n  getDataLakeLeaseClient(proposeLeaseId) {\n    return new DataLakeLeaseClient(this.blobClient.getBlobLeaseClient(proposeLeaseId));\n  }\n  /**\n   * Create a directory or path.\n   *\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create\n   *\n   * @param resourceType - Resource type, \"directory\" or \"file\".\n   * @param options - Optional. Options when creating path.\n   */\n\n\n  create(resourceType, options = {}) {\n    var _this2 = this;\n\n    return _asyncToGenerator(function* () {\n      options.conditions = options.conditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakePathClient-create\", options);\n\n      try {\n        return yield _this2.pathContext.create(Object.assign(Object.assign(Object.assign({}, options), {\n          resource: resourceType,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: options.conditions,\n          properties: toProperties(options.metadata)\n        }), convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Create a directory or file. If the resource already exists, it is not changed.\n   *\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create\n   *\n   * @param resourceType - Resource type, \"directory\" or \"file\".\n   * @param options -\n   */\n\n\n  createIfNotExists(resourceType, options = {}) {\n    var _this3 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a, _b;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakePathClient-createIfNotExists\", options);\n\n      try {\n        const conditions = {\n          ifNoneMatch: ETagAny\n        };\n        const res = yield _this3.create(resourceType, Object.assign(Object.assign({}, options), {\n          conditions,\n          tracingOptions: updatedOptions.tracingOptions\n        }));\n        return Object.assign({\n          succeeded: true\n        }, res);\n      } catch (e) {\n        if (((_a = e.details) === null || _a === void 0 ? void 0 : _a.errorCode) === \"PathAlreadyExists\") {\n          span.setStatus({\n            code: SpanStatusCode.ERROR,\n            message: \"Expected exception when creating a blob only if it does not already exist.\"\n          });\n          return Object.assign(Object.assign({\n            succeeded: false\n          }, (_b = e.response) === null || _b === void 0 ? void 0 : _b.parsedHeaders), {\n            _response: e.response\n          });\n        }\n\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Returns true if the Data Lake file represented by this client exists; false otherwise.\n   *\n   * NOTE: use this function with care since an existing file might be deleted by other clients or\n   * applications. Vice versa new files might be added by other clients or applications after this\n   * function completes.\n   *\n   * @param options - options to Exists operation.\n   */\n\n\n  exists(options = {}) {\n    var _this4 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakeFileClient-exists\", options);\n\n      try {\n        return yield _this4.blobClient.exists(updatedOptions);\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Delete current path (directory or file).\n   *\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete\n   *\n   * @param recursive - Required and valid only when the resource is a directory. If \"true\", all paths beneath the directory will be deleted.\n   * @param options - Optional. Options when deleting path.\n   */\n\n\n  delete(recursive, options = {}) {\n    var _this5 = this;\n\n    return _asyncToGenerator(function* () {\n      options.conditions = options.conditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakePathClient-delete\", options);\n\n      try {\n        let continuation;\n        let response; // How to handle long delete loop?\n\n        do {\n          response = yield _this5.pathContext.delete(Object.assign(Object.assign({\n            continuation,\n            recursive,\n            leaseAccessConditions: options.conditions,\n            modifiedAccessConditions: options.conditions\n          }, convertTracingToRequestOptionsBase(updatedOptions)), {\n            abortSignal: options.abortSignal\n          }));\n          continuation = response.continuation;\n        } while (continuation !== undefined && continuation !== \"\");\n\n        return response;\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Delete current path (directory or file) if it exists.\n   *\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete\n   *\n   * @param recursive - Required and valid only when the resource is a directory. If \"true\", all paths beneath the directory will be deleted.\n   * @param options -\n   */\n\n\n  deleteIfExists(recursive, options = {}) {\n    var _this6 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a, _b;\n\n      options.conditions = options.conditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakePathClient-deleteIfExists\", options);\n\n      try {\n        const res = yield _this6.delete(recursive, updatedOptions);\n        return Object.assign({\n          succeeded: true\n        }, res);\n      } catch (e) {\n        if (((_a = e.details) === null || _a === void 0 ? void 0 : _a.errorCode) === \"PathNotFound\") {\n          span.setStatus({\n            code: SpanStatusCode.ERROR,\n            message: \"Expected exception when deleting a directory or file only if it exists.\"\n          });\n          return Object.assign(Object.assign({\n            succeeded: false\n          }, (_b = e.response) === null || _b === void 0 ? void 0 : _b.parsedHeaders), {\n            _response: e.response\n          });\n        }\n\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Returns the access control data for a path (directory of file).\n   *\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/getproperties\n   *\n   * @param options - Optional. Options when getting file access control.\n   */\n\n\n  getAccessControl(options = {}) {\n    var _this7 = this;\n\n    return _asyncToGenerator(function* () {\n      options.conditions = options.conditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakePathClient-getAccessControl\", options);\n\n      try {\n        const response = yield _this7.pathContext.getProperties(Object.assign(Object.assign({\n          action: \"getAccessControl\",\n          upn: options.userPrincipalName,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: options.conditions\n        }, convertTracingToRequestOptionsBase(updatedOptions)), {\n          abortSignal: options.abortSignal\n        }));\n        return toPathGetAccessControlResponse(response);\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Set the access control data for a path (directory of file).\n   *\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update\n   *\n   * @param acl - The POSIX access control list for the file or directory.\n   * @param options - Optional. Options when setting path access control.\n   */\n\n\n  setAccessControl(acl, options = {}) {\n    var _this8 = this;\n\n    return _asyncToGenerator(function* () {\n      options.conditions = options.conditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakePathClient-setAccessControl\", options);\n\n      try {\n        return yield _this8.pathContext.setAccessControl(Object.assign(Object.assign(Object.assign({}, options), {\n          acl: toAclString(acl),\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: options.conditions\n        }), convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Sets the Access Control on a path and sub paths.\n   *\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update\n   *\n   * @param acl - The POSIX access control list for the file or directory.\n   * @param options - Optional. Options\n   */\n\n\n  setAccessControlRecursive(acl, options = {}) {\n    var _this9 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakePathClient-setAccessControlRecursive\", options);\n\n      try {\n        return _this9.setAccessControlRecursiveInternal(\"set\", acl, updatedOptions);\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Modifies the Access Control on a path and sub paths.\n   *\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update\n   *\n   * @param acl - The POSIX access control list for the file or directory.\n   * @param options - Optional. Options\n   */\n\n\n  updateAccessControlRecursive(acl, options = {}) {\n    var _this10 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakePathClient-updateAccessControlRecursive\", options);\n\n      try {\n        return _this10.setAccessControlRecursiveInternal(\"modify\", acl, updatedOptions);\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Removes the Access Control on a path and sub paths.\n   *\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update\n   *\n   * @param acl - The POSIX access control list for the file or directory.\n   * @param options - Optional. Options\n   */\n\n\n  removeAccessControlRecursive(acl, options = {}) {\n    var _this11 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakePathClient-removeAccessControlRecursive\", options);\n\n      try {\n        return _this11.setAccessControlRecursiveInternal(\"remove\", acl, updatedOptions);\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Sets the file permissions on a path.\n   *\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update\n   *\n   * @param permissions - The POSIX access permissions for the file owner, the file owning group, and others.\n   * @param options - Optional. Options when setting path permissions.\n   */\n\n\n  setPermissions(permissions, options = {}) {\n    var _this12 = this;\n\n    return _asyncToGenerator(function* () {\n      options.conditions = options.conditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakePathClient-setPermissions\", options);\n\n      try {\n        return yield _this12.pathContext.setAccessControl(Object.assign(Object.assign(Object.assign({}, options), {\n          permissions: toPermissionsString(permissions),\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: options.conditions\n        }), convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Returns all user-defined metadata, standard HTTP properties, and system properties\n   * for the path (directory or file).\n   *\n   * WARNING: The `metadata` object returned in the response will have its keys in lowercase, even if\n   * they originally contained uppercase characters. This differs from the metadata keys returned by\n   * the methods of {@link DataLakeFileSystemClient} that list paths using the `includeMetadata` option, which\n   * will retain their original casing.\n   *\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob-properties\n   *\n   * @param options - Optional. Options when getting path properties.\n   */\n\n\n  getProperties(options = {}) {\n    var _this13 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakePathClient-getProperties\", options);\n\n      try {\n        return yield _this13.blobClient.getProperties(Object.assign(Object.assign({}, options), {\n          customerProvidedKey: undefined,\n          tracingOptions: updatedOptions.tracingOptions\n        }));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Sets system properties on the path (directory or file).\n   *\n   * If no value provided, or no value provided for the specified blob HTTP headers,\n   * these blob HTTP headers without a value will be cleared.\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-blob-properties\n   *\n   * @param httpHeaders -\n   * @param options -\n   */\n\n\n  setHttpHeaders(httpHeaders, options = {}) {\n    var _this14 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakePathClient-setHttpHeaders\", options);\n\n      try {\n        return yield _this14.blobClient.setHTTPHeaders({\n          blobCacheControl: httpHeaders.cacheControl,\n          blobContentType: httpHeaders.contentType,\n          blobContentMD5: httpHeaders.contentMD5,\n          blobContentEncoding: httpHeaders.contentEncoding,\n          blobContentLanguage: httpHeaders.contentLanguage,\n          blobContentDisposition: httpHeaders.contentDisposition\n        }, updatedOptions);\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Sets user-defined metadata for the specified path (directory of file) as one or more name-value pairs.\n   *\n   * If no option provided, or no metadata defined in the parameter, the path\n   * metadata will be removed.\n   *\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-blob-metadata\n   *\n   * @param metadata - Optional. Replace existing metadata with this value.\n   *                              If no value provided the existing metadata will be removed.\n   * @param options - Optional. Options when setting path metadata.\n   */\n\n\n  setMetadata(metadata, options = {}) {\n    var _this15 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakePathClient-setMetadata\", options);\n\n      try {\n        return yield _this15.blobClient.setMetadata(metadata, Object.assign(Object.assign({}, options), {\n          customerProvidedKey: undefined,\n          tracingOptions: updatedOptions.tracingOptions\n        }));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n\n  move(destinationPathOrFileSystem, destinationPathOrOptions, options) {\n    var _this16 = this;\n\n    return _asyncToGenerator(function* () {\n      let destinationFileSystem = _this16.fileSystemName;\n      let destinationPath = destinationPathOrFileSystem;\n\n      if (typeof destinationPathOrOptions === \"string\") {\n        destinationFileSystem = destinationPathOrFileSystem;\n        destinationPath = destinationPathOrOptions;\n        options = options || {};\n      } else {\n        options = destinationPathOrOptions || {};\n      }\n\n      options.conditions = options.conditions || {};\n      options.destinationConditions = options.destinationConditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakePathClient-move\", options);\n      const renameSource = getURLPathAndQuery(_this16.dfsEndpointUrl);\n      const split = destinationPath.split(\"?\");\n      let destinationUrl;\n\n      if (split.length === 2) {\n        const renameDestination = `/${destinationFileSystem}/${split[0]}`;\n        destinationUrl = setURLPath(_this16.dfsEndpointUrl, renameDestination);\n        destinationUrl = setURLQueries(destinationUrl, split[1]);\n      } else if (split.length === 1) {\n        const renameDestination = `/${destinationFileSystem}/${destinationPath}`;\n        destinationUrl = setURLPath(_this16.dfsEndpointUrl, renameDestination);\n      } else {\n        throw new RangeError(\"Destination path should not contain more than one query string\");\n      }\n\n      const destPathClient = new DataLakePathClient(destinationUrl, _this16.pipeline);\n\n      try {\n        return yield destPathClient.pathContext.create(Object.assign(Object.assign({\n          mode: \"legacy\",\n          // By default\n          renameSource,\n          sourceLeaseId: options.conditions.leaseId,\n          leaseAccessConditions: options.destinationConditions,\n          sourceModifiedAccessConditions: {\n            sourceIfMatch: options.conditions.ifMatch,\n            sourceIfNoneMatch: options.conditions.ifNoneMatch,\n            sourceIfModifiedSince: options.conditions.ifModifiedSince,\n            sourceIfUnmodifiedSince: options.conditions.ifUnmodifiedSince\n          },\n          modifiedAccessConditions: options.destinationConditions\n        }, convertTracingToRequestOptionsBase(updatedOptions)), {\n          abortSignal: options.abortSignal\n        }));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n\n}\n/**\n * A DataLakeDirectoryClient represents a URL to the Azure Storage directory.\n */\n\nexport class DataLakeDirectoryClient extends DataLakePathClient {\n  create(resourceTypeOrOptions, options = {}) {\n    var _superprop_getCreate = () => super.create,\n        _this17 = this;\n\n    return _asyncToGenerator(function* () {\n      if (resourceTypeOrOptions === \"directory\") {\n        return _superprop_getCreate().call(_this17, resourceTypeOrOptions, options);\n      }\n\n      if (resourceTypeOrOptions === \"file\") {\n        throw TypeError(`DataLakeDirectoryClient:create() resourceType cannot be ${resourceTypeOrOptions}. Refer to DataLakeFileClient for file creation.`);\n      }\n\n      options = resourceTypeOrOptions || {};\n      options.conditions = options.conditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakeDirectoryClient-create\", options);\n\n      try {\n        return yield _superprop_getCreate().call(_this17, \"directory\", Object.assign(Object.assign({}, options), {\n          tracingOptions: Object.assign(Object.assign({}, options.tracingOptions), convertTracingToRequestOptionsBase(updatedOptions))\n        }));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n\n  createIfNotExists(resourceTypeOrOptions, options = {}) {\n    var _superprop_getCreateIfNotExists = () => super.createIfNotExists,\n        _this18 = this;\n\n    return _asyncToGenerator(function* () {\n      if (resourceTypeOrOptions === \"file\") {\n        throw TypeError(`DataLakeDirectoryClient:createIfNotExists() resourceType cannot be ${resourceTypeOrOptions}. Refer to DataLakeFileClient for file creation.`);\n      }\n\n      if (resourceTypeOrOptions !== \"directory\") {\n        options = resourceTypeOrOptions || {};\n      }\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakeDirectoryClient-createIfNotExists\", options);\n\n      try {\n        return yield _superprop_getCreateIfNotExists().call(_this18, \"directory\", Object.assign(Object.assign({}, options), {\n          tracingOptions: Object.assign(Object.assign({}, options.tracingOptions), convertTracingToRequestOptionsBase(updatedOptions))\n        }));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Creates a {@link DataLakeDirectoryClient} object under current directory.\n   *\n   * @param subdirectoryName - Subdirectory name.\n   */\n\n\n  getSubdirectoryClient(subdirectoryName) {\n    return new DataLakeDirectoryClient(appendToURLPath(this.url, encodeURIComponent(subdirectoryName)), this.pipeline);\n  }\n  /**\n   * Creates a {@link DataLakeFileClient} object under current directory.\n   *\n   * @param fileName -\n   */\n  // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.\n\n  /* eslint-disable-next-line @azure/azure-sdk/ts-naming-subclients */\n\n\n  getFileClient(fileName) {\n    return new DataLakeFileClient(appendToURLPath(this.url, encodeURIComponent(fileName)), this.pipeline);\n  }\n  /**\n   * Only available for clients constructed with a shared key credential.\n   *\n   * Generates a Service Shared Access Signature (SAS) URI based on the client properties\n   * and parameters passed in. The SAS is signed by the shared key credential of the client.\n   *\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas\n   *\n   * @param options - Optional parameters.\n   * @returns The SAS URI consisting of the URI to the resource represented by this client, followed by the generated SAS token.\n   */\n\n\n  generateSasUrl(options) {\n    return new Promise(resolve => {\n      if (!(this.credential instanceof StorageSharedKeyCredential)) {\n        throw RangeError(\"Can only generate the SAS when the client is initialized with a shared key credential\");\n      }\n\n      const sas = generateDataLakeSASQueryParameters(Object.assign({\n        fileSystemName: this.fileSystemName,\n        pathName: this.name,\n        isDirectory: true\n      }, options), this.credential).toString();\n      resolve(appendToURLQuery(this.url, sas));\n    });\n  }\n\n}\n/**\n * A DataLakeFileClient represents a URL to the Azure Storage file.\n */\n\nexport class DataLakeFileClient extends DataLakePathClient {\n  constructor(url, credentialOrPipeline, // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.\n\n  /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options */\n  options) {\n    if (credentialOrPipeline instanceof Pipeline) {\n      super(url, credentialOrPipeline);\n    } else {\n      let credential;\n\n      if (credentialOrPipeline === undefined) {\n        credential = new AnonymousCredential();\n      } else {\n        credential = credentialOrPipeline;\n      }\n\n      const pipeline = newPipeline(credential, options);\n      super(url, pipeline);\n    }\n\n    this.pathContextInternal = new Path(this.storageClientContext);\n    this.blockBlobClientInternal = new BlockBlobClient(this.blobEndpointUrl, this.pipeline);\n    this.pathContextInternalToBlobEndpoint = new Path(this.storageClientContextToBlobEndpoint);\n  }\n\n  create(resourceTypeOrOptions, options = {}) {\n    var _superprop_getCreate2 = () => super.create,\n        _this19 = this;\n\n    return _asyncToGenerator(function* () {\n      if (resourceTypeOrOptions === \"file\") {\n        return _superprop_getCreate2().call(_this19, resourceTypeOrOptions, options);\n      }\n\n      if (resourceTypeOrOptions === \"directory\") {\n        throw TypeError(`DataLakeFileClient:create() resourceType cannot be ${resourceTypeOrOptions}. Refer to DataLakeDirectoryClient for directory creation.`);\n      }\n\n      options = resourceTypeOrOptions || {};\n      options.conditions = options.conditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakeFileClient-create\", options);\n\n      try {\n        return yield _superprop_getCreate2().call(_this19, \"file\", Object.assign(Object.assign({}, options), {\n          tracingOptions: Object.assign(Object.assign({}, options.tracingOptions), convertTracingToRequestOptionsBase(updatedOptions))\n        }));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n\n  createIfNotExists(resourceTypeOrOptions, options = {}) {\n    var _superprop_getCreateIfNotExists2 = () => super.createIfNotExists,\n        _this20 = this;\n\n    return _asyncToGenerator(function* () {\n      if (resourceTypeOrOptions === \"directory\") {\n        throw TypeError(`DataLakeFileClient:createIfNotExists() resourceType cannot be ${resourceTypeOrOptions}. Refer to DataLakeDirectoryClient for directory creation.`);\n      }\n\n      if (resourceTypeOrOptions !== \"file\") {\n        options = resourceTypeOrOptions || {};\n      }\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakeFileClient-createIfNotExists\", options);\n\n      try {\n        return yield _superprop_getCreateIfNotExists2().call(_this20, \"file\", Object.assign(Object.assign({}, options), {\n          tracingOptions: Object.assign(Object.assign({}, options.tracingOptions), convertTracingToRequestOptionsBase(updatedOptions))\n        }));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Downloads a file from the service, including its metadata and properties.\n   *\n   * * In Node.js, data returns in a Readable stream readableStreamBody\n   * * In browsers, data returns in a promise contentAsBlob\n   *\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob\n   *\n   * * Example usage (Node.js):\n   *\n   * ```js\n   * // Download and convert a file to a string\n   * const downloadResponse = await fileClient.read();\n   * const downloaded = await streamToBuffer(downloadResponse.readableStreamBody);\n   * console.log(\"Downloaded file content:\", downloaded.toString());\n   *\n   * async function streamToBuffer(readableStream) {\n   *   return new Promise((resolve, reject) => {\n   *     const chunks = [];\n   *     readableStream.on(\"data\", (data) => {\n   *       chunks.push(data instanceof Buffer ? data : Buffer.from(data));\n   *     });\n   *     readableStream.on(\"end\", () => {\n   *       resolve(Buffer.concat(chunks));\n   *     });\n   *     readableStream.on(\"error\", reject);\n   *   });\n   * }\n   * ```\n   *\n   * Example usage (browser):\n   *\n   * ```js\n   * // Download and convert a file to a string\n   * const downloadResponse = await fileClient.read();\n   * const downloaded = await blobToString(await downloadResponse.contentAsBlob);\n   * console.log(\"Downloaded file content\", downloaded);\n   *\n   * async function blobToString(blob: Blob): Promise<string> {\n   *   const fileReader = new FileReader();\n   *   return new Promise<string>((resolve, reject) => {\n   *     fileReader.onloadend = (ev: any) => {\n   *       resolve(ev.target!.result);\n   *     };\n   *     fileReader.onerror = reject;\n   *     fileReader.readAsText(blob);\n   *   });\n   * }\n   * ```\n   *\n   * @param offset - Optional. Offset to read file, default value is 0.\n   * @param count - Optional. How many bytes to read, default will read from offset to the end.\n   * @param options - Optional. Options when reading file.\n   */\n\n\n  read(offset = 0, count, options = {}) {\n    var _this21 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakeFileClient-read\", options);\n\n      try {\n        const rawResponse = yield _this21.blockBlobClientInternal.download(offset, count, updatedOptions);\n        const response = rawResponse;\n\n        if (!isNode && !response.contentAsBlob) {\n          response.contentAsBlob = rawResponse.blobBody;\n        }\n\n        response.fileContentMD5 = rawResponse.blobContentMD5;\n        response._response.parsedHeaders.fileContentMD5 = rawResponse._response.parsedHeaders.blobContentMD5;\n        delete rawResponse.blobContentMD5;\n        delete rawResponse._response.parsedHeaders.blobContentMD5;\n        return response;\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Uploads data to be appended to a file. Data can only be appended to a file.\n   * To apply perviously uploaded data to a file, call flush.\n   *\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update\n   *\n   * @param body - Content to be uploaded.\n   * @param offset - Append offset in bytes.\n   * @param length - Length of content to append in bytes.\n   * @param options - Optional. Options when appending data.\n   */\n\n\n  append(body, offset, length, options = {}) {\n    var _this22 = this;\n\n    return _asyncToGenerator(function* () {\n      options.conditions = options.conditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakeFileClient-append\", options);\n\n      try {\n        return yield _this22.pathContextInternal.appendData(body, Object.assign({\n          pathHttpHeaders: {\n            contentMD5: options.transactionalContentMD5\n          },\n          abortSignal: options.abortSignal,\n          position: offset,\n          contentLength: length,\n          leaseAccessConditions: options.conditions,\n          requestOptions: {\n            onUploadProgress: options.onProgress\n          }\n        }, convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Flushes (writes) previously appended data to a file.\n   *\n   * @param position - File position to flush.\n   *                          This parameter allows the caller to upload data in parallel and control the order in which it is appended to the file.\n   *                          It is required when uploading data to be appended to the file and when flushing previously uploaded data to the file.\n   *                          The value must be the position where the data is to be appended. Uploaded data is not immediately flushed, or written,\n   *                          to the file. To flush, the previously uploaded data must be contiguous, the position parameter must be specified and\n   *                          equal to the length of the file after all data has been written, and there must not be a request entity body included\n   *                          with the request.\n   * @param options - Optional. Options when flushing data.\n   */\n\n\n  flush(position, options = {}) {\n    var _this23 = this;\n\n    return _asyncToGenerator(function* () {\n      options.conditions = options.conditions || {};\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakeFileClient-flush\", options);\n\n      try {\n        return yield _this23.pathContextInternal.flushData(Object.assign(Object.assign(Object.assign({}, options), {\n          position,\n          contentLength: 0,\n          leaseAccessConditions: options.conditions,\n          modifiedAccessConditions: options.conditions\n        }), convertTracingToRequestOptionsBase(updatedOptions)));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  } // high level functions\n\n  /**\n   * ONLY AVAILABLE IN NODE.JS RUNTIME.\n   *\n   * Uploads a local file to a Data Lake file.\n   *\n   * @param filePath - Full path of the local file\n   * @param options -\n   */\n\n\n  uploadFile(filePath, // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.\n\n  /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options */\n  options = {}) {\n    var _this24 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakeFileClient-uploadFile\", options);\n\n      try {\n        const size = (yield fsStat(filePath)).size;\n        return yield _this24.uploadSeekableInternal((offset, contentSize) => {\n          return () => fsCreateReadStream(filePath, {\n            autoClose: true,\n            end: offset + contentSize - 1,\n            start: offset\n          });\n        }, size, updatedOptions);\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Uploads a Buffer(Node.js)/Blob/ArrayBuffer/ArrayBufferView to a File.\n   *\n   * @param data - Buffer(Node), Blob, ArrayBuffer or ArrayBufferView\n   * @param options -\n   */\n\n\n  upload(data, options = {}) {\n    var _this25 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakeFileClient-upload\", options);\n\n      try {\n        if (isNode) {\n          let buffer;\n\n          if (data instanceof Buffer) {\n            buffer = data;\n          } else if (data instanceof ArrayBuffer) {\n            buffer = Buffer.from(data);\n          } else {\n            data = data;\n            buffer = Buffer.from(data.buffer, data.byteOffset, data.byteLength);\n          }\n\n          return _this25.uploadSeekableInternal((offset, size) => buffer.slice(offset, offset + size), buffer.length, updatedOptions);\n        } else {\n          const browserBlob = new Blob([data]);\n          return _this25.uploadSeekableInternal((offset, size) => browserBlob.slice(offset, offset + size), browserBlob.size, updatedOptions);\n        }\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n\n  uploadSeekableInternal(bodyFactory, size, options = {}) {\n    var _this26 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakeFileClient-uploadData\", options);\n\n      try {\n        if (size > FILE_MAX_SIZE_BYTES) {\n          throw new RangeError(`size must be <= ${FILE_MAX_SIZE_BYTES}.`);\n        } // Create the file.\n\n\n        const createRes = _this26.create({\n          abortSignal: options.abortSignal,\n          metadata: options.metadata,\n          permissions: options.permissions,\n          umask: options.umask,\n          conditions: options.conditions,\n          pathHttpHeaders: options.pathHttpHeaders,\n          tracingOptions: updatedOptions.tracingOptions\n        }); // append() with empty data would return error, so do not continue\n\n\n        if (size === 0) {\n          return yield createRes;\n        } else {\n          yield createRes;\n        } // After the File is Create, Lease ID is the only valid request parameter.\n\n\n        options.conditions = {\n          leaseId: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.leaseId\n        };\n\n        if (!options.chunkSize) {\n          options.chunkSize = Math.ceil(size / BLOCK_BLOB_MAX_BLOCKS);\n\n          if (options.chunkSize < FILE_UPLOAD_DEFAULT_CHUNK_SIZE) {\n            options.chunkSize = FILE_UPLOAD_DEFAULT_CHUNK_SIZE;\n          }\n        }\n\n        if (options.chunkSize < 1 || options.chunkSize > FILE_UPLOAD_MAX_CHUNK_SIZE) {\n          throw new RangeError(`chunkSize option must be >= 1 and <= ${FILE_UPLOAD_MAX_CHUNK_SIZE}`);\n        }\n\n        if (!options.maxConcurrency) {\n          options.maxConcurrency = DEFAULT_HIGH_LEVEL_CONCURRENCY;\n        }\n\n        if (options.maxConcurrency <= 0) {\n          throw new RangeError(`maxConcurrency must be > 0.`);\n        }\n\n        if (!options.singleUploadThreshold) {\n          options.singleUploadThreshold = FILE_MAX_SINGLE_UPLOAD_THRESHOLD;\n        }\n\n        if (options.singleUploadThreshold < 1 || options.singleUploadThreshold > FILE_MAX_SINGLE_UPLOAD_THRESHOLD) {\n          throw new RangeError(`singleUploadThreshold option must be >= 1 and <= ${FILE_MAX_SINGLE_UPLOAD_THRESHOLD}`);\n        } // When buffer length <= singleUploadThreshold, this method will use one append/flush call to finish the upload.\n\n\n        if (size <= options.singleUploadThreshold) {\n          yield _this26.append(bodyFactory(0, size), 0, size, {\n            abortSignal: options.abortSignal,\n            conditions: options.conditions,\n            onProgress: options.onProgress,\n            tracingOptions: updatedOptions.tracingOptions\n          });\n          return yield _this26.flush(size, {\n            abortSignal: options.abortSignal,\n            conditions: options.conditions,\n            close: options.close,\n            pathHttpHeaders: options.pathHttpHeaders,\n            tracingOptions: updatedOptions.tracingOptions\n          });\n        }\n\n        const numBlocks = Math.floor((size - 1) / options.chunkSize) + 1;\n\n        if (numBlocks > BLOCK_BLOB_MAX_BLOCKS) {\n          throw new RangeError(`The data's size is too big or the chunkSize is too small;` + `the number of chunks must be <= ${BLOCK_BLOB_MAX_BLOCKS}`);\n        }\n\n        let transferProgress = 0;\n        const batch = new Batch(options.maxConcurrency);\n\n        for (let i = 0; i < numBlocks; i++) {\n          batch.addOperation( /*#__PURE__*/_asyncToGenerator(function* () {\n            const start = options.chunkSize * i;\n            const end = i === numBlocks - 1 ? size : start + options.chunkSize;\n            const contentLength = end - start;\n            yield _this26.append(bodyFactory(start, contentLength), start, contentLength, {\n              abortSignal: options.abortSignal,\n              conditions: options.conditions,\n              tracingOptions: updatedOptions.tracingOptions\n            });\n            transferProgress += contentLength;\n\n            if (options.onProgress) {\n              options.onProgress({\n                loadedBytes: transferProgress\n              });\n            }\n          }));\n        }\n\n        yield batch.do();\n        return yield _this26.flush(size, {\n          abortSignal: options.abortSignal,\n          conditions: options.conditions,\n          close: options.close,\n          pathHttpHeaders: options.pathHttpHeaders,\n          tracingOptions: updatedOptions.tracingOptions\n        });\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * ONLY AVAILABLE IN NODE.JS RUNTIME.\n   *\n   * Uploads a Node.js Readable stream into a Data Lake file.\n   * This method will try to create a file, then starts uploading chunk by chunk.\n   * Please make sure potential size of stream doesn't exceed FILE_MAX_SIZE_BYTES and\n   * potential number of chunks doesn't exceed BLOCK_BLOB_MAX_BLOCKS.\n   *\n   * PERFORMANCE IMPROVEMENT TIPS:\n   * * Input stream highWaterMark is better to set a same value with options.chunkSize\n   *   parameter, which will avoid Buffer.concat() operations.\n   *\n   * @param stream - Node.js Readable stream.\n   * @param options -\n   */\n\n\n  uploadStream(stream, options = {}) {\n    var _this27 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakeFileClient-uploadStream\", options);\n\n      try {\n        // Create the file\n        yield _this27.create({\n          abortSignal: options.abortSignal,\n          metadata: options.metadata,\n          permissions: options.permissions,\n          umask: options.umask,\n          conditions: options.conditions,\n          pathHttpHeaders: options.pathHttpHeaders,\n          tracingOptions: updatedOptions.tracingOptions\n        }); // After the File is Create, Lease ID is the only valid request parameter.\n\n        options.conditions = {\n          leaseId: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.leaseId\n        };\n\n        if (!options.chunkSize) {\n          options.chunkSize = FILE_UPLOAD_DEFAULT_CHUNK_SIZE;\n        }\n\n        if (options.chunkSize < 1 || options.chunkSize > FILE_UPLOAD_MAX_CHUNK_SIZE) {\n          throw new RangeError(`chunkSize option must be >= 1 and <= ${FILE_UPLOAD_MAX_CHUNK_SIZE}`);\n        }\n\n        if (!options.maxConcurrency) {\n          options.maxConcurrency = DEFAULT_HIGH_LEVEL_CONCURRENCY;\n        }\n\n        if (options.maxConcurrency <= 0) {\n          throw new RangeError(`maxConcurrency must be > 0.`);\n        }\n\n        let transferProgress = 0;\n        const scheduler = new BufferScheduler(stream, options.chunkSize, options.maxConcurrency, /*#__PURE__*/function () {\n          var _ref2 = _asyncToGenerator(function* (body, length, offset) {\n            yield _this27.append(body, offset, length, {\n              abortSignal: options.abortSignal,\n              conditions: options.conditions,\n              tracingOptions: updatedOptions.tracingOptions\n            }); // Update progress after block is successfully uploaded to server, in case of block trying\n\n            transferProgress += length;\n\n            if (options.onProgress) {\n              options.onProgress({\n                loadedBytes: transferProgress\n              });\n            }\n          });\n\n          return function (_x, _x2, _x3) {\n            return _ref2.apply(this, arguments);\n          };\n        }(), // concurrency should set a smaller value than maxConcurrency, which is helpful to\n        // reduce the possibility when a outgoing handler waits for stream data, in\n        // this situation, outgoing handlers are blocked.\n        // Outgoing queue shouldn't be empty.\n        Math.ceil(options.maxConcurrency / 4 * 3));\n        yield scheduler.do();\n        return yield _this27.flush(transferProgress, {\n          abortSignal: options.abortSignal,\n          conditions: options.conditions,\n          close: options.close,\n          pathHttpHeaders: options.pathHttpHeaders,\n          tracingOptions: updatedOptions.tracingOptions\n        });\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n\n  readToBuffer(bufferOrOffset, offsetOrCount, countOrOptions, optOptions = {}) {\n    var _this28 = this;\n\n    return _asyncToGenerator(function* () {\n      let buffer = undefined;\n      let offset = 0;\n      let count = 0;\n      let options = optOptions;\n\n      if (bufferOrOffset instanceof Buffer) {\n        buffer = bufferOrOffset;\n        offset = offsetOrCount || 0;\n        count = typeof countOrOptions === \"number\" ? countOrOptions : 0;\n      } else {\n        offset = typeof bufferOrOffset === \"number\" ? bufferOrOffset : 0;\n        count = typeof offsetOrCount === \"number\" ? offsetOrCount : 0;\n        options = countOrOptions || {};\n      }\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakeFileClient-readToBuffer\", options);\n\n      try {\n        if (buffer) {\n          return yield _this28.blockBlobClientInternal.downloadToBuffer(buffer, offset, count, Object.assign(Object.assign({}, options), {\n            maxRetryRequestsPerBlock: options.maxRetryRequestsPerChunk,\n            blockSize: options.chunkSize,\n            tracingOptions: updatedOptions.tracingOptions\n          }));\n        } else {\n          return yield _this28.blockBlobClientInternal.downloadToBuffer(offset, count, Object.assign(Object.assign({}, options), {\n            maxRetryRequestsPerBlock: options.maxRetryRequestsPerChunk,\n            blockSize: options.chunkSize,\n            tracingOptions: updatedOptions.tracingOptions\n          }));\n        }\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * ONLY AVAILABLE IN NODE.JS RUNTIME.\n   *\n   * Downloads a Data Lake file to a local file.\n   * Fails if the the given file path already exits.\n   * Offset and count are optional, pass 0 and undefined respectively to download the entire file.\n   *\n   * @param filePath -\n   * @param offset - From which position of the file to download.\n   * @param count - How much data to be downloaded. Will download to the end when passing undefined.\n   * @param options - Options to read Data Lake file.\n   * @returns The response data for file read operation,\n   *                                      but with readableStreamBody set to undefined since its\n   *                                      content is already read and written into a local file\n   *                                      at the specified path.\n   */\n\n\n  readToFile(filePath, offset = 0, count, options = {}) {\n    var _this29 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakeFileClient-readToFile\", options);\n\n      try {\n        return yield _this29.blockBlobClientInternal.downloadToFile(filePath, offset, count, updatedOptions);\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Quick query for a JSON or CSV formatted file.\n   *\n   * Example usage (Node.js):\n   *\n   * ```js\n   * // Query and convert a file to a string\n   * const queryResponse = await fileClient.query(\"select * from BlobStorage\");\n   * const downloaded = (await streamToBuffer(queryResponse.readableStreamBody)).toString();\n   * console.log(\"Query file content:\", downloaded);\n   *\n   * async function streamToBuffer(readableStream) {\n   *   return new Promise((resolve, reject) => {\n   *     const chunks = [];\n   *     readableStream.on(\"data\", (data) => {\n   *       chunks.push(data instanceof Buffer ? data : Buffer.from(data));\n   *     });\n   *     readableStream.on(\"end\", () => {\n   *       resolve(Buffer.concat(chunks));\n   *     });\n   *     readableStream.on(\"error\", reject);\n   *   });\n   * }\n   * ```\n   *\n   * @param query -\n   * @param options -\n   */\n\n\n  query(query, options = {}) {\n    var _this30 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakeFileClient-query\", options);\n\n      try {\n        const rawResponse = yield _this30.blockBlobClientInternal.query(query, updatedOptions);\n        const response = rawResponse;\n\n        if (!isNode && !response.contentAsBlob) {\n          response.contentAsBlob = rawResponse.blobBody;\n        }\n\n        response.fileContentMD5 = rawResponse.blobContentMD5;\n        response._response.parsedHeaders.fileContentMD5 = rawResponse._response.parsedHeaders.blobContentMD5;\n        delete rawResponse.blobContentMD5;\n        delete rawResponse._response.parsedHeaders.blobContentMD5;\n        return response;\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Sets an expiry time on a file, once that time is met the file is deleted.\n   *\n   * @param mode -\n   * @param options -\n   */\n\n\n  setExpiry(mode, options = {}) {\n    var _this31 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      const {\n        span,\n        updatedOptions\n      } = createSpan(\"DataLakeFileClient-setExpiry\", options);\n\n      try {\n        let expiresOn = undefined;\n\n        if (mode === \"RelativeToNow\" || mode === \"RelativeToCreation\") {\n          if (!options.timeToExpireInMs) {\n            throw new Error(`Should specify options.timeToExpireInMs when using mode ${mode}.`);\n          } // MINOR: need check against <= 2**64, but JS number has the precision problem.\n\n\n          expiresOn = Math.round(options.timeToExpireInMs).toString();\n        }\n\n        if (mode === \"Absolute\") {\n          if (!options.expiresOn) {\n            throw new Error(`Should specify options.expiresOn when using mode ${mode}.`);\n          }\n\n          const now = new Date();\n\n          if (!(options.expiresOn.getTime() > now.getTime())) {\n            throw new Error(`options.expiresOn should be later than now: ${now.toUTCString()} when using mode ${mode}, but is ${(_a = options.expiresOn) === null || _a === void 0 ? void 0 : _a.toUTCString()}`);\n          }\n\n          expiresOn = options.expiresOn.toUTCString();\n        }\n\n        const adaptedOptions = Object.assign(Object.assign({}, options), {\n          expiresOn\n        });\n        return yield _this31.pathContextInternalToBlobEndpoint.setExpiry(mode, Object.assign(Object.assign({}, adaptedOptions), {\n          tracingOptions: updatedOptions.tracingOptions\n        }));\n      } catch (e) {\n        span.setStatus({\n          code: SpanStatusCode.ERROR,\n          message: e.message\n        });\n        throw e;\n      } finally {\n        span.end();\n      }\n    })();\n  }\n  /**\n   * Only available for clients constructed with a shared key credential.\n   *\n   * Generates a Service Shared Access Signature (SAS) URI based on the client properties\n   * and parameters passed in. The SAS is signed by the shared key credential of the client.\n   *\n   * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas\n   *\n   * @param options - Optional parameters.\n   * @returns The SAS URI consisting of the URI to the resource represented by this client, followed by the generated SAS token.\n   */\n\n\n  generateSasUrl(options) {\n    return new Promise(resolve => {\n      if (!(this.credential instanceof StorageSharedKeyCredential)) {\n        throw RangeError(\"Can only generate the SAS when the client is initialized with a shared key credential\");\n      }\n\n      const sas = generateDataLakeSASQueryParameters(Object.assign({\n        fileSystemName: this.fileSystemName,\n        pathName: this.name\n      }, options), this.credential).toString();\n      resolve(appendToURLQuery(this.url, sas));\n    });\n  }\n\n} //# sourceMappingURL=clients.js.map","map":{"version":3,"sources":["F:/statvalu/project/AR_DocuExpert_Test/node_modules/@azure/storage-file-datalake/dist-esm/storage-file-datalake/src/clients.js"],"names":["isNode","BlobClient","BlockBlobClient","SpanStatusCode","BufferScheduler","AnonymousCredential","StorageSharedKeyCredential","DataLakeLeaseClient","Path","newPipeline","Pipeline","generateDataLakeSASQueryParameters","StorageClient","toAccessControlChangeFailureArray","toAclString","toPathGetAccessControlResponse","toPermissionsString","toProperties","Batch","BLOCK_BLOB_MAX_BLOCKS","DEFAULT_HIGH_LEVEL_CONCURRENCY","ETagAny","FILE_MAX_SINGLE_UPLOAD_THRESHOLD","FILE_MAX_SIZE_BYTES","FILE_UPLOAD_DEFAULT_CHUNK_SIZE","FILE_UPLOAD_MAX_CHUNK_SIZE","DataLakeAclChangeFailedError","convertTracingToRequestOptionsBase","createSpan","appendToURLPath","appendToURLQuery","getURLPathAndQuery","setURLPath","setURLQueries","fsCreateReadStream","fsStat","DataLakePathClient","constructor","url","credentialOrPipeline","options","credential","undefined","pipeline","pathContext","storageClientContext","blobClient","blobEndpointUrl","setAccessControlRecursiveInternal","mode","acl","maxBatches","RangeError","batchSize","span","updatedOptions","result","counters","failedChangesCount","changedDirectoriesCount","changedFilesCount","continuationToken","batchCounter","reachMaxBatches","response","setAccessControlRecursive","Object","assign","maxRecords","continuation","forceFlag","continueOnFailure","e","failureCount","directoriesSuccessful","filesSuccessful","onProgress","progress","batchFailures","failedEntries","batchCounters","aggregateCounters","setStatus","code","ERROR","message","end","fileSystemName","containerName","name","toDirectoryClient","DataLakeDirectoryClient","dfsEndpointUrl","toFileClient","DataLakeFileClient","getDataLakeLeaseClient","proposeLeaseId","getBlobLeaseClient","create","resourceType","conditions","resource","leaseAccessConditions","modifiedAccessConditions","properties","metadata","createIfNotExists","_a","_b","ifNoneMatch","res","tracingOptions","succeeded","details","errorCode","parsedHeaders","_response","exists","delete","recursive","abortSignal","deleteIfExists","getAccessControl","getProperties","action","upn","userPrincipalName","setAccessControl","updateAccessControlRecursive","removeAccessControlRecursive","setPermissions","permissions","customerProvidedKey","setHttpHeaders","httpHeaders","setHTTPHeaders","blobCacheControl","cacheControl","blobContentType","contentType","blobContentMD5","contentMD5","blobContentEncoding","contentEncoding","blobContentLanguage","contentLanguage","blobContentDisposition","contentDisposition","setMetadata","move","destinationPathOrFileSystem","destinationPathOrOptions","destinationFileSystem","destinationPath","destinationConditions","renameSource","split","destinationUrl","length","renameDestination","destPathClient","sourceLeaseId","leaseId","sourceModifiedAccessConditions","sourceIfMatch","ifMatch","sourceIfNoneMatch","sourceIfModifiedSince","ifModifiedSince","sourceIfUnmodifiedSince","ifUnmodifiedSince","resourceTypeOrOptions","TypeError","getSubdirectoryClient","subdirectoryName","encodeURIComponent","getFileClient","fileName","generateSasUrl","Promise","resolve","sas","pathName","isDirectory","toString","pathContextInternal","blockBlobClientInternal","pathContextInternalToBlobEndpoint","storageClientContextToBlobEndpoint","read","offset","count","rawResponse","download","contentAsBlob","blobBody","fileContentMD5","append","body","appendData","pathHttpHeaders","transactionalContentMD5","position","contentLength","requestOptions","onUploadProgress","flush","flushData","uploadFile","filePath","size","uploadSeekableInternal","contentSize","autoClose","start","upload","data","buffer","Buffer","ArrayBuffer","from","byteOffset","byteLength","slice","browserBlob","Blob","bodyFactory","createRes","umask","chunkSize","Math","ceil","maxConcurrency","singleUploadThreshold","close","numBlocks","floor","transferProgress","batch","i","addOperation","loadedBytes","do","uploadStream","stream","scheduler","readToBuffer","bufferOrOffset","offsetOrCount","countOrOptions","optOptions","downloadToBuffer","maxRetryRequestsPerBlock","maxRetryRequestsPerChunk","blockSize","readToFile","downloadToFile","query","setExpiry","expiresOn","timeToExpireInMs","Error","round","now","Date","getTime","toUTCString","adaptedOptions"],"mappings":";AAAA;AACA;AACA,SAASA,MAAT,QAAuB,kBAAvB;AACA,SAASC,UAAT,EAAqBC,eAArB,QAA4C,qBAA5C;AACA,SAASC,cAAT,QAA+B,qBAA/B;AACA,SAASC,eAAT,QAAgC,0BAAhC;AACA,SAASC,mBAAT,QAAoC,mCAApC;AACA,SAASC,0BAAT,QAA2C,0CAA3C;AACA,SAASC,mBAAT,QAAoC,uBAApC;AACA,SAASC,IAAT,QAAqB,4BAArB;AACA,SAASC,WAAT,EAAsBC,QAAtB,QAAsC,YAAtC;AACA,SAASC,kCAAT,QAAmD,kCAAnD;AACA,SAASC,aAAT,QAA8B,iBAA9B;AACA,SAASC,iCAAT,EAA4CC,WAA5C,EAAyDC,8BAAzD,EAAyFC,mBAAzF,EAA8GC,YAA9G,QAAkI,cAAlI;AACA,SAASC,KAAT,QAAsB,eAAtB;AACA,SAASC,qBAAT,EAAgCC,8BAAhC,EAAgEC,OAAhE,EAAyEC,gCAAzE,EAA2GC,mBAA3G,EAAgIC,8BAAhI,EAAgKC,0BAAhK,QAAkM,mBAAlM;AACA,SAASC,4BAAT,QAA6C,sCAA7C;AACA,SAASC,kCAAT,EAA6CC,UAA7C,QAA+D,iBAA/D;AACA,SAASC,eAAT,EAA0BC,gBAA1B,EAA4CC,kBAA5C,EAAgEC,UAAhE,EAA4EC,aAA5E,QAAiG,sBAAjG;AACA,SAASC,kBAAT,EAA6BC,MAA7B,QAA2C,oBAA3C;AACA;AACA;AACA;;AACA,OAAO,MAAMC,kBAAN,SAAiCxB,aAAjC,CAA+C;AAClDyB,EAAAA,WAAW,CAACC,GAAD,EAAMC,oBAAN,EACX;;AACA;AACAC,EAAAA,OAHW,EAGF;AACL,QAAID,oBAAoB,YAAY7B,QAApC,EAA8C;AAC1C,YAAM4B,GAAN,EAAWC,oBAAX;AACH,KAFD,MAGK;AACD,UAAIE,UAAJ;;AACA,UAAIF,oBAAoB,KAAKG,SAA7B,EAAwC;AACpCD,QAAAA,UAAU,GAAG,IAAIpC,mBAAJ,EAAb;AACH,OAFD,MAGK;AACDoC,QAAAA,UAAU,GAAGF,oBAAb;AACH;;AACD,YAAMI,QAAQ,GAAGlC,WAAW,CAACgC,UAAD,EAAaD,OAAb,CAA5B;AACA,YAAMF,GAAN,EAAWK,QAAX;AACH;;AACD,SAAKC,WAAL,GAAmB,IAAIpC,IAAJ,CAAS,KAAKqC,oBAAd,CAAnB;AACA,SAAKC,UAAL,GAAkB,IAAI7C,UAAJ,CAAe,KAAK8C,eAApB,EAAqC,KAAKJ,QAA1C,CAAlB;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACUK,EAAAA,iCAAiC,CAACC,IAAD,EAAOC,GAAP,EAAYV,OAAO,GAAG,EAAtB,EAA0B;AAAA;;AAAA;AAC7D,UAAIA,OAAO,CAACW,UAAR,KAAuBT,SAAvB,IAAoCF,OAAO,CAACW,UAAR,GAAqB,CAA7D,EAAgE;AAC5D,cAAMC,UAAU,CAAE,2CAAF,CAAhB;AACH;;AACD,UAAIZ,OAAO,CAACa,SAAR,KAAsBX,SAAtB,IAAmCF,OAAO,CAACa,SAAR,GAAoB,CAA3D,EAA8D;AAC1D,cAAMD,UAAU,CAAE,0CAAF,CAAhB;AACH;;AACD,YAAM;AAAEE,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAE,sDAAF,EAAyDY,OAAzD,CAA3C;AACA,YAAMgB,MAAM,GAAG;AACXC,QAAAA,QAAQ,EAAE;AACNC,UAAAA,kBAAkB,EAAE,CADd;AAENC,UAAAA,uBAAuB,EAAE,CAFnB;AAGNC,UAAAA,iBAAiB,EAAE;AAHb,SADC;AAMXC,QAAAA,iBAAiB,EAAEnB;AANR,OAAf;;AAQA,UAAI;AACA,YAAImB,iBAAiB,GAAGrB,OAAO,CAACqB,iBAAhC;AACA,YAAIC,YAAY,GAAG,CAAnB;AACA,YAAIC,eAAe,GAAG,KAAtB;;AACA,WAAG;AACC,cAAIC,QAAJ;;AACA,cAAI;AACAA,YAAAA,QAAQ,SAAS,KAAI,CAACpB,WAAL,CAAiBqB,yBAAjB,CAA2ChB,IAA3C,EAAiDiB,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB3B,OAAlB,CAAd,EAA0C;AAAEU,cAAAA,GAAG,EAAEpC,WAAW,CAACoC,GAAD,CAAlB;AAAyBkB,cAAAA,UAAU,EAAE5B,OAAO,CAACa,SAA7C;AAAwDgB,cAAAA,YAAY,EAAER,iBAAtE;AAAyFS,cAAAA,SAAS,EAAE9B,OAAO,CAAC+B;AAA5G,aAA1C,CAAd,EAA0L5C,kCAAkC,CAAC4B,cAAD,CAA5N,CAAjD,CAAjB;AACH,WAFD,CAGA,OAAOiB,CAAP,EAAU;AACN,kBAAM,IAAI9C,4BAAJ,CAAiC8C,CAAjC,EAAoCX,iBAApC,CAAN;AACH;;AACDC,UAAAA,YAAY;AACZD,UAAAA,iBAAiB,GAAGG,QAAQ,CAACK,YAA7B,CATD,CAUC;;AACAb,UAAAA,MAAM,CAACK,iBAAP,GAA2BA,iBAA3B;AACAL,UAAAA,MAAM,CAACC,QAAP,CAAgBC,kBAAhB,IAAsCM,QAAQ,CAACS,YAAT,IAAyB,CAA/D;AACAjB,UAAAA,MAAM,CAACC,QAAP,CAAgBE,uBAAhB,IAA2CK,QAAQ,CAACU,qBAAT,IAAkC,CAA7E;AACAlB,UAAAA,MAAM,CAACC,QAAP,CAAgBG,iBAAhB,IAAqCI,QAAQ,CAACW,eAAT,IAA4B,CAAjE,CAdD,CAeC;;AACA,cAAInC,OAAO,CAACoC,UAAZ,EAAwB;AACpB,kBAAMC,QAAQ,GAAG;AACbC,cAAAA,aAAa,EAAEjE,iCAAiC,CAACmD,QAAQ,CAACe,aAAV,CADnC;AAEbC,cAAAA,aAAa,EAAE;AACXtB,gBAAAA,kBAAkB,EAAEM,QAAQ,CAACS,YAAT,IAAyB,CADlC;AAEXd,gBAAAA,uBAAuB,EAAEK,QAAQ,CAACU,qBAAT,IAAkC,CAFhD;AAGXd,gBAAAA,iBAAiB,EAAEI,QAAQ,CAACW,eAAT,IAA4B;AAHpC,eAFF;AAObM,cAAAA,iBAAiB,EAAEzB,MAAM,CAACC,QAPb;AAQbI,cAAAA,iBAAiB,EAAEA;AARN,aAAjB;AAUArB,YAAAA,OAAO,CAACoC,UAAR,CAAmBC,QAAnB;AACH;;AACDd,UAAAA,eAAe,GACXvB,OAAO,CAACW,UAAR,KAAuBT,SAAvB,GAAmC,KAAnC,GAA2CoB,YAAY,IAAItB,OAAO,CAACW,UADvE;AAEH,SA/BD,QA+BSU,iBAAiB,IAAI,CAACE,eA/B/B;;AAgCA,eAAOP,MAAP;AACH,OArCD,CAsCA,OAAOgB,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OA5CD,SA6CQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AA/D4D;AAgEhE;AACD;AACJ;AACA;AACA;AACA;;;AACsB,MAAdC,cAAc,GAAG;AACjB,WAAO,KAAKzC,UAAL,CAAgB0C,aAAvB;AACH;AACD;AACJ;AACA;AACA;AACA;;;AACY,MAAJC,IAAI,GAAG;AACP,WAAO,KAAK3C,UAAL,CAAgB2C,IAAvB;AACH;AACD;AACJ;AACA;AACA;AACI;;AACA;;;AACAC,EAAAA,iBAAiB,GAAG;AAChB,WAAO,IAAIC,uBAAJ,CAA4B,KAAKC,cAAjC,EAAiD,KAAKjD,QAAtD,CAAP;AACH;AACD;AACJ;AACA;AACA;AACI;;AACA;;;AACAkD,EAAAA,YAAY,GAAG;AACX,WAAO,IAAIC,kBAAJ,CAAuB,KAAKF,cAA5B,EAA4C,KAAKjD,QAAjD,CAAP;AACH;AACD;AACJ;AACA;AACA;AACA;;;AACIoD,EAAAA,sBAAsB,CAACC,cAAD,EAAiB;AACnC,WAAO,IAAIzF,mBAAJ,CAAwB,KAAKuC,UAAL,CAAgBmD,kBAAhB,CAAmCD,cAAnC,CAAxB,CAAP;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;;AACUE,EAAAA,MAAM,CAACC,YAAD,EAAe3D,OAAO,GAAG,EAAzB,EAA6B;AAAA;;AAAA;AACrCA,MAAAA,OAAO,CAAC4D,UAAR,GAAqB5D,OAAO,CAAC4D,UAAR,IAAsB,EAA3C;AACA,YAAM;AAAE9C,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,2BAAD,EAA8BY,OAA9B,CAA3C;;AACA,UAAI;AACA,qBAAa,MAAI,CAACI,WAAL,CAAiBsD,MAAjB,CAAwBhC,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB3B,OAAlB,CAAd,EAA0C;AAAE6D,UAAAA,QAAQ,EAAEF,YAAZ;AAA0BG,UAAAA,qBAAqB,EAAE9D,OAAO,CAAC4D,UAAzD;AAAqEG,UAAAA,wBAAwB,EAAE/D,OAAO,CAAC4D,UAAvG;AAAmHI,UAAAA,UAAU,EAAEvF,YAAY,CAACuB,OAAO,CAACiE,QAAT;AAA3I,SAA1C,CAAd,EAA0N9E,kCAAkC,CAAC4B,cAAD,CAA5P,CAAxB,CAAb;AACH,OAFD,CAGA,OAAOiB,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OATD,SAUQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAfoC;AAgBxC;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;;AACUoB,EAAAA,iBAAiB,CAACP,YAAD,EAAe3D,OAAO,GAAG,EAAzB,EAA6B;AAAA;;AAAA;AAChD,UAAImE,EAAJ,EAAQC,EAAR;;AACA,YAAM;AAAEtD,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,sCAAD,EAAyCY,OAAzC,CAA3C;;AACA,UAAI;AACA,cAAM4D,UAAU,GAAG;AAAES,UAAAA,WAAW,EAAExF;AAAf,SAAnB;AACA,cAAMyF,GAAG,SAAS,MAAI,CAACZ,MAAL,CAAYC,YAAZ,EAA0BjC,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB3B,OAAlB,CAAd,EAA0C;AAAE4D,UAAAA,UAAF;AAAcW,UAAAA,cAAc,EAAExD,cAAc,CAACwD;AAA7C,SAA1C,CAA1B,CAAlB;AACA,eAAO7C,MAAM,CAACC,MAAP,CAAc;AAAE6C,UAAAA,SAAS,EAAE;AAAb,SAAd,EAAmCF,GAAnC,CAAP;AACH,OAJD,CAKA,OAAOtC,CAAP,EAAU;AACN,YAAI,CAAC,CAACmC,EAAE,GAAGnC,CAAC,CAACyC,OAAR,MAAqB,IAArB,IAA6BN,EAAE,KAAK,KAAK,CAAzC,GAA6C,KAAK,CAAlD,GAAsDA,EAAE,CAACO,SAA1D,MAAyE,mBAA7E,EAAkG;AAC9F5D,UAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,YAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,YAAAA,OAAO,EAAE;AAFE,WAAf;AAIA,iBAAOnB,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc;AAAE6C,YAAAA,SAAS,EAAE;AAAb,WAAd,EAAoC,CAACJ,EAAE,GAAGpC,CAAC,CAACR,QAAR,MAAsB,IAAtB,IAA8B4C,EAAE,KAAK,KAAK,CAA1C,GAA8C,KAAK,CAAnD,GAAuDA,EAAE,CAACO,aAA9F,CAAd,EAA4H;AAAEC,YAAAA,SAAS,EAAE5C,CAAC,CAACR;AAAf,WAA5H,CAAP;AACH;;AACDV,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OAlBD,SAmBQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAxB+C;AAyBnD;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACU+B,EAAAA,MAAM,CAAC7E,OAAO,GAAG,EAAX,EAAe;AAAA;;AAAA;AACvB,YAAM;AAAEc,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,2BAAD,EAA8BY,OAA9B,CAA3C;;AACA,UAAI;AACA,qBAAa,MAAI,CAACM,UAAL,CAAgBuE,MAAhB,CAAuB9D,cAAvB,CAAb;AACH,OAFD,CAGA,OAAOiB,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OATD,SAUQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAdsB;AAe1B;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;;AACUgC,EAAAA,MAAM,CAACC,SAAD,EAAY/E,OAAO,GAAG,EAAtB,EAA0B;AAAA;;AAAA;AAClCA,MAAAA,OAAO,CAAC4D,UAAR,GAAqB5D,OAAO,CAAC4D,UAAR,IAAsB,EAA3C;AACA,YAAM;AAAE9C,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,2BAAD,EAA8BY,OAA9B,CAA3C;;AACA,UAAI;AACA,YAAI6B,YAAJ;AACA,YAAIL,QAAJ,CAFA,CAGA;;AACA,WAAG;AACCA,UAAAA,QAAQ,SAAS,MAAI,CAACpB,WAAL,CAAiB0E,MAAjB,CAAwBpD,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc;AAAEE,YAAAA,YAAF;AACjEkD,YAAAA,SADiE;AACtDjB,YAAAA,qBAAqB,EAAE9D,OAAO,CAAC4D,UADuB;AACXG,YAAAA,wBAAwB,EAAE/D,OAAO,CAAC4D;AADvB,WAAd,EACmDzE,kCAAkC,CAAC4B,cAAD,CADrF,CAAd,EACsH;AAAEiE,YAAAA,WAAW,EAAEhF,OAAO,CAACgF;AAAvB,WADtH,CAAxB,CAAjB;AAEAnD,UAAAA,YAAY,GAAGL,QAAQ,CAACK,YAAxB;AACH,SAJD,QAISA,YAAY,KAAK3B,SAAjB,IAA8B2B,YAAY,KAAK,EAJxD;;AAKA,eAAOL,QAAP;AACH,OAVD,CAWA,OAAOQ,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OAjBD,SAkBQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAvBiC;AAwBrC;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;;AACUmC,EAAAA,cAAc,CAACF,SAAD,EAAY/E,OAAO,GAAG,EAAtB,EAA0B;AAAA;;AAAA;AAC1C,UAAImE,EAAJ,EAAQC,EAAR;;AACApE,MAAAA,OAAO,CAAC4D,UAAR,GAAqB5D,OAAO,CAAC4D,UAAR,IAAsB,EAA3C;AACA,YAAM;AAAE9C,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,mCAAD,EAAsCY,OAAtC,CAA3C;;AACA,UAAI;AACA,cAAMsE,GAAG,SAAS,MAAI,CAACQ,MAAL,CAAYC,SAAZ,EAAuBhE,cAAvB,CAAlB;AACA,eAAOW,MAAM,CAACC,MAAP,CAAc;AAAE6C,UAAAA,SAAS,EAAE;AAAb,SAAd,EAAmCF,GAAnC,CAAP;AACH,OAHD,CAIA,OAAOtC,CAAP,EAAU;AACN,YAAI,CAAC,CAACmC,EAAE,GAAGnC,CAAC,CAACyC,OAAR,MAAqB,IAArB,IAA6BN,EAAE,KAAK,KAAK,CAAzC,GAA6C,KAAK,CAAlD,GAAsDA,EAAE,CAACO,SAA1D,MAAyE,cAA7E,EAA6F;AACzF5D,UAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,YAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,YAAAA,OAAO,EAAE;AAFE,WAAf;AAIA,iBAAOnB,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc;AAAE6C,YAAAA,SAAS,EAAE;AAAb,WAAd,EAAoC,CAACJ,EAAE,GAAGpC,CAAC,CAACR,QAAR,MAAsB,IAAtB,IAA8B4C,EAAE,KAAK,KAAK,CAA1C,GAA8C,KAAK,CAAnD,GAAuDA,EAAE,CAACO,aAA9F,CAAd,EAA4H;AAAEC,YAAAA,SAAS,EAAE5C,CAAC,CAACR;AAAf,WAA5H,CAAP;AACH;;AACDV,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OAjBD,SAkBQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAxByC;AAyB7C;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;;;AACUoC,EAAAA,gBAAgB,CAAClF,OAAO,GAAG,EAAX,EAAe;AAAA;;AAAA;AACjCA,MAAAA,OAAO,CAAC4D,UAAR,GAAqB5D,OAAO,CAAC4D,UAAR,IAAsB,EAA3C;AACA,YAAM;AAAE9C,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,qCAAD,EAAwCY,OAAxC,CAA3C;;AACA,UAAI;AACA,cAAMwB,QAAQ,SAAS,MAAI,CAACpB,WAAL,CAAiB+E,aAAjB,CAA+BzD,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc;AAAEyD,UAAAA,MAAM,EAAE,kBAAV;AAA8BC,UAAAA,GAAG,EAAErF,OAAO,CAACsF,iBAA3C;AAA8DxB,UAAAA,qBAAqB,EAAE9D,OAAO,CAAC4D,UAA7F;AAAyGG,UAAAA,wBAAwB,EAAE/D,OAAO,CAAC4D;AAA3I,SAAd,EAAuKzE,kCAAkC,CAAC4B,cAAD,CAAzM,CAAd,EAA0O;AAAEiE,UAAAA,WAAW,EAAEhF,OAAO,CAACgF;AAAvB,SAA1O,CAA/B,CAAvB;AACA,eAAOzG,8BAA8B,CAACiD,QAAD,CAArC;AACH,OAHD,CAIA,OAAOQ,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OAVD,SAWQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAhBgC;AAiBpC;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;;AACUyC,EAAAA,gBAAgB,CAAC7E,GAAD,EAAMV,OAAO,GAAG,EAAhB,EAAoB;AAAA;;AAAA;AACtCA,MAAAA,OAAO,CAAC4D,UAAR,GAAqB5D,OAAO,CAAC4D,UAAR,IAAsB,EAA3C;AACA,YAAM;AAAE9C,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,qCAAD,EAAwCY,OAAxC,CAA3C;;AACA,UAAI;AACA,qBAAa,MAAI,CAACI,WAAL,CAAiBmF,gBAAjB,CAAkC7D,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB3B,OAAlB,CAAd,EAA0C;AAAEU,UAAAA,GAAG,EAAEpC,WAAW,CAACoC,GAAD,CAAlB;AAAyBoD,UAAAA,qBAAqB,EAAE9D,OAAO,CAAC4D,UAAxD;AAAoEG,UAAAA,wBAAwB,EAAE/D,OAAO,CAAC4D;AAAtG,SAA1C,CAAd,EAA6KzE,kCAAkC,CAAC4B,cAAD,CAA/M,CAAlC,CAAb;AACH,OAFD,CAGA,OAAOiB,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OATD,SAUQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAfqC;AAgBzC;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;;AACUrB,EAAAA,yBAAyB,CAACf,GAAD,EAAMV,OAAO,GAAG,EAAhB,EAAoB;AAAA;;AAAA;AAC/C,YAAM;AAAEc,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,8CAAD,EAAiDY,OAAjD,CAA3C;;AACA,UAAI;AACA,eAAO,MAAI,CAACQ,iCAAL,CAAuC,KAAvC,EAA8CE,GAA9C,EAAmDK,cAAnD,CAAP;AACH,OAFD,CAGA,OAAOiB,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OATD,SAUQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAd8C;AAelD;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;;AACU0C,EAAAA,4BAA4B,CAAC9E,GAAD,EAAMV,OAAO,GAAG,EAAhB,EAAoB;AAAA;;AAAA;AAClD,YAAM;AAAEc,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,iDAAD,EAAoDY,OAApD,CAA3C;;AACA,UAAI;AACA,eAAO,OAAI,CAACQ,iCAAL,CAAuC,QAAvC,EAAiDE,GAAjD,EAAsDK,cAAtD,CAAP;AACH,OAFD,CAGA,OAAOiB,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OATD,SAUQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAdiD;AAerD;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;;AACU2C,EAAAA,4BAA4B,CAAC/E,GAAD,EAAMV,OAAO,GAAG,EAAhB,EAAoB;AAAA;;AAAA;AAClD,YAAM;AAAEc,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,iDAAD,EAAoDY,OAApD,CAA3C;;AACA,UAAI;AACA,eAAO,OAAI,CAACQ,iCAAL,CAAuC,QAAvC,EAAiDE,GAAjD,EAAsDK,cAAtD,CAAP;AACH,OAFD,CAGA,OAAOiB,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OATD,SAUQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAdiD;AAerD;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;;AACU4C,EAAAA,cAAc,CAACC,WAAD,EAAc3F,OAAO,GAAG,EAAxB,EAA4B;AAAA;;AAAA;AAC5CA,MAAAA,OAAO,CAAC4D,UAAR,GAAqB5D,OAAO,CAAC4D,UAAR,IAAsB,EAA3C;AACA,YAAM;AAAE9C,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,mCAAD,EAAsCY,OAAtC,CAA3C;;AACA,UAAI;AACA,qBAAa,OAAI,CAACI,WAAL,CAAiBmF,gBAAjB,CAAkC7D,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB3B,OAAlB,CAAd,EAA0C;AAAE2F,UAAAA,WAAW,EAAEnH,mBAAmB,CAACmH,WAAD,CAAlC;AAAiD7B,UAAAA,qBAAqB,EAAE9D,OAAO,CAAC4D,UAAhF;AAA4FG,UAAAA,wBAAwB,EAAE/D,OAAO,CAAC4D;AAA9H,SAA1C,CAAd,EAAqMzE,kCAAkC,CAAC4B,cAAD,CAAvO,CAAlC,CAAb;AACH,OAFD,CAGA,OAAOiB,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OATD,SAUQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAf2C;AAgB/C;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACUqC,EAAAA,aAAa,CAACnF,OAAO,GAAG,EAAX,EAAe;AAAA;;AAAA;AAC9B,YAAM;AAAEc,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,kCAAD,EAAqCY,OAArC,CAA3C;;AACA,UAAI;AACA,qBAAa,OAAI,CAACM,UAAL,CAAgB6E,aAAhB,CAA8BzD,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB3B,OAAlB,CAAd,EAA0C;AAAE4F,UAAAA,mBAAmB,EAAE1F,SAAvB;AAAkCqE,UAAAA,cAAc,EAAExD,cAAc,CAACwD;AAAjE,SAA1C,CAA9B,CAAb;AACH,OAFD,CAGA,OAAOvC,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OATD,SAUQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAd6B;AAejC;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACU+C,EAAAA,cAAc,CAACC,WAAD,EAAc9F,OAAO,GAAG,EAAxB,EAA4B;AAAA;;AAAA;AAC5C,YAAM;AAAEc,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,mCAAD,EAAsCY,OAAtC,CAA3C;;AACA,UAAI;AACA,qBAAa,OAAI,CAACM,UAAL,CAAgByF,cAAhB,CAA+B;AACxCC,UAAAA,gBAAgB,EAAEF,WAAW,CAACG,YADU;AAExCC,UAAAA,eAAe,EAAEJ,WAAW,CAACK,WAFW;AAGxCC,UAAAA,cAAc,EAAEN,WAAW,CAACO,UAHY;AAIxCC,UAAAA,mBAAmB,EAAER,WAAW,CAACS,eAJO;AAKxCC,UAAAA,mBAAmB,EAAEV,WAAW,CAACW,eALO;AAMxCC,UAAAA,sBAAsB,EAAEZ,WAAW,CAACa;AANI,SAA/B,EAOV5F,cAPU,CAAb;AAQH,OATD,CAUA,OAAOiB,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OAhBD,SAiBQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AArB2C;AAsB/C;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACU8D,EAAAA,WAAW,CAAC3C,QAAD,EAAWjE,OAAO,GAAG,EAArB,EAAyB;AAAA;;AAAA;AACtC,YAAM;AAAEc,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,gCAAD,EAAmCY,OAAnC,CAA3C;;AACA,UAAI;AACA,qBAAa,OAAI,CAACM,UAAL,CAAgBsG,WAAhB,CAA4B3C,QAA5B,EAAsCvC,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB3B,OAAlB,CAAd,EAA0C;AAAE4F,UAAAA,mBAAmB,EAAE1F,SAAvB;AAAkCqE,UAAAA,cAAc,EAAExD,cAAc,CAACwD;AAAjE,SAA1C,CAAtC,CAAb;AACH,OAFD,CAGA,OAAOvC,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OATD,SAUQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAdqC;AAezC;;AACK+D,EAAAA,IAAI,CAACC,2BAAD,EAA8BC,wBAA9B,EAAwD/G,OAAxD,EAAiE;AAAA;;AAAA;AACvE,UAAIgH,qBAAqB,GAAG,OAAI,CAACjE,cAAjC;AACA,UAAIkE,eAAe,GAAGH,2BAAtB;;AACA,UAAI,OAAOC,wBAAP,KAAoC,QAAxC,EAAkD;AAC9CC,QAAAA,qBAAqB,GAAGF,2BAAxB;AACAG,QAAAA,eAAe,GAAGF,wBAAlB;AACA/G,QAAAA,OAAO,GAAGA,OAAO,IAAI,EAArB;AACH,OAJD,MAKK;AACDA,QAAAA,OAAO,GAAG+G,wBAAwB,IAAI,EAAtC;AACH;;AACD/G,MAAAA,OAAO,CAAC4D,UAAR,GAAqB5D,OAAO,CAAC4D,UAAR,IAAsB,EAA3C;AACA5D,MAAAA,OAAO,CAACkH,qBAAR,GAAgClH,OAAO,CAACkH,qBAAR,IAAiC,EAAjE;AACA,YAAM;AAAEpG,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,yBAAD,EAA4BY,OAA5B,CAA3C;AACA,YAAMmH,YAAY,GAAG5H,kBAAkB,CAAC,OAAI,CAAC6D,cAAN,CAAvC;AACA,YAAMgE,KAAK,GAAGH,eAAe,CAACG,KAAhB,CAAsB,GAAtB,CAAd;AACA,UAAIC,cAAJ;;AACA,UAAID,KAAK,CAACE,MAAN,KAAiB,CAArB,EAAwB;AACpB,cAAMC,iBAAiB,GAAI,IAAGP,qBAAsB,IAAGI,KAAK,CAAC,CAAD,CAAI,EAAhE;AACAC,QAAAA,cAAc,GAAG7H,UAAU,CAAC,OAAI,CAAC4D,cAAN,EAAsBmE,iBAAtB,CAA3B;AACAF,QAAAA,cAAc,GAAG5H,aAAa,CAAC4H,cAAD,EAAiBD,KAAK,CAAC,CAAD,CAAtB,CAA9B;AACH,OAJD,MAKK,IAAIA,KAAK,CAACE,MAAN,KAAiB,CAArB,EAAwB;AACzB,cAAMC,iBAAiB,GAAI,IAAGP,qBAAsB,IAAGC,eAAgB,EAAvE;AACAI,QAAAA,cAAc,GAAG7H,UAAU,CAAC,OAAI,CAAC4D,cAAN,EAAsBmE,iBAAtB,CAA3B;AACH,OAHI,MAIA;AACD,cAAM,IAAI3G,UAAJ,CAAe,gEAAf,CAAN;AACH;;AACD,YAAM4G,cAAc,GAAG,IAAI5H,kBAAJ,CAAuByH,cAAvB,EAAuC,OAAI,CAAClH,QAA5C,CAAvB;;AACA,UAAI;AACA,qBAAaqH,cAAc,CAACpH,WAAf,CAA2BsD,MAA3B,CAAkChC,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc;AAAElB,UAAAA,IAAI,EAAE,QAAR;AAAkB;AACzF0G,UAAAA,YADuE;AACzDM,UAAAA,aAAa,EAAEzH,OAAO,CAAC4D,UAAR,CAAmB8D,OADuB;AACd5D,UAAAA,qBAAqB,EAAE9D,OAAO,CAACkH,qBADjB;AACwCS,UAAAA,8BAA8B,EAAE;AAC3IC,YAAAA,aAAa,EAAE5H,OAAO,CAAC4D,UAAR,CAAmBiE,OADyG;AAE3IC,YAAAA,iBAAiB,EAAE9H,OAAO,CAAC4D,UAAR,CAAmBS,WAFqG;AAG3I0D,YAAAA,qBAAqB,EAAE/H,OAAO,CAAC4D,UAAR,CAAmBoE,eAHiG;AAI3IC,YAAAA,uBAAuB,EAAEjI,OAAO,CAAC4D,UAAR,CAAmBsE;AAJ+F,WADxE;AAMpEnE,UAAAA,wBAAwB,EAAE/D,OAAO,CAACkH;AANkC,SAAd,EAMK/H,kCAAkC,CAAC4B,cAAD,CANvC,CAAd,EAMwE;AAAEiE,UAAAA,WAAW,EAAEhF,OAAO,CAACgF;AAAvB,SANxE,CAAlC,CAAb;AAOH,OARD,CASA,OAAOhD,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OAfD,SAgBQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAhDsE;AAiD1E;;AA/jBiD;AAikBtD;AACA;AACA;;AACA,OAAO,MAAMK,uBAAN,SAAsCvD,kBAAtC,CAAyD;AACtD8D,EAAAA,MAAM,CAACyE,qBAAD,EAAwBnI,OAAO,GAAG,EAAlC,EAAsC;AAAA;AAAA;;AAAA;AAC9C,UAAImI,qBAAqB,KAAK,WAA9B,EAA2C;AACvC,eAAO,qCAAaA,qBAAb,EAAoCnI,OAApC,CAAP;AACH;;AACD,UAAImI,qBAAqB,KAAK,MAA9B,EAAsC;AAClC,cAAMC,SAAS,CAAE,2DAA0DD,qBAAsB,kDAAlF,CAAf;AACH;;AACDnI,MAAAA,OAAO,GAAGmI,qBAAqB,IAAI,EAAnC;AACAnI,MAAAA,OAAO,CAAC4D,UAAR,GAAqB5D,OAAO,CAAC4D,UAAR,IAAsB,EAA3C;AACA,YAAM;AAAE9C,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,gCAAD,EAAmCY,OAAnC,CAA3C;;AACA,UAAI;AACA,qBAAa,qCAAa,WAAb,EAA0B0B,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB3B,OAAlB,CAAd,EAA0C;AAAEuE,UAAAA,cAAc,EAAE7C,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB3B,OAAO,CAACuE,cAA1B,CAAd,EAAyDpF,kCAAkC,CAAC4B,cAAD,CAA3F;AAAlB,SAA1C,CAA1B,CAAb;AACH,OAFD,CAGA,OAAOiB,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OATD,SAUQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAtB6C;AAuBjD;;AACKoB,EAAAA,iBAAiB,CAACiE,qBAAD,EAAwBnI,OAAO,GAAG,EAAlC,EAAsC;AAAA;AAAA;;AAAA;AACzD,UAAImI,qBAAqB,KAAK,MAA9B,EAAsC;AAClC,cAAMC,SAAS,CAAE,sEAAqED,qBAAsB,kDAA7F,CAAf;AACH;;AACD,UAAIA,qBAAqB,KAAK,WAA9B,EAA2C;AACvCnI,QAAAA,OAAO,GAAGmI,qBAAqB,IAAI,EAAnC;AACH;;AACD,YAAM;AAAErH,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,2CAAD,EAA8CY,OAA9C,CAA3C;;AACA,UAAI;AACA,qBAAa,gDAAwB,WAAxB,EAAqC0B,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB3B,OAAlB,CAAd,EAA0C;AAAEuE,UAAAA,cAAc,EAAE7C,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB3B,OAAO,CAACuE,cAA1B,CAAd,EAAyDpF,kCAAkC,CAAC4B,cAAD,CAA3F;AAAlB,SAA1C,CAArC,CAAb;AACH,OAFD,CAGA,OAAOiB,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OATD,SAUQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AApBwD;AAqB5D;AACD;AACJ;AACA;AACA;AACA;;;AACIuF,EAAAA,qBAAqB,CAACC,gBAAD,EAAmB;AACpC,WAAO,IAAInF,uBAAJ,CAA4B9D,eAAe,CAAC,KAAKS,GAAN,EAAWyI,kBAAkB,CAACD,gBAAD,CAA7B,CAA3C,EAA6F,KAAKnI,QAAlG,CAAP;AACH;AACD;AACJ;AACA;AACA;AACA;AACI;;AACA;;;AACAqI,EAAAA,aAAa,CAACC,QAAD,EAAW;AACpB,WAAO,IAAInF,kBAAJ,CAAuBjE,eAAe,CAAC,KAAKS,GAAN,EAAWyI,kBAAkB,CAACE,QAAD,CAA7B,CAAtC,EAAgF,KAAKtI,QAArF,CAAP;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACIuI,EAAAA,cAAc,CAAC1I,OAAD,EAAU;AACpB,WAAO,IAAI2I,OAAJ,CAAaC,OAAD,IAAa;AAC5B,UAAI,EAAE,KAAK3I,UAAL,YAA2BnC,0BAA7B,CAAJ,EAA8D;AAC1D,cAAM8C,UAAU,CAAC,uFAAD,CAAhB;AACH;;AACD,YAAMiI,GAAG,GAAG1K,kCAAkC,CAACuD,MAAM,CAACC,MAAP,CAAc;AAAEoB,QAAAA,cAAc,EAAE,KAAKA,cAAvB;AAAuC+F,QAAAA,QAAQ,EAAE,KAAK7F,IAAtD;AAA4D8F,QAAAA,WAAW,EAAE;AAAzE,OAAd,EAA+F/I,OAA/F,CAAD,EAA0G,KAAKC,UAA/G,CAAlC,CAA6J+I,QAA7J,EAAZ;AACAJ,MAAAA,OAAO,CAACtJ,gBAAgB,CAAC,KAAKQ,GAAN,EAAW+I,GAAX,CAAjB,CAAP;AACH,KANM,CAAP;AAOH;;AApF2D;AAsFhE;AACA;AACA;;AACA,OAAO,MAAMvF,kBAAN,SAAiC1D,kBAAjC,CAAoD;AACvDC,EAAAA,WAAW,CAACC,GAAD,EAAMC,oBAAN,EACX;;AACA;AACAC,EAAAA,OAHW,EAGF;AACL,QAAID,oBAAoB,YAAY7B,QAApC,EAA8C;AAC1C,YAAM4B,GAAN,EAAWC,oBAAX;AACH,KAFD,MAGK;AACD,UAAIE,UAAJ;;AACA,UAAIF,oBAAoB,KAAKG,SAA7B,EAAwC;AACpCD,QAAAA,UAAU,GAAG,IAAIpC,mBAAJ,EAAb;AACH,OAFD,MAGK;AACDoC,QAAAA,UAAU,GAAGF,oBAAb;AACH;;AACD,YAAMI,QAAQ,GAAGlC,WAAW,CAACgC,UAAD,EAAaD,OAAb,CAA5B;AACA,YAAMF,GAAN,EAAWK,QAAX;AACH;;AACD,SAAK8I,mBAAL,GAA2B,IAAIjL,IAAJ,CAAS,KAAKqC,oBAAd,CAA3B;AACA,SAAK6I,uBAAL,GAA+B,IAAIxL,eAAJ,CAAoB,KAAK6C,eAAzB,EAA0C,KAAKJ,QAA/C,CAA/B;AACA,SAAKgJ,iCAAL,GAAyC,IAAInL,IAAJ,CAAS,KAAKoL,kCAAd,CAAzC;AACH;;AACK1F,EAAAA,MAAM,CAACyE,qBAAD,EAAwBnI,OAAO,GAAG,EAAlC,EAAsC;AAAA;AAAA;;AAAA;AAC9C,UAAImI,qBAAqB,KAAK,MAA9B,EAAsC;AAClC,eAAO,sCAAaA,qBAAb,EAAoCnI,OAApC,CAAP;AACH;;AACD,UAAImI,qBAAqB,KAAK,WAA9B,EAA2C;AACvC,cAAMC,SAAS,CAAE,sDAAqDD,qBAAsB,4DAA7E,CAAf;AACH;;AACDnI,MAAAA,OAAO,GAAGmI,qBAAqB,IAAI,EAAnC;AACAnI,MAAAA,OAAO,CAAC4D,UAAR,GAAqB5D,OAAO,CAAC4D,UAAR,IAAsB,EAA3C;AACA,YAAM;AAAE9C,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,2BAAD,EAA8BY,OAA9B,CAA3C;;AACA,UAAI;AACA,qBAAa,sCAAa,MAAb,EAAqB0B,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB3B,OAAlB,CAAd,EAA0C;AAAEuE,UAAAA,cAAc,EAAE7C,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB3B,OAAO,CAACuE,cAA1B,CAAd,EAAyDpF,kCAAkC,CAAC4B,cAAD,CAA3F;AAAlB,SAA1C,CAArB,CAAb;AACH,OAFD,CAGA,OAAOiB,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OATD,SAUQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAtB6C;AAuBjD;;AACKoB,EAAAA,iBAAiB,CAACiE,qBAAD,EAAwBnI,OAAO,GAAG,EAAlC,EAAsC;AAAA;AAAA;;AAAA;AACzD,UAAImI,qBAAqB,KAAK,WAA9B,EAA2C;AACvC,cAAMC,SAAS,CAAE,iEAAgED,qBAAsB,4DAAxF,CAAf;AACH;;AACD,UAAIA,qBAAqB,KAAK,MAA9B,EAAsC;AAClCnI,QAAAA,OAAO,GAAGmI,qBAAqB,IAAI,EAAnC;AACH;;AACD,YAAM;AAAErH,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,sCAAD,EAAyCY,OAAzC,CAA3C;;AACA,UAAI;AACA,qBAAa,iDAAwB,MAAxB,EAAgC0B,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB3B,OAAlB,CAAd,EAA0C;AAAEuE,UAAAA,cAAc,EAAE7C,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB3B,OAAO,CAACuE,cAA1B,CAAd,EAAyDpF,kCAAkC,CAAC4B,cAAD,CAA3F;AAAlB,SAA1C,CAAhC,CAAb;AACH,OAFD,CAGA,OAAOiB,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OATD,SAUQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AApBwD;AAqB5D;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACUuG,EAAAA,IAAI,CAACC,MAAM,GAAG,CAAV,EAAaC,KAAb,EAAoBvJ,OAAO,GAAG,EAA9B,EAAkC;AAAA;;AAAA;AACxC,YAAM;AAAEc,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,yBAAD,EAA4BY,OAA5B,CAA3C;;AACA,UAAI;AACA,cAAMwJ,WAAW,SAAS,OAAI,CAACN,uBAAL,CAA6BO,QAA7B,CAAsCH,MAAtC,EAA8CC,KAA9C,EAAqDxI,cAArD,CAA1B;AACA,cAAMS,QAAQ,GAAGgI,WAAjB;;AACA,YAAI,CAAChM,MAAD,IAAW,CAACgE,QAAQ,CAACkI,aAAzB,EAAwC;AACpClI,UAAAA,QAAQ,CAACkI,aAAT,GAAyBF,WAAW,CAACG,QAArC;AACH;;AACDnI,QAAAA,QAAQ,CAACoI,cAAT,GAA0BJ,WAAW,CAACpD,cAAtC;AACA5E,QAAAA,QAAQ,CAACoD,SAAT,CAAmBD,aAAnB,CAAiCiF,cAAjC,GACIJ,WAAW,CAAC5E,SAAZ,CAAsBD,aAAtB,CAAoCyB,cADxC;AAEA,eAAOoD,WAAW,CAACpD,cAAnB;AACA,eAAOoD,WAAW,CAAC5E,SAAZ,CAAsBD,aAAtB,CAAoCyB,cAA3C;AACA,eAAO5E,QAAP;AACH,OAZD,CAaA,OAAOQ,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OAnBD,SAoBQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAxBuC;AAyB3C;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACU+G,EAAAA,MAAM,CAACC,IAAD,EAAOR,MAAP,EAAehC,MAAf,EAAuBtH,OAAO,GAAG,EAAjC,EAAqC;AAAA;;AAAA;AAC7CA,MAAAA,OAAO,CAAC4D,UAAR,GAAqB5D,OAAO,CAAC4D,UAAR,IAAsB,EAA3C;AACA,YAAM;AAAE9C,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,2BAAD,EAA8BY,OAA9B,CAA3C;;AACA,UAAI;AACA,qBAAa,OAAI,CAACiJ,mBAAL,CAAyBc,UAAzB,CAAoCD,IAApC,EAA0CpI,MAAM,CAACC,MAAP,CAAc;AAAEqI,UAAAA,eAAe,EAAE;AAChF3D,YAAAA,UAAU,EAAErG,OAAO,CAACiK;AAD4D,WAAnB;AAE9DjF,UAAAA,WAAW,EAAEhF,OAAO,CAACgF,WAFyC;AAE5BkF,UAAAA,QAAQ,EAAEZ,MAFkB;AAEVa,UAAAA,aAAa,EAAE7C,MAFL;AAEaxD,UAAAA,qBAAqB,EAAE9D,OAAO,CAAC4D,UAF5C;AAEwDwG,UAAAA,cAAc,EAAE;AACrIC,YAAAA,gBAAgB,EAAErK,OAAO,CAACoC;AAD2G;AAFxE,SAAd,EAI9CjD,kCAAkC,CAAC4B,cAAD,CAJY,CAA1C,CAAb;AAKH,OAND,CAOA,OAAOiB,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OAbD,SAcQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAnB4C;AAoBhD;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACUwH,EAAAA,KAAK,CAACJ,QAAD,EAAWlK,OAAO,GAAG,EAArB,EAAyB;AAAA;;AAAA;AAChCA,MAAAA,OAAO,CAAC4D,UAAR,GAAqB5D,OAAO,CAAC4D,UAAR,IAAsB,EAA3C;AACA,YAAM;AAAE9C,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,0BAAD,EAA6BY,OAA7B,CAA3C;;AACA,UAAI;AACA,qBAAa,OAAI,CAACiJ,mBAAL,CAAyBsB,SAAzB,CAAmC7I,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB3B,OAAlB,CAAd,EAA0C;AAAEkK,UAAAA,QAAF;AAAYC,UAAAA,aAAa,EAAE,CAA3B;AAA8BrG,UAAAA,qBAAqB,EAAE9D,OAAO,CAAC4D,UAA7D;AAAyEG,UAAAA,wBAAwB,EAAE/D,OAAO,CAAC4D;AAA3G,SAA1C,CAAd,EAAkLzE,kCAAkC,CAAC4B,cAAD,CAApN,CAAnC,CAAb;AACH,OAFD,CAGA,OAAOiB,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OATD,SAUQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAf+B;AAgBnC,GAjNsD,CAkNvD;;AACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;;AACU0H,EAAAA,UAAU,CAACC,QAAD,EAChB;;AACA;AACAzK,EAAAA,OAAO,GAAG,EAHM,EAGF;AAAA;;AAAA;AACV,YAAM;AAAEc,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,+BAAD,EAAkCY,OAAlC,CAA3C;;AACA,UAAI;AACA,cAAM0K,IAAI,GAAG,OAAO/K,MAAM,CAAC8K,QAAD,CAAb,EAAyBC,IAAtC;AACA,qBAAa,OAAI,CAACC,sBAAL,CAA4B,CAACrB,MAAD,EAASsB,WAAT,KAAyB;AAC9D,iBAAO,MAAMlL,kBAAkB,CAAC+K,QAAD,EAAW;AACtCI,YAAAA,SAAS,EAAE,IAD2B;AAEtC/H,YAAAA,GAAG,EAAEwG,MAAM,GAAGsB,WAAT,GAAuB,CAFU;AAGtCE,YAAAA,KAAK,EAAExB;AAH+B,WAAX,CAA/B;AAKH,SANY,EAMVoB,IANU,EAMJ3J,cANI,CAAb;AAOH,OATD,CAUA,OAAOiB,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OAhBD,SAiBQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AArBS;AAsBb;AACD;AACJ;AACA;AACA;AACA;AACA;;;AACUiI,EAAAA,MAAM,CAACC,IAAD,EAAOhL,OAAO,GAAG,EAAjB,EAAqB;AAAA;;AAAA;AAC7B,YAAM;AAAEc,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,2BAAD,EAA8BY,OAA9B,CAA3C;;AACA,UAAI;AACA,YAAIxC,MAAJ,EAAY;AACR,cAAIyN,MAAJ;;AACA,cAAID,IAAI,YAAYE,MAApB,EAA4B;AACxBD,YAAAA,MAAM,GAAGD,IAAT;AACH,WAFD,MAGK,IAAIA,IAAI,YAAYG,WAApB,EAAiC;AAClCF,YAAAA,MAAM,GAAGC,MAAM,CAACE,IAAP,CAAYJ,IAAZ,CAAT;AACH,WAFI,MAGA;AACDA,YAAAA,IAAI,GAAGA,IAAP;AACAC,YAAAA,MAAM,GAAGC,MAAM,CAACE,IAAP,CAAYJ,IAAI,CAACC,MAAjB,EAAyBD,IAAI,CAACK,UAA9B,EAA0CL,IAAI,CAACM,UAA/C,CAAT;AACH;;AACD,iBAAO,OAAI,CAACX,sBAAL,CAA4B,CAACrB,MAAD,EAASoB,IAAT,KAAkBO,MAAM,CAACM,KAAP,CAAajC,MAAb,EAAqBA,MAAM,GAAGoB,IAA9B,CAA9C,EAAmFO,MAAM,CAAC3D,MAA1F,EAAkGvG,cAAlG,CAAP;AACH,SAbD,MAcK;AACD,gBAAMyK,WAAW,GAAG,IAAIC,IAAJ,CAAS,CAACT,IAAD,CAAT,CAApB;AACA,iBAAO,OAAI,CAACL,sBAAL,CAA4B,CAACrB,MAAD,EAASoB,IAAT,KAAkBc,WAAW,CAACD,KAAZ,CAAkBjC,MAAlB,EAA0BA,MAAM,GAAGoB,IAAnC,CAA9C,EAAwFc,WAAW,CAACd,IAApG,EAA0G3J,cAA1G,CAAP;AACH;AACJ,OAnBD,CAoBA,OAAOiB,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OA1BD,SA2BQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AA/B4B;AAgChC;;AACK6H,EAAAA,sBAAsB,CAACe,WAAD,EAAchB,IAAd,EAAoB1K,OAAO,GAAG,EAA9B,EAAkC;AAAA;;AAAA;AAC1D,UAAImE,EAAJ;;AACA,YAAM;AAAErD,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,+BAAD,EAAkCY,OAAlC,CAA3C;;AACA,UAAI;AACA,YAAI0K,IAAI,GAAG3L,mBAAX,EAAgC;AAC5B,gBAAM,IAAI6B,UAAJ,CAAgB,mBAAkB7B,mBAAoB,GAAtD,CAAN;AACH,SAHD,CAIA;;;AACA,cAAM4M,SAAS,GAAG,OAAI,CAACjI,MAAL,CAAY;AAC1BsB,UAAAA,WAAW,EAAEhF,OAAO,CAACgF,WADK;AAE1Bf,UAAAA,QAAQ,EAAEjE,OAAO,CAACiE,QAFQ;AAG1B0B,UAAAA,WAAW,EAAE3F,OAAO,CAAC2F,WAHK;AAI1BiG,UAAAA,KAAK,EAAE5L,OAAO,CAAC4L,KAJW;AAK1BhI,UAAAA,UAAU,EAAE5D,OAAO,CAAC4D,UALM;AAM1BoG,UAAAA,eAAe,EAAEhK,OAAO,CAACgK,eANC;AAO1BzF,UAAAA,cAAc,EAAExD,cAAc,CAACwD;AAPL,SAAZ,CAAlB,CALA,CAcA;;;AACA,YAAImG,IAAI,KAAK,CAAb,EAAgB;AACZ,uBAAaiB,SAAb;AACH,SAFD,MAGK;AACD,gBAAMA,SAAN;AACH,SApBD,CAqBA;;;AACA3L,QAAAA,OAAO,CAAC4D,UAAR,GAAqB;AAAE8D,UAAAA,OAAO,EAAE,CAACvD,EAAE,GAAGnE,OAAO,CAAC4D,UAAd,MAA8B,IAA9B,IAAsCO,EAAE,KAAK,KAAK,CAAlD,GAAsD,KAAK,CAA3D,GAA+DA,EAAE,CAACuD;AAA7E,SAArB;;AACA,YAAI,CAAC1H,OAAO,CAAC6L,SAAb,EAAwB;AACpB7L,UAAAA,OAAO,CAAC6L,SAAR,GAAoBC,IAAI,CAACC,IAAL,CAAUrB,IAAI,GAAG/L,qBAAjB,CAApB;;AACA,cAAIqB,OAAO,CAAC6L,SAAR,GAAoB7M,8BAAxB,EAAwD;AACpDgB,YAAAA,OAAO,CAAC6L,SAAR,GAAoB7M,8BAApB;AACH;AACJ;;AACD,YAAIgB,OAAO,CAAC6L,SAAR,GAAoB,CAApB,IAAyB7L,OAAO,CAAC6L,SAAR,GAAoB5M,0BAAjD,EAA6E;AACzE,gBAAM,IAAI2B,UAAJ,CAAgB,wCAAuC3B,0BAA2B,EAAlF,CAAN;AACH;;AACD,YAAI,CAACe,OAAO,CAACgM,cAAb,EAA6B;AACzBhM,UAAAA,OAAO,CAACgM,cAAR,GAAyBpN,8BAAzB;AACH;;AACD,YAAIoB,OAAO,CAACgM,cAAR,IAA0B,CAA9B,EAAiC;AAC7B,gBAAM,IAAIpL,UAAJ,CAAgB,6BAAhB,CAAN;AACH;;AACD,YAAI,CAACZ,OAAO,CAACiM,qBAAb,EAAoC;AAChCjM,UAAAA,OAAO,CAACiM,qBAAR,GAAgCnN,gCAAhC;AACH;;AACD,YAAIkB,OAAO,CAACiM,qBAAR,GAAgC,CAAhC,IACAjM,OAAO,CAACiM,qBAAR,GAAgCnN,gCADpC,EACsE;AAClE,gBAAM,IAAI8B,UAAJ,CAAgB,oDAAmD9B,gCAAiC,EAApG,CAAN;AACH,SA5CD,CA6CA;;;AACA,YAAI4L,IAAI,IAAI1K,OAAO,CAACiM,qBAApB,EAA2C;AACvC,gBAAM,OAAI,CAACpC,MAAL,CAAY6B,WAAW,CAAC,CAAD,EAAIhB,IAAJ,CAAvB,EAAkC,CAAlC,EAAqCA,IAArC,EAA2C;AAC7C1F,YAAAA,WAAW,EAAEhF,OAAO,CAACgF,WADwB;AAE7CpB,YAAAA,UAAU,EAAE5D,OAAO,CAAC4D,UAFyB;AAG7CxB,YAAAA,UAAU,EAAEpC,OAAO,CAACoC,UAHyB;AAI7CmC,YAAAA,cAAc,EAAExD,cAAc,CAACwD;AAJc,WAA3C,CAAN;AAMA,uBAAa,OAAI,CAAC+F,KAAL,CAAWI,IAAX,EAAiB;AAC1B1F,YAAAA,WAAW,EAAEhF,OAAO,CAACgF,WADK;AAE1BpB,YAAAA,UAAU,EAAE5D,OAAO,CAAC4D,UAFM;AAG1BsI,YAAAA,KAAK,EAAElM,OAAO,CAACkM,KAHW;AAI1BlC,YAAAA,eAAe,EAAEhK,OAAO,CAACgK,eAJC;AAK1BzF,YAAAA,cAAc,EAAExD,cAAc,CAACwD;AALL,WAAjB,CAAb;AAOH;;AACD,cAAM4H,SAAS,GAAGL,IAAI,CAACM,KAAL,CAAW,CAAC1B,IAAI,GAAG,CAAR,IAAa1K,OAAO,CAAC6L,SAAhC,IAA6C,CAA/D;;AACA,YAAIM,SAAS,GAAGxN,qBAAhB,EAAuC;AACnC,gBAAM,IAAIiC,UAAJ,CAAgB,2DAAD,GAChB,mCAAkCjC,qBAAsB,EADvD,CAAN;AAEH;;AACD,YAAI0N,gBAAgB,GAAG,CAAvB;AACA,cAAMC,KAAK,GAAG,IAAI5N,KAAJ,CAAUsB,OAAO,CAACgM,cAAlB,CAAd;;AACA,aAAK,IAAIO,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGJ,SAApB,EAA+BI,CAAC,EAAhC,EAAoC;AAChCD,UAAAA,KAAK,CAACE,YAAN,iCAAmB,aAAY;AAC3B,kBAAM1B,KAAK,GAAG9K,OAAO,CAAC6L,SAAR,GAAoBU,CAAlC;AACA,kBAAMzJ,GAAG,GAAGyJ,CAAC,KAAKJ,SAAS,GAAG,CAAlB,GAAsBzB,IAAtB,GAA6BI,KAAK,GAAG9K,OAAO,CAAC6L,SAAzD;AACA,kBAAM1B,aAAa,GAAGrH,GAAG,GAAGgI,KAA5B;AACA,kBAAM,OAAI,CAACjB,MAAL,CAAY6B,WAAW,CAACZ,KAAD,EAAQX,aAAR,CAAvB,EAA+CW,KAA/C,EAAsDX,aAAtD,EAAqE;AACvEnF,cAAAA,WAAW,EAAEhF,OAAO,CAACgF,WADkD;AAEvEpB,cAAAA,UAAU,EAAE5D,OAAO,CAAC4D,UAFmD;AAGvEW,cAAAA,cAAc,EAAExD,cAAc,CAACwD;AAHwC,aAArE,CAAN;AAKA8H,YAAAA,gBAAgB,IAAIlC,aAApB;;AACA,gBAAInK,OAAO,CAACoC,UAAZ,EAAwB;AACpBpC,cAAAA,OAAO,CAACoC,UAAR,CAAmB;AAAEqK,gBAAAA,WAAW,EAAEJ;AAAf,eAAnB;AACH;AACJ,WAbD;AAcH;;AACD,cAAMC,KAAK,CAACI,EAAN,EAAN;AACA,qBAAa,OAAI,CAACpC,KAAL,CAAWI,IAAX,EAAiB;AAC1B1F,UAAAA,WAAW,EAAEhF,OAAO,CAACgF,WADK;AAE1BpB,UAAAA,UAAU,EAAE5D,OAAO,CAAC4D,UAFM;AAG1BsI,UAAAA,KAAK,EAAElM,OAAO,CAACkM,KAHW;AAI1BlC,UAAAA,eAAe,EAAEhK,OAAO,CAACgK,eAJC;AAK1BzF,UAAAA,cAAc,EAAExD,cAAc,CAACwD;AALL,SAAjB,CAAb;AAOH,OA5FD,CA6FA,OAAOvC,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OAnGD,SAoGQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAzGyD;AA0G7D;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACU6J,EAAAA,YAAY,CAACC,MAAD,EAAS5M,OAAO,GAAG,EAAnB,EAAuB;AAAA;;AAAA;AACrC,UAAImE,EAAJ;;AACA,YAAM;AAAErD,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,iCAAD,EAAoCY,OAApC,CAA3C;;AACA,UAAI;AACA;AACA,cAAM,OAAI,CAAC0D,MAAL,CAAY;AACdsB,UAAAA,WAAW,EAAEhF,OAAO,CAACgF,WADP;AAEdf,UAAAA,QAAQ,EAAEjE,OAAO,CAACiE,QAFJ;AAGd0B,UAAAA,WAAW,EAAE3F,OAAO,CAAC2F,WAHP;AAIdiG,UAAAA,KAAK,EAAE5L,OAAO,CAAC4L,KAJD;AAKdhI,UAAAA,UAAU,EAAE5D,OAAO,CAAC4D,UALN;AAMdoG,UAAAA,eAAe,EAAEhK,OAAO,CAACgK,eANX;AAOdzF,UAAAA,cAAc,EAAExD,cAAc,CAACwD;AAPjB,SAAZ,CAAN,CAFA,CAWA;;AACAvE,QAAAA,OAAO,CAAC4D,UAAR,GAAqB;AAAE8D,UAAAA,OAAO,EAAE,CAACvD,EAAE,GAAGnE,OAAO,CAAC4D,UAAd,MAA8B,IAA9B,IAAsCO,EAAE,KAAK,KAAK,CAAlD,GAAsD,KAAK,CAA3D,GAA+DA,EAAE,CAACuD;AAA7E,SAArB;;AACA,YAAI,CAAC1H,OAAO,CAAC6L,SAAb,EAAwB;AACpB7L,UAAAA,OAAO,CAAC6L,SAAR,GAAoB7M,8BAApB;AACH;;AACD,YAAIgB,OAAO,CAAC6L,SAAR,GAAoB,CAApB,IAAyB7L,OAAO,CAAC6L,SAAR,GAAoB5M,0BAAjD,EAA6E;AACzE,gBAAM,IAAI2B,UAAJ,CAAgB,wCAAuC3B,0BAA2B,EAAlF,CAAN;AACH;;AACD,YAAI,CAACe,OAAO,CAACgM,cAAb,EAA6B;AACzBhM,UAAAA,OAAO,CAACgM,cAAR,GAAyBpN,8BAAzB;AACH;;AACD,YAAIoB,OAAO,CAACgM,cAAR,IAA0B,CAA9B,EAAiC;AAC7B,gBAAM,IAAIpL,UAAJ,CAAgB,6BAAhB,CAAN;AACH;;AACD,YAAIyL,gBAAgB,GAAG,CAAvB;AACA,cAAMQ,SAAS,GAAG,IAAIjP,eAAJ,CAAoBgP,MAApB,EAA4B5M,OAAO,CAAC6L,SAApC,EAA+C7L,OAAO,CAACgM,cAAvD;AAAA,wCAAuE,WAAOlC,IAAP,EAAaxC,MAAb,EAAqBgC,MAArB,EAAgC;AACrH,kBAAM,OAAI,CAACO,MAAL,CAAYC,IAAZ,EAAkBR,MAAlB,EAA0BhC,MAA1B,EAAkC;AACpCtC,cAAAA,WAAW,EAAEhF,OAAO,CAACgF,WADe;AAEpCpB,cAAAA,UAAU,EAAE5D,OAAO,CAAC4D,UAFgB;AAGpCW,cAAAA,cAAc,EAAExD,cAAc,CAACwD;AAHK,aAAlC,CAAN,CADqH,CAMrH;;AACA8H,YAAAA,gBAAgB,IAAI/E,MAApB;;AACA,gBAAItH,OAAO,CAACoC,UAAZ,EAAwB;AACpBpC,cAAAA,OAAO,CAACoC,UAAR,CAAmB;AAAEqK,gBAAAA,WAAW,EAAEJ;AAAf,eAAnB;AACH;AACJ,WAXiB;;AAAA;AAAA;AAAA;AAAA,aAYlB;AACA;AACA;AACA;AACAP,QAAAA,IAAI,CAACC,IAAL,CAAW/L,OAAO,CAACgM,cAAR,GAAyB,CAA1B,GAA+B,CAAzC,CAhBkB,CAAlB;AAiBA,cAAMa,SAAS,CAACH,EAAV,EAAN;AACA,qBAAa,OAAI,CAACpC,KAAL,CAAW+B,gBAAX,EAA6B;AACtCrH,UAAAA,WAAW,EAAEhF,OAAO,CAACgF,WADiB;AAEtCpB,UAAAA,UAAU,EAAE5D,OAAO,CAAC4D,UAFkB;AAGtCsI,UAAAA,KAAK,EAAElM,OAAO,CAACkM,KAHuB;AAItClC,UAAAA,eAAe,EAAEhK,OAAO,CAACgK,eAJa;AAKtCzF,UAAAA,cAAc,EAAExD,cAAc,CAACwD;AALO,SAA7B,CAAb;AAOH,OAnDD,CAoDA,OAAOvC,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OA1DD,SA2DQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAhEoC;AAiExC;;AACKgK,EAAAA,YAAY,CAACC,cAAD,EAAiBC,aAAjB,EAAgCC,cAAhC,EAAgDC,UAAU,GAAG,EAA7D,EAAiE;AAAA;;AAAA;AAC/E,UAAIjC,MAAM,GAAG/K,SAAb;AACA,UAAIoJ,MAAM,GAAG,CAAb;AACA,UAAIC,KAAK,GAAG,CAAZ;AACA,UAAIvJ,OAAO,GAAGkN,UAAd;;AACA,UAAIH,cAAc,YAAY7B,MAA9B,EAAsC;AAClCD,QAAAA,MAAM,GAAG8B,cAAT;AACAzD,QAAAA,MAAM,GAAG0D,aAAa,IAAI,CAA1B;AACAzD,QAAAA,KAAK,GAAG,OAAO0D,cAAP,KAA0B,QAA1B,GAAqCA,cAArC,GAAsD,CAA9D;AACH,OAJD,MAKK;AACD3D,QAAAA,MAAM,GAAG,OAAOyD,cAAP,KAA0B,QAA1B,GAAqCA,cAArC,GAAsD,CAA/D;AACAxD,QAAAA,KAAK,GAAG,OAAOyD,aAAP,KAAyB,QAAzB,GAAoCA,aAApC,GAAoD,CAA5D;AACAhN,QAAAA,OAAO,GAAGiN,cAAc,IAAI,EAA5B;AACH;;AACD,YAAM;AAAEnM,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,iCAAD,EAAoCY,OAApC,CAA3C;;AACA,UAAI;AACA,YAAIiL,MAAJ,EAAY;AACR,uBAAa,OAAI,CAAC/B,uBAAL,CAA6BiE,gBAA7B,CAA8ClC,MAA9C,EAAsD3B,MAAtD,EAA8DC,KAA9D,EAAqE7H,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB3B,OAAlB,CAAd,EAA0C;AAAEoN,YAAAA,wBAAwB,EAAEpN,OAAO,CAACqN,wBAApC;AAA8DC,YAAAA,SAAS,EAAEtN,OAAO,CAAC6L,SAAjF;AAA4FtH,YAAAA,cAAc,EAAExD,cAAc,CAACwD;AAA3H,WAA1C,CAArE,CAAb;AACH,SAFD,MAGK;AACD,uBAAa,OAAI,CAAC2E,uBAAL,CAA6BiE,gBAA7B,CAA8C7D,MAA9C,EAAsDC,KAAtD,EAA6D7H,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB3B,OAAlB,CAAd,EAA0C;AAAEoN,YAAAA,wBAAwB,EAAEpN,OAAO,CAACqN,wBAApC;AAA8DC,YAAAA,SAAS,EAAEtN,OAAO,CAAC6L,SAAjF;AAA4FtH,YAAAA,cAAc,EAAExD,cAAc,CAACwD;AAA3H,WAA1C,CAA7D,CAAb;AACH;AACJ,OAPD,CAQA,OAAOvC,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OAdD,SAeQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAjC8E;AAkClF;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACUyK,EAAAA,UAAU,CAAC9C,QAAD,EAAWnB,MAAM,GAAG,CAApB,EAAuBC,KAAvB,EAA8BvJ,OAAO,GAAG,EAAxC,EAA4C;AAAA;;AAAA;AACxD,YAAM;AAAEc,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,+BAAD,EAAkCY,OAAlC,CAA3C;;AACA,UAAI;AACA,qBAAa,OAAI,CAACkJ,uBAAL,CAA6BsE,cAA7B,CAA4C/C,QAA5C,EAAsDnB,MAAtD,EAA8DC,KAA9D,EAAqExI,cAArE,CAAb;AACH,OAFD,CAGA,OAAOiB,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OATD,SAUQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAduD;AAe3D;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACU2K,EAAAA,KAAK,CAACA,KAAD,EAAQzN,OAAO,GAAG,EAAlB,EAAsB;AAAA;;AAAA;AAC7B,YAAM;AAAEc,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,0BAAD,EAA6BY,OAA7B,CAA3C;;AACA,UAAI;AACA,cAAMwJ,WAAW,SAAS,OAAI,CAACN,uBAAL,CAA6BuE,KAA7B,CAAmCA,KAAnC,EAA0C1M,cAA1C,CAA1B;AACA,cAAMS,QAAQ,GAAGgI,WAAjB;;AACA,YAAI,CAAChM,MAAD,IAAW,CAACgE,QAAQ,CAACkI,aAAzB,EAAwC;AACpClI,UAAAA,QAAQ,CAACkI,aAAT,GAAyBF,WAAW,CAACG,QAArC;AACH;;AACDnI,QAAAA,QAAQ,CAACoI,cAAT,GAA0BJ,WAAW,CAACpD,cAAtC;AACA5E,QAAAA,QAAQ,CAACoD,SAAT,CAAmBD,aAAnB,CAAiCiF,cAAjC,GACIJ,WAAW,CAAC5E,SAAZ,CAAsBD,aAAtB,CAAoCyB,cADxC;AAEA,eAAOoD,WAAW,CAACpD,cAAnB;AACA,eAAOoD,WAAW,CAAC5E,SAAZ,CAAsBD,aAAtB,CAAoCyB,cAA3C;AACA,eAAO5E,QAAP;AACH,OAZD,CAaA,OAAOQ,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OAnBD,SAoBQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAxB4B;AAyBhC;AACD;AACJ;AACA;AACA;AACA;AACA;;;AACU4K,EAAAA,SAAS,CAACjN,IAAD,EAAOT,OAAO,GAAG,EAAjB,EAAqB;AAAA;;AAAA;AAChC,UAAImE,EAAJ;;AACA,YAAM;AAAErD,QAAAA,IAAF;AAAQC,QAAAA;AAAR,UAA2B3B,UAAU,CAAC,8BAAD,EAAiCY,OAAjC,CAA3C;;AACA,UAAI;AACA,YAAI2N,SAAS,GAAGzN,SAAhB;;AACA,YAAIO,IAAI,KAAK,eAAT,IAA4BA,IAAI,KAAK,oBAAzC,EAA+D;AAC3D,cAAI,CAACT,OAAO,CAAC4N,gBAAb,EAA+B;AAC3B,kBAAM,IAAIC,KAAJ,CAAW,2DAA0DpN,IAAK,GAA1E,CAAN;AACH,WAH0D,CAI3D;;;AACAkN,UAAAA,SAAS,GAAG7B,IAAI,CAACgC,KAAL,CAAW9N,OAAO,CAAC4N,gBAAnB,EAAqC5E,QAArC,EAAZ;AACH;;AACD,YAAIvI,IAAI,KAAK,UAAb,EAAyB;AACrB,cAAI,CAACT,OAAO,CAAC2N,SAAb,EAAwB;AACpB,kBAAM,IAAIE,KAAJ,CAAW,oDAAmDpN,IAAK,GAAnE,CAAN;AACH;;AACD,gBAAMsN,GAAG,GAAG,IAAIC,IAAJ,EAAZ;;AACA,cAAI,EAAEhO,OAAO,CAAC2N,SAAR,CAAkBM,OAAlB,KAA8BF,GAAG,CAACE,OAAJ,EAAhC,CAAJ,EAAoD;AAChD,kBAAM,IAAIJ,KAAJ,CAAW,+CAA8CE,GAAG,CAACG,WAAJ,EAAkB,oBAAmBzN,IAAK,YAAW,CAAC0D,EAAE,GAAGnE,OAAO,CAAC2N,SAAd,MAA6B,IAA7B,IAAqCxJ,EAAE,KAAK,KAAK,CAAjD,GAAqD,KAAK,CAA1D,GAA8DA,EAAE,CAAC+J,WAAH,EAAiB,EAA7L,CAAN;AACH;;AACDP,UAAAA,SAAS,GAAG3N,OAAO,CAAC2N,SAAR,CAAkBO,WAAlB,EAAZ;AACH;;AACD,cAAMC,cAAc,GAAGzM,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB3B,OAAlB,CAAd,EAA0C;AAAE2N,UAAAA;AAAF,SAA1C,CAAvB;AACA,qBAAa,OAAI,CAACxE,iCAAL,CAAuCuE,SAAvC,CAAiDjN,IAAjD,EAAuDiB,MAAM,CAACC,MAAP,CAAcD,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkBwM,cAAlB,CAAd,EAAiD;AAAE5J,UAAAA,cAAc,EAAExD,cAAc,CAACwD;AAAjC,SAAjD,CAAvD,CAAb;AACH,OArBD,CAsBA,OAAOvC,CAAP,EAAU;AACNlB,QAAAA,IAAI,CAAC4B,SAAL,CAAe;AACXC,UAAAA,IAAI,EAAEhF,cAAc,CAACiF,KADV;AAEXC,UAAAA,OAAO,EAAEb,CAAC,CAACa;AAFA,SAAf;AAIA,cAAMb,CAAN;AACH,OA5BD,SA6BQ;AACJlB,QAAAA,IAAI,CAACgC,GAAL;AACH;AAlC+B;AAmCnC;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACI4F,EAAAA,cAAc,CAAC1I,OAAD,EAAU;AACpB,WAAO,IAAI2I,OAAJ,CAAaC,OAAD,IAAa;AAC5B,UAAI,EAAE,KAAK3I,UAAL,YAA2BnC,0BAA7B,CAAJ,EAA8D;AAC1D,cAAM8C,UAAU,CAAC,uFAAD,CAAhB;AACH;;AACD,YAAMiI,GAAG,GAAG1K,kCAAkC,CAACuD,MAAM,CAACC,MAAP,CAAc;AAAEoB,QAAAA,cAAc,EAAE,KAAKA,cAAvB;AAAuC+F,QAAAA,QAAQ,EAAE,KAAK7F;AAAtD,OAAd,EAA4EjD,OAA5E,CAAD,EAAuF,KAAKC,UAA5F,CAAlC,CAA0I+I,QAA1I,EAAZ;AACAJ,MAAAA,OAAO,CAACtJ,gBAAgB,CAAC,KAAKQ,GAAN,EAAW+I,GAAX,CAAjB,CAAP;AACH,KANM,CAAP;AAOH;;AA9oBsD,C,CAgpB3D","sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\nimport { isNode } from \"@azure/core-http\";\nimport { BlobClient, BlockBlobClient } from \"@azure/storage-blob\";\nimport { SpanStatusCode } from \"@azure/core-tracing\";\nimport { BufferScheduler } from \"../../storage-common/src\";\nimport { AnonymousCredential } from \"./credentials/AnonymousCredential\";\nimport { StorageSharedKeyCredential } from \"./credentials/StorageSharedKeyCredential\";\nimport { DataLakeLeaseClient } from \"./DataLakeLeaseClient\";\nimport { Path } from \"./generated/src/operations\";\nimport { newPipeline, Pipeline } from \"./Pipeline\";\nimport { generateDataLakeSASQueryParameters } from \"./sas/DataLakeSASSignatureValues\";\nimport { StorageClient } from \"./StorageClient\";\nimport { toAccessControlChangeFailureArray, toAclString, toPathGetAccessControlResponse, toPermissionsString, toProperties } from \"./transforms\";\nimport { Batch } from \"./utils/Batch\";\nimport { BLOCK_BLOB_MAX_BLOCKS, DEFAULT_HIGH_LEVEL_CONCURRENCY, ETagAny, FILE_MAX_SINGLE_UPLOAD_THRESHOLD, FILE_MAX_SIZE_BYTES, FILE_UPLOAD_DEFAULT_CHUNK_SIZE, FILE_UPLOAD_MAX_CHUNK_SIZE } from \"./utils/constants\";\nimport { DataLakeAclChangeFailedError } from \"./utils/DataLakeAclChangeFailedError\";\nimport { convertTracingToRequestOptionsBase, createSpan } from \"./utils/tracing\";\nimport { appendToURLPath, appendToURLQuery, getURLPathAndQuery, setURLPath, setURLQueries } from \"./utils/utils.common\";\nimport { fsCreateReadStream, fsStat } from \"./utils/utils.node\";\n/**\n * A DataLakePathClient represents a URL to the Azure Storage path (directory or file).\n */\nexport class DataLakePathClient extends StorageClient {\n    constructor(url, credentialOrPipeline, \n    // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.\n    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options */\n    options) {\n        if (credentialOrPipeline instanceof Pipeline) {\n            super(url, credentialOrPipeline);\n        }\n        else {\n            let credential;\n            if (credentialOrPipeline === undefined) {\n                credential = new AnonymousCredential();\n            }\n            else {\n                credential = credentialOrPipeline;\n            }\n            const pipeline = newPipeline(credential, options);\n            super(url, pipeline);\n        }\n        this.pathContext = new Path(this.storageClientContext);\n        this.blobClient = new BlobClient(this.blobEndpointUrl, this.pipeline);\n    }\n    /**\n     * SetAccessControlRecursiveInternal operation sets the Access Control on a path and sub paths.\n     *\n     * @param mode - Mode \\\"set\\\" sets POSIX access control rights on files and directories,\n     *                                                 Mode \\\"modify\\\" modifies one or more POSIX access control rights that pre-exist on files and directories,\n     *                                                 Mode \\\"remove\\\" removes one or more POSIX access control rights that were present earlier on files and directories.\n     * @param acl - The POSIX access control list for the file or directory.\n     * @param options - Optional. Options\n     */\n    async setAccessControlRecursiveInternal(mode, acl, options = {}) {\n        if (options.maxBatches !== undefined && options.maxBatches < 1) {\n            throw RangeError(`Options maxBatches must be larger than 0.`);\n        }\n        if (options.batchSize !== undefined && options.batchSize < 1) {\n            throw RangeError(`Options batchSize must be larger than 0.`);\n        }\n        const { span, updatedOptions } = createSpan(`DataLakePathClient-setAccessControlRecursiveInternal`, options);\n        const result = {\n            counters: {\n                failedChangesCount: 0,\n                changedDirectoriesCount: 0,\n                changedFilesCount: 0\n            },\n            continuationToken: undefined\n        };\n        try {\n            let continuationToken = options.continuationToken;\n            let batchCounter = 0;\n            let reachMaxBatches = false;\n            do {\n                let response;\n                try {\n                    response = await this.pathContext.setAccessControlRecursive(mode, Object.assign(Object.assign(Object.assign({}, options), { acl: toAclString(acl), maxRecords: options.batchSize, continuation: continuationToken, forceFlag: options.continueOnFailure }), convertTracingToRequestOptionsBase(updatedOptions)));\n                }\n                catch (e) {\n                    throw new DataLakeAclChangeFailedError(e, continuationToken);\n                }\n                batchCounter++;\n                continuationToken = response.continuation;\n                // Update result\n                result.continuationToken = continuationToken;\n                result.counters.failedChangesCount += response.failureCount || 0;\n                result.counters.changedDirectoriesCount += response.directoriesSuccessful || 0;\n                result.counters.changedFilesCount += response.filesSuccessful || 0;\n                // Progress event call back\n                if (options.onProgress) {\n                    const progress = {\n                        batchFailures: toAccessControlChangeFailureArray(response.failedEntries),\n                        batchCounters: {\n                            failedChangesCount: response.failureCount || 0,\n                            changedDirectoriesCount: response.directoriesSuccessful || 0,\n                            changedFilesCount: response.filesSuccessful || 0\n                        },\n                        aggregateCounters: result.counters,\n                        continuationToken: continuationToken\n                    };\n                    options.onProgress(progress);\n                }\n                reachMaxBatches =\n                    options.maxBatches === undefined ? false : batchCounter >= options.maxBatches;\n            } while (continuationToken && !reachMaxBatches);\n            return result;\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Name of current file system.\n     *\n     * @readonly\n     */\n    get fileSystemName() {\n        return this.blobClient.containerName;\n    }\n    /**\n     * Name of current path (directory or file).\n     *\n     * @readonly\n     */\n    get name() {\n        return this.blobClient.name;\n    }\n    /**\n     * Convert current DataLakePathClient to DataLakeDirectoryClient if current path is a directory.\n     *\n     */\n    // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.\n    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-subclients */\n    toDirectoryClient() {\n        return new DataLakeDirectoryClient(this.dfsEndpointUrl, this.pipeline);\n    }\n    /**\n     * Convert current DataLakePathClient to DataLakeFileClient if current path is a file.\n     *\n     */\n    // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.\n    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-subclients */\n    toFileClient() {\n        return new DataLakeFileClient(this.dfsEndpointUrl, this.pipeline);\n    }\n    /**\n     * Get a {@link DataLakeLeaseClient} that manages leases on the path (directory or file).\n     *\n     * @param proposeLeaseId - Optional. Initial proposed lease Id.\n     */\n    getDataLakeLeaseClient(proposeLeaseId) {\n        return new DataLakeLeaseClient(this.blobClient.getBlobLeaseClient(proposeLeaseId));\n    }\n    /**\n     * Create a directory or path.\n     *\n     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create\n     *\n     * @param resourceType - Resource type, \"directory\" or \"file\".\n     * @param options - Optional. Options when creating path.\n     */\n    async create(resourceType, options = {}) {\n        options.conditions = options.conditions || {};\n        const { span, updatedOptions } = createSpan(\"DataLakePathClient-create\", options);\n        try {\n            return await this.pathContext.create(Object.assign(Object.assign(Object.assign({}, options), { resource: resourceType, leaseAccessConditions: options.conditions, modifiedAccessConditions: options.conditions, properties: toProperties(options.metadata) }), convertTracingToRequestOptionsBase(updatedOptions)));\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Create a directory or file. If the resource already exists, it is not changed.\n     *\n     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create\n     *\n     * @param resourceType - Resource type, \"directory\" or \"file\".\n     * @param options -\n     */\n    async createIfNotExists(resourceType, options = {}) {\n        var _a, _b;\n        const { span, updatedOptions } = createSpan(\"DataLakePathClient-createIfNotExists\", options);\n        try {\n            const conditions = { ifNoneMatch: ETagAny };\n            const res = await this.create(resourceType, Object.assign(Object.assign({}, options), { conditions, tracingOptions: updatedOptions.tracingOptions }));\n            return Object.assign({ succeeded: true }, res);\n        }\n        catch (e) {\n            if (((_a = e.details) === null || _a === void 0 ? void 0 : _a.errorCode) === \"PathAlreadyExists\") {\n                span.setStatus({\n                    code: SpanStatusCode.ERROR,\n                    message: \"Expected exception when creating a blob only if it does not already exist.\"\n                });\n                return Object.assign(Object.assign({ succeeded: false }, (_b = e.response) === null || _b === void 0 ? void 0 : _b.parsedHeaders), { _response: e.response });\n            }\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Returns true if the Data Lake file represented by this client exists; false otherwise.\n     *\n     * NOTE: use this function with care since an existing file might be deleted by other clients or\n     * applications. Vice versa new files might be added by other clients or applications after this\n     * function completes.\n     *\n     * @param options - options to Exists operation.\n     */\n    async exists(options = {}) {\n        const { span, updatedOptions } = createSpan(\"DataLakeFileClient-exists\", options);\n        try {\n            return await this.blobClient.exists(updatedOptions);\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Delete current path (directory or file).\n     *\n     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete\n     *\n     * @param recursive - Required and valid only when the resource is a directory. If \"true\", all paths beneath the directory will be deleted.\n     * @param options - Optional. Options when deleting path.\n     */\n    async delete(recursive, options = {}) {\n        options.conditions = options.conditions || {};\n        const { span, updatedOptions } = createSpan(\"DataLakePathClient-delete\", options);\n        try {\n            let continuation;\n            let response;\n            // How to handle long delete loop?\n            do {\n                response = await this.pathContext.delete(Object.assign(Object.assign({ continuation,\n                    recursive, leaseAccessConditions: options.conditions, modifiedAccessConditions: options.conditions }, convertTracingToRequestOptionsBase(updatedOptions)), { abortSignal: options.abortSignal }));\n                continuation = response.continuation;\n            } while (continuation !== undefined && continuation !== \"\");\n            return response;\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Delete current path (directory or file) if it exists.\n     *\n     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete\n     *\n     * @param recursive - Required and valid only when the resource is a directory. If \"true\", all paths beneath the directory will be deleted.\n     * @param options -\n     */\n    async deleteIfExists(recursive, options = {}) {\n        var _a, _b;\n        options.conditions = options.conditions || {};\n        const { span, updatedOptions } = createSpan(\"DataLakePathClient-deleteIfExists\", options);\n        try {\n            const res = await this.delete(recursive, updatedOptions);\n            return Object.assign({ succeeded: true }, res);\n        }\n        catch (e) {\n            if (((_a = e.details) === null || _a === void 0 ? void 0 : _a.errorCode) === \"PathNotFound\") {\n                span.setStatus({\n                    code: SpanStatusCode.ERROR,\n                    message: \"Expected exception when deleting a directory or file only if it exists.\"\n                });\n                return Object.assign(Object.assign({ succeeded: false }, (_b = e.response) === null || _b === void 0 ? void 0 : _b.parsedHeaders), { _response: e.response });\n            }\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Returns the access control data for a path (directory of file).\n     *\n     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/getproperties\n     *\n     * @param options - Optional. Options when getting file access control.\n     */\n    async getAccessControl(options = {}) {\n        options.conditions = options.conditions || {};\n        const { span, updatedOptions } = createSpan(\"DataLakePathClient-getAccessControl\", options);\n        try {\n            const response = await this.pathContext.getProperties(Object.assign(Object.assign({ action: \"getAccessControl\", upn: options.userPrincipalName, leaseAccessConditions: options.conditions, modifiedAccessConditions: options.conditions }, convertTracingToRequestOptionsBase(updatedOptions)), { abortSignal: options.abortSignal }));\n            return toPathGetAccessControlResponse(response);\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Set the access control data for a path (directory of file).\n     *\n     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update\n     *\n     * @param acl - The POSIX access control list for the file or directory.\n     * @param options - Optional. Options when setting path access control.\n     */\n    async setAccessControl(acl, options = {}) {\n        options.conditions = options.conditions || {};\n        const { span, updatedOptions } = createSpan(\"DataLakePathClient-setAccessControl\", options);\n        try {\n            return await this.pathContext.setAccessControl(Object.assign(Object.assign(Object.assign({}, options), { acl: toAclString(acl), leaseAccessConditions: options.conditions, modifiedAccessConditions: options.conditions }), convertTracingToRequestOptionsBase(updatedOptions)));\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Sets the Access Control on a path and sub paths.\n     *\n     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update\n     *\n     * @param acl - The POSIX access control list for the file or directory.\n     * @param options - Optional. Options\n     */\n    async setAccessControlRecursive(acl, options = {}) {\n        const { span, updatedOptions } = createSpan(\"DataLakePathClient-setAccessControlRecursive\", options);\n        try {\n            return this.setAccessControlRecursiveInternal(\"set\", acl, updatedOptions);\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Modifies the Access Control on a path and sub paths.\n     *\n     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update\n     *\n     * @param acl - The POSIX access control list for the file or directory.\n     * @param options - Optional. Options\n     */\n    async updateAccessControlRecursive(acl, options = {}) {\n        const { span, updatedOptions } = createSpan(\"DataLakePathClient-updateAccessControlRecursive\", options);\n        try {\n            return this.setAccessControlRecursiveInternal(\"modify\", acl, updatedOptions);\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Removes the Access Control on a path and sub paths.\n     *\n     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update\n     *\n     * @param acl - The POSIX access control list for the file or directory.\n     * @param options - Optional. Options\n     */\n    async removeAccessControlRecursive(acl, options = {}) {\n        const { span, updatedOptions } = createSpan(\"DataLakePathClient-removeAccessControlRecursive\", options);\n        try {\n            return this.setAccessControlRecursiveInternal(\"remove\", acl, updatedOptions);\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Sets the file permissions on a path.\n     *\n     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update\n     *\n     * @param permissions - The POSIX access permissions for the file owner, the file owning group, and others.\n     * @param options - Optional. Options when setting path permissions.\n     */\n    async setPermissions(permissions, options = {}) {\n        options.conditions = options.conditions || {};\n        const { span, updatedOptions } = createSpan(\"DataLakePathClient-setPermissions\", options);\n        try {\n            return await this.pathContext.setAccessControl(Object.assign(Object.assign(Object.assign({}, options), { permissions: toPermissionsString(permissions), leaseAccessConditions: options.conditions, modifiedAccessConditions: options.conditions }), convertTracingToRequestOptionsBase(updatedOptions)));\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Returns all user-defined metadata, standard HTTP properties, and system properties\n     * for the path (directory or file).\n     *\n     * WARNING: The `metadata` object returned in the response will have its keys in lowercase, even if\n     * they originally contained uppercase characters. This differs from the metadata keys returned by\n     * the methods of {@link DataLakeFileSystemClient} that list paths using the `includeMetadata` option, which\n     * will retain their original casing.\n     *\n     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob-properties\n     *\n     * @param options - Optional. Options when getting path properties.\n     */\n    async getProperties(options = {}) {\n        const { span, updatedOptions } = createSpan(\"DataLakePathClient-getProperties\", options);\n        try {\n            return await this.blobClient.getProperties(Object.assign(Object.assign({}, options), { customerProvidedKey: undefined, tracingOptions: updatedOptions.tracingOptions }));\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Sets system properties on the path (directory or file).\n     *\n     * If no value provided, or no value provided for the specified blob HTTP headers,\n     * these blob HTTP headers without a value will be cleared.\n     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-blob-properties\n     *\n     * @param httpHeaders -\n     * @param options -\n     */\n    async setHttpHeaders(httpHeaders, options = {}) {\n        const { span, updatedOptions } = createSpan(\"DataLakePathClient-setHttpHeaders\", options);\n        try {\n            return await this.blobClient.setHTTPHeaders({\n                blobCacheControl: httpHeaders.cacheControl,\n                blobContentType: httpHeaders.contentType,\n                blobContentMD5: httpHeaders.contentMD5,\n                blobContentEncoding: httpHeaders.contentEncoding,\n                blobContentLanguage: httpHeaders.contentLanguage,\n                blobContentDisposition: httpHeaders.contentDisposition\n            }, updatedOptions);\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Sets user-defined metadata for the specified path (directory of file) as one or more name-value pairs.\n     *\n     * If no option provided, or no metadata defined in the parameter, the path\n     * metadata will be removed.\n     *\n     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-blob-metadata\n     *\n     * @param metadata - Optional. Replace existing metadata with this value.\n     *                              If no value provided the existing metadata will be removed.\n     * @param options - Optional. Options when setting path metadata.\n     */\n    async setMetadata(metadata, options = {}) {\n        const { span, updatedOptions } = createSpan(\"DataLakePathClient-setMetadata\", options);\n        try {\n            return await this.blobClient.setMetadata(metadata, Object.assign(Object.assign({}, options), { customerProvidedKey: undefined, tracingOptions: updatedOptions.tracingOptions }));\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    async move(destinationPathOrFileSystem, destinationPathOrOptions, options) {\n        let destinationFileSystem = this.fileSystemName;\n        let destinationPath = destinationPathOrFileSystem;\n        if (typeof destinationPathOrOptions === \"string\") {\n            destinationFileSystem = destinationPathOrFileSystem;\n            destinationPath = destinationPathOrOptions;\n            options = options || {};\n        }\n        else {\n            options = destinationPathOrOptions || {};\n        }\n        options.conditions = options.conditions || {};\n        options.destinationConditions = options.destinationConditions || {};\n        const { span, updatedOptions } = createSpan(\"DataLakePathClient-move\", options);\n        const renameSource = getURLPathAndQuery(this.dfsEndpointUrl);\n        const split = destinationPath.split(\"?\");\n        let destinationUrl;\n        if (split.length === 2) {\n            const renameDestination = `/${destinationFileSystem}/${split[0]}`;\n            destinationUrl = setURLPath(this.dfsEndpointUrl, renameDestination);\n            destinationUrl = setURLQueries(destinationUrl, split[1]);\n        }\n        else if (split.length === 1) {\n            const renameDestination = `/${destinationFileSystem}/${destinationPath}`;\n            destinationUrl = setURLPath(this.dfsEndpointUrl, renameDestination);\n        }\n        else {\n            throw new RangeError(\"Destination path should not contain more than one query string\");\n        }\n        const destPathClient = new DataLakePathClient(destinationUrl, this.pipeline);\n        try {\n            return await destPathClient.pathContext.create(Object.assign(Object.assign({ mode: \"legacy\", // By default\n                renameSource, sourceLeaseId: options.conditions.leaseId, leaseAccessConditions: options.destinationConditions, sourceModifiedAccessConditions: {\n                    sourceIfMatch: options.conditions.ifMatch,\n                    sourceIfNoneMatch: options.conditions.ifNoneMatch,\n                    sourceIfModifiedSince: options.conditions.ifModifiedSince,\n                    sourceIfUnmodifiedSince: options.conditions.ifUnmodifiedSince\n                }, modifiedAccessConditions: options.destinationConditions }, convertTracingToRequestOptionsBase(updatedOptions)), { abortSignal: options.abortSignal }));\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n}\n/**\n * A DataLakeDirectoryClient represents a URL to the Azure Storage directory.\n */\nexport class DataLakeDirectoryClient extends DataLakePathClient {\n    async create(resourceTypeOrOptions, options = {}) {\n        if (resourceTypeOrOptions === \"directory\") {\n            return super.create(resourceTypeOrOptions, options);\n        }\n        if (resourceTypeOrOptions === \"file\") {\n            throw TypeError(`DataLakeDirectoryClient:create() resourceType cannot be ${resourceTypeOrOptions}. Refer to DataLakeFileClient for file creation.`);\n        }\n        options = resourceTypeOrOptions || {};\n        options.conditions = options.conditions || {};\n        const { span, updatedOptions } = createSpan(\"DataLakeDirectoryClient-create\", options);\n        try {\n            return await super.create(\"directory\", Object.assign(Object.assign({}, options), { tracingOptions: Object.assign(Object.assign({}, options.tracingOptions), convertTracingToRequestOptionsBase(updatedOptions)) }));\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    async createIfNotExists(resourceTypeOrOptions, options = {}) {\n        if (resourceTypeOrOptions === \"file\") {\n            throw TypeError(`DataLakeDirectoryClient:createIfNotExists() resourceType cannot be ${resourceTypeOrOptions}. Refer to DataLakeFileClient for file creation.`);\n        }\n        if (resourceTypeOrOptions !== \"directory\") {\n            options = resourceTypeOrOptions || {};\n        }\n        const { span, updatedOptions } = createSpan(\"DataLakeDirectoryClient-createIfNotExists\", options);\n        try {\n            return await super.createIfNotExists(\"directory\", Object.assign(Object.assign({}, options), { tracingOptions: Object.assign(Object.assign({}, options.tracingOptions), convertTracingToRequestOptionsBase(updatedOptions)) }));\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Creates a {@link DataLakeDirectoryClient} object under current directory.\n     *\n     * @param subdirectoryName - Subdirectory name.\n     */\n    getSubdirectoryClient(subdirectoryName) {\n        return new DataLakeDirectoryClient(appendToURLPath(this.url, encodeURIComponent(subdirectoryName)), this.pipeline);\n    }\n    /**\n     * Creates a {@link DataLakeFileClient} object under current directory.\n     *\n     * @param fileName -\n     */\n    // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.\n    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-subclients */\n    getFileClient(fileName) {\n        return new DataLakeFileClient(appendToURLPath(this.url, encodeURIComponent(fileName)), this.pipeline);\n    }\n    /**\n     * Only available for clients constructed with a shared key credential.\n     *\n     * Generates a Service Shared Access Signature (SAS) URI based on the client properties\n     * and parameters passed in. The SAS is signed by the shared key credential of the client.\n     *\n     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas\n     *\n     * @param options - Optional parameters.\n     * @returns The SAS URI consisting of the URI to the resource represented by this client, followed by the generated SAS token.\n     */\n    generateSasUrl(options) {\n        return new Promise((resolve) => {\n            if (!(this.credential instanceof StorageSharedKeyCredential)) {\n                throw RangeError(\"Can only generate the SAS when the client is initialized with a shared key credential\");\n            }\n            const sas = generateDataLakeSASQueryParameters(Object.assign({ fileSystemName: this.fileSystemName, pathName: this.name, isDirectory: true }, options), this.credential).toString();\n            resolve(appendToURLQuery(this.url, sas));\n        });\n    }\n}\n/**\n * A DataLakeFileClient represents a URL to the Azure Storage file.\n */\nexport class DataLakeFileClient extends DataLakePathClient {\n    constructor(url, credentialOrPipeline, \n    // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.\n    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options */\n    options) {\n        if (credentialOrPipeline instanceof Pipeline) {\n            super(url, credentialOrPipeline);\n        }\n        else {\n            let credential;\n            if (credentialOrPipeline === undefined) {\n                credential = new AnonymousCredential();\n            }\n            else {\n                credential = credentialOrPipeline;\n            }\n            const pipeline = newPipeline(credential, options);\n            super(url, pipeline);\n        }\n        this.pathContextInternal = new Path(this.storageClientContext);\n        this.blockBlobClientInternal = new BlockBlobClient(this.blobEndpointUrl, this.pipeline);\n        this.pathContextInternalToBlobEndpoint = new Path(this.storageClientContextToBlobEndpoint);\n    }\n    async create(resourceTypeOrOptions, options = {}) {\n        if (resourceTypeOrOptions === \"file\") {\n            return super.create(resourceTypeOrOptions, options);\n        }\n        if (resourceTypeOrOptions === \"directory\") {\n            throw TypeError(`DataLakeFileClient:create() resourceType cannot be ${resourceTypeOrOptions}. Refer to DataLakeDirectoryClient for directory creation.`);\n        }\n        options = resourceTypeOrOptions || {};\n        options.conditions = options.conditions || {};\n        const { span, updatedOptions } = createSpan(\"DataLakeFileClient-create\", options);\n        try {\n            return await super.create(\"file\", Object.assign(Object.assign({}, options), { tracingOptions: Object.assign(Object.assign({}, options.tracingOptions), convertTracingToRequestOptionsBase(updatedOptions)) }));\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    async createIfNotExists(resourceTypeOrOptions, options = {}) {\n        if (resourceTypeOrOptions === \"directory\") {\n            throw TypeError(`DataLakeFileClient:createIfNotExists() resourceType cannot be ${resourceTypeOrOptions}. Refer to DataLakeDirectoryClient for directory creation.`);\n        }\n        if (resourceTypeOrOptions !== \"file\") {\n            options = resourceTypeOrOptions || {};\n        }\n        const { span, updatedOptions } = createSpan(\"DataLakeFileClient-createIfNotExists\", options);\n        try {\n            return await super.createIfNotExists(\"file\", Object.assign(Object.assign({}, options), { tracingOptions: Object.assign(Object.assign({}, options.tracingOptions), convertTracingToRequestOptionsBase(updatedOptions)) }));\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Downloads a file from the service, including its metadata and properties.\n     *\n     * * In Node.js, data returns in a Readable stream readableStreamBody\n     * * In browsers, data returns in a promise contentAsBlob\n     *\n     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob\n     *\n     * * Example usage (Node.js):\n     *\n     * ```js\n     * // Download and convert a file to a string\n     * const downloadResponse = await fileClient.read();\n     * const downloaded = await streamToBuffer(downloadResponse.readableStreamBody);\n     * console.log(\"Downloaded file content:\", downloaded.toString());\n     *\n     * async function streamToBuffer(readableStream) {\n     *   return new Promise((resolve, reject) => {\n     *     const chunks = [];\n     *     readableStream.on(\"data\", (data) => {\n     *       chunks.push(data instanceof Buffer ? data : Buffer.from(data));\n     *     });\n     *     readableStream.on(\"end\", () => {\n     *       resolve(Buffer.concat(chunks));\n     *     });\n     *     readableStream.on(\"error\", reject);\n     *   });\n     * }\n     * ```\n     *\n     * Example usage (browser):\n     *\n     * ```js\n     * // Download and convert a file to a string\n     * const downloadResponse = await fileClient.read();\n     * const downloaded = await blobToString(await downloadResponse.contentAsBlob);\n     * console.log(\"Downloaded file content\", downloaded);\n     *\n     * async function blobToString(blob: Blob): Promise<string> {\n     *   const fileReader = new FileReader();\n     *   return new Promise<string>((resolve, reject) => {\n     *     fileReader.onloadend = (ev: any) => {\n     *       resolve(ev.target!.result);\n     *     };\n     *     fileReader.onerror = reject;\n     *     fileReader.readAsText(blob);\n     *   });\n     * }\n     * ```\n     *\n     * @param offset - Optional. Offset to read file, default value is 0.\n     * @param count - Optional. How many bytes to read, default will read from offset to the end.\n     * @param options - Optional. Options when reading file.\n     */\n    async read(offset = 0, count, options = {}) {\n        const { span, updatedOptions } = createSpan(\"DataLakeFileClient-read\", options);\n        try {\n            const rawResponse = await this.blockBlobClientInternal.download(offset, count, updatedOptions);\n            const response = rawResponse;\n            if (!isNode && !response.contentAsBlob) {\n                response.contentAsBlob = rawResponse.blobBody;\n            }\n            response.fileContentMD5 = rawResponse.blobContentMD5;\n            response._response.parsedHeaders.fileContentMD5 =\n                rawResponse._response.parsedHeaders.blobContentMD5;\n            delete rawResponse.blobContentMD5;\n            delete rawResponse._response.parsedHeaders.blobContentMD5;\n            return response;\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Uploads data to be appended to a file. Data can only be appended to a file.\n     * To apply perviously uploaded data to a file, call flush.\n     *\n     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update\n     *\n     * @param body - Content to be uploaded.\n     * @param offset - Append offset in bytes.\n     * @param length - Length of content to append in bytes.\n     * @param options - Optional. Options when appending data.\n     */\n    async append(body, offset, length, options = {}) {\n        options.conditions = options.conditions || {};\n        const { span, updatedOptions } = createSpan(\"DataLakeFileClient-append\", options);\n        try {\n            return await this.pathContextInternal.appendData(body, Object.assign({ pathHttpHeaders: {\n                    contentMD5: options.transactionalContentMD5\n                }, abortSignal: options.abortSignal, position: offset, contentLength: length, leaseAccessConditions: options.conditions, requestOptions: {\n                    onUploadProgress: options.onProgress\n                } }, convertTracingToRequestOptionsBase(updatedOptions)));\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Flushes (writes) previously appended data to a file.\n     *\n     * @param position - File position to flush.\n     *                          This parameter allows the caller to upload data in parallel and control the order in which it is appended to the file.\n     *                          It is required when uploading data to be appended to the file and when flushing previously uploaded data to the file.\n     *                          The value must be the position where the data is to be appended. Uploaded data is not immediately flushed, or written,\n     *                          to the file. To flush, the previously uploaded data must be contiguous, the position parameter must be specified and\n     *                          equal to the length of the file after all data has been written, and there must not be a request entity body included\n     *                          with the request.\n     * @param options - Optional. Options when flushing data.\n     */\n    async flush(position, options = {}) {\n        options.conditions = options.conditions || {};\n        const { span, updatedOptions } = createSpan(\"DataLakeFileClient-flush\", options);\n        try {\n            return await this.pathContextInternal.flushData(Object.assign(Object.assign(Object.assign({}, options), { position, contentLength: 0, leaseAccessConditions: options.conditions, modifiedAccessConditions: options.conditions }), convertTracingToRequestOptionsBase(updatedOptions)));\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    // high level functions\n    /**\n     * ONLY AVAILABLE IN NODE.JS RUNTIME.\n     *\n     * Uploads a local file to a Data Lake file.\n     *\n     * @param filePath - Full path of the local file\n     * @param options -\n     */\n    async uploadFile(filePath, \n    // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.\n    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options */\n    options = {}) {\n        const { span, updatedOptions } = createSpan(\"DataLakeFileClient-uploadFile\", options);\n        try {\n            const size = (await fsStat(filePath)).size;\n            return await this.uploadSeekableInternal((offset, contentSize) => {\n                return () => fsCreateReadStream(filePath, {\n                    autoClose: true,\n                    end: offset + contentSize - 1,\n                    start: offset\n                });\n            }, size, updatedOptions);\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Uploads a Buffer(Node.js)/Blob/ArrayBuffer/ArrayBufferView to a File.\n     *\n     * @param data - Buffer(Node), Blob, ArrayBuffer or ArrayBufferView\n     * @param options -\n     */\n    async upload(data, options = {}) {\n        const { span, updatedOptions } = createSpan(\"DataLakeFileClient-upload\", options);\n        try {\n            if (isNode) {\n                let buffer;\n                if (data instanceof Buffer) {\n                    buffer = data;\n                }\n                else if (data instanceof ArrayBuffer) {\n                    buffer = Buffer.from(data);\n                }\n                else {\n                    data = data;\n                    buffer = Buffer.from(data.buffer, data.byteOffset, data.byteLength);\n                }\n                return this.uploadSeekableInternal((offset, size) => buffer.slice(offset, offset + size), buffer.length, updatedOptions);\n            }\n            else {\n                const browserBlob = new Blob([data]);\n                return this.uploadSeekableInternal((offset, size) => browserBlob.slice(offset, offset + size), browserBlob.size, updatedOptions);\n            }\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    async uploadSeekableInternal(bodyFactory, size, options = {}) {\n        var _a;\n        const { span, updatedOptions } = createSpan(\"DataLakeFileClient-uploadData\", options);\n        try {\n            if (size > FILE_MAX_SIZE_BYTES) {\n                throw new RangeError(`size must be <= ${FILE_MAX_SIZE_BYTES}.`);\n            }\n            // Create the file.\n            const createRes = this.create({\n                abortSignal: options.abortSignal,\n                metadata: options.metadata,\n                permissions: options.permissions,\n                umask: options.umask,\n                conditions: options.conditions,\n                pathHttpHeaders: options.pathHttpHeaders,\n                tracingOptions: updatedOptions.tracingOptions\n            });\n            // append() with empty data would return error, so do not continue\n            if (size === 0) {\n                return await createRes;\n            }\n            else {\n                await createRes;\n            }\n            // After the File is Create, Lease ID is the only valid request parameter.\n            options.conditions = { leaseId: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.leaseId };\n            if (!options.chunkSize) {\n                options.chunkSize = Math.ceil(size / BLOCK_BLOB_MAX_BLOCKS);\n                if (options.chunkSize < FILE_UPLOAD_DEFAULT_CHUNK_SIZE) {\n                    options.chunkSize = FILE_UPLOAD_DEFAULT_CHUNK_SIZE;\n                }\n            }\n            if (options.chunkSize < 1 || options.chunkSize > FILE_UPLOAD_MAX_CHUNK_SIZE) {\n                throw new RangeError(`chunkSize option must be >= 1 and <= ${FILE_UPLOAD_MAX_CHUNK_SIZE}`);\n            }\n            if (!options.maxConcurrency) {\n                options.maxConcurrency = DEFAULT_HIGH_LEVEL_CONCURRENCY;\n            }\n            if (options.maxConcurrency <= 0) {\n                throw new RangeError(`maxConcurrency must be > 0.`);\n            }\n            if (!options.singleUploadThreshold) {\n                options.singleUploadThreshold = FILE_MAX_SINGLE_UPLOAD_THRESHOLD;\n            }\n            if (options.singleUploadThreshold < 1 ||\n                options.singleUploadThreshold > FILE_MAX_SINGLE_UPLOAD_THRESHOLD) {\n                throw new RangeError(`singleUploadThreshold option must be >= 1 and <= ${FILE_MAX_SINGLE_UPLOAD_THRESHOLD}`);\n            }\n            // When buffer length <= singleUploadThreshold, this method will use one append/flush call to finish the upload.\n            if (size <= options.singleUploadThreshold) {\n                await this.append(bodyFactory(0, size), 0, size, {\n                    abortSignal: options.abortSignal,\n                    conditions: options.conditions,\n                    onProgress: options.onProgress,\n                    tracingOptions: updatedOptions.tracingOptions\n                });\n                return await this.flush(size, {\n                    abortSignal: options.abortSignal,\n                    conditions: options.conditions,\n                    close: options.close,\n                    pathHttpHeaders: options.pathHttpHeaders,\n                    tracingOptions: updatedOptions.tracingOptions\n                });\n            }\n            const numBlocks = Math.floor((size - 1) / options.chunkSize) + 1;\n            if (numBlocks > BLOCK_BLOB_MAX_BLOCKS) {\n                throw new RangeError(`The data's size is too big or the chunkSize is too small;` +\n                    `the number of chunks must be <= ${BLOCK_BLOB_MAX_BLOCKS}`);\n            }\n            let transferProgress = 0;\n            const batch = new Batch(options.maxConcurrency);\n            for (let i = 0; i < numBlocks; i++) {\n                batch.addOperation(async () => {\n                    const start = options.chunkSize * i;\n                    const end = i === numBlocks - 1 ? size : start + options.chunkSize;\n                    const contentLength = end - start;\n                    await this.append(bodyFactory(start, contentLength), start, contentLength, {\n                        abortSignal: options.abortSignal,\n                        conditions: options.conditions,\n                        tracingOptions: updatedOptions.tracingOptions\n                    });\n                    transferProgress += contentLength;\n                    if (options.onProgress) {\n                        options.onProgress({ loadedBytes: transferProgress });\n                    }\n                });\n            }\n            await batch.do();\n            return await this.flush(size, {\n                abortSignal: options.abortSignal,\n                conditions: options.conditions,\n                close: options.close,\n                pathHttpHeaders: options.pathHttpHeaders,\n                tracingOptions: updatedOptions.tracingOptions\n            });\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * ONLY AVAILABLE IN NODE.JS RUNTIME.\n     *\n     * Uploads a Node.js Readable stream into a Data Lake file.\n     * This method will try to create a file, then starts uploading chunk by chunk.\n     * Please make sure potential size of stream doesn't exceed FILE_MAX_SIZE_BYTES and\n     * potential number of chunks doesn't exceed BLOCK_BLOB_MAX_BLOCKS.\n     *\n     * PERFORMANCE IMPROVEMENT TIPS:\n     * * Input stream highWaterMark is better to set a same value with options.chunkSize\n     *   parameter, which will avoid Buffer.concat() operations.\n     *\n     * @param stream - Node.js Readable stream.\n     * @param options -\n     */\n    async uploadStream(stream, options = {}) {\n        var _a;\n        const { span, updatedOptions } = createSpan(\"DataLakeFileClient-uploadStream\", options);\n        try {\n            // Create the file\n            await this.create({\n                abortSignal: options.abortSignal,\n                metadata: options.metadata,\n                permissions: options.permissions,\n                umask: options.umask,\n                conditions: options.conditions,\n                pathHttpHeaders: options.pathHttpHeaders,\n                tracingOptions: updatedOptions.tracingOptions\n            });\n            // After the File is Create, Lease ID is the only valid request parameter.\n            options.conditions = { leaseId: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.leaseId };\n            if (!options.chunkSize) {\n                options.chunkSize = FILE_UPLOAD_DEFAULT_CHUNK_SIZE;\n            }\n            if (options.chunkSize < 1 || options.chunkSize > FILE_UPLOAD_MAX_CHUNK_SIZE) {\n                throw new RangeError(`chunkSize option must be >= 1 and <= ${FILE_UPLOAD_MAX_CHUNK_SIZE}`);\n            }\n            if (!options.maxConcurrency) {\n                options.maxConcurrency = DEFAULT_HIGH_LEVEL_CONCURRENCY;\n            }\n            if (options.maxConcurrency <= 0) {\n                throw new RangeError(`maxConcurrency must be > 0.`);\n            }\n            let transferProgress = 0;\n            const scheduler = new BufferScheduler(stream, options.chunkSize, options.maxConcurrency, async (body, length, offset) => {\n                await this.append(body, offset, length, {\n                    abortSignal: options.abortSignal,\n                    conditions: options.conditions,\n                    tracingOptions: updatedOptions.tracingOptions\n                });\n                // Update progress after block is successfully uploaded to server, in case of block trying\n                transferProgress += length;\n                if (options.onProgress) {\n                    options.onProgress({ loadedBytes: transferProgress });\n                }\n            }, \n            // concurrency should set a smaller value than maxConcurrency, which is helpful to\n            // reduce the possibility when a outgoing handler waits for stream data, in\n            // this situation, outgoing handlers are blocked.\n            // Outgoing queue shouldn't be empty.\n            Math.ceil((options.maxConcurrency / 4) * 3));\n            await scheduler.do();\n            return await this.flush(transferProgress, {\n                abortSignal: options.abortSignal,\n                conditions: options.conditions,\n                close: options.close,\n                pathHttpHeaders: options.pathHttpHeaders,\n                tracingOptions: updatedOptions.tracingOptions\n            });\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    async readToBuffer(bufferOrOffset, offsetOrCount, countOrOptions, optOptions = {}) {\n        let buffer = undefined;\n        let offset = 0;\n        let count = 0;\n        let options = optOptions;\n        if (bufferOrOffset instanceof Buffer) {\n            buffer = bufferOrOffset;\n            offset = offsetOrCount || 0;\n            count = typeof countOrOptions === \"number\" ? countOrOptions : 0;\n        }\n        else {\n            offset = typeof bufferOrOffset === \"number\" ? bufferOrOffset : 0;\n            count = typeof offsetOrCount === \"number\" ? offsetOrCount : 0;\n            options = countOrOptions || {};\n        }\n        const { span, updatedOptions } = createSpan(\"DataLakeFileClient-readToBuffer\", options);\n        try {\n            if (buffer) {\n                return await this.blockBlobClientInternal.downloadToBuffer(buffer, offset, count, Object.assign(Object.assign({}, options), { maxRetryRequestsPerBlock: options.maxRetryRequestsPerChunk, blockSize: options.chunkSize, tracingOptions: updatedOptions.tracingOptions }));\n            }\n            else {\n                return await this.blockBlobClientInternal.downloadToBuffer(offset, count, Object.assign(Object.assign({}, options), { maxRetryRequestsPerBlock: options.maxRetryRequestsPerChunk, blockSize: options.chunkSize, tracingOptions: updatedOptions.tracingOptions }));\n            }\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * ONLY AVAILABLE IN NODE.JS RUNTIME.\n     *\n     * Downloads a Data Lake file to a local file.\n     * Fails if the the given file path already exits.\n     * Offset and count are optional, pass 0 and undefined respectively to download the entire file.\n     *\n     * @param filePath -\n     * @param offset - From which position of the file to download.\n     * @param count - How much data to be downloaded. Will download to the end when passing undefined.\n     * @param options - Options to read Data Lake file.\n     * @returns The response data for file read operation,\n     *                                      but with readableStreamBody set to undefined since its\n     *                                      content is already read and written into a local file\n     *                                      at the specified path.\n     */\n    async readToFile(filePath, offset = 0, count, options = {}) {\n        const { span, updatedOptions } = createSpan(\"DataLakeFileClient-readToFile\", options);\n        try {\n            return await this.blockBlobClientInternal.downloadToFile(filePath, offset, count, updatedOptions);\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Quick query for a JSON or CSV formatted file.\n     *\n     * Example usage (Node.js):\n     *\n     * ```js\n     * // Query and convert a file to a string\n     * const queryResponse = await fileClient.query(\"select * from BlobStorage\");\n     * const downloaded = (await streamToBuffer(queryResponse.readableStreamBody)).toString();\n     * console.log(\"Query file content:\", downloaded);\n     *\n     * async function streamToBuffer(readableStream) {\n     *   return new Promise((resolve, reject) => {\n     *     const chunks = [];\n     *     readableStream.on(\"data\", (data) => {\n     *       chunks.push(data instanceof Buffer ? data : Buffer.from(data));\n     *     });\n     *     readableStream.on(\"end\", () => {\n     *       resolve(Buffer.concat(chunks));\n     *     });\n     *     readableStream.on(\"error\", reject);\n     *   });\n     * }\n     * ```\n     *\n     * @param query -\n     * @param options -\n     */\n    async query(query, options = {}) {\n        const { span, updatedOptions } = createSpan(\"DataLakeFileClient-query\", options);\n        try {\n            const rawResponse = await this.blockBlobClientInternal.query(query, updatedOptions);\n            const response = rawResponse;\n            if (!isNode && !response.contentAsBlob) {\n                response.contentAsBlob = rawResponse.blobBody;\n            }\n            response.fileContentMD5 = rawResponse.blobContentMD5;\n            response._response.parsedHeaders.fileContentMD5 =\n                rawResponse._response.parsedHeaders.blobContentMD5;\n            delete rawResponse.blobContentMD5;\n            delete rawResponse._response.parsedHeaders.blobContentMD5;\n            return response;\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Sets an expiry time on a file, once that time is met the file is deleted.\n     *\n     * @param mode -\n     * @param options -\n     */\n    async setExpiry(mode, options = {}) {\n        var _a;\n        const { span, updatedOptions } = createSpan(\"DataLakeFileClient-setExpiry\", options);\n        try {\n            let expiresOn = undefined;\n            if (mode === \"RelativeToNow\" || mode === \"RelativeToCreation\") {\n                if (!options.timeToExpireInMs) {\n                    throw new Error(`Should specify options.timeToExpireInMs when using mode ${mode}.`);\n                }\n                // MINOR: need check against <= 2**64, but JS number has the precision problem.\n                expiresOn = Math.round(options.timeToExpireInMs).toString();\n            }\n            if (mode === \"Absolute\") {\n                if (!options.expiresOn) {\n                    throw new Error(`Should specify options.expiresOn when using mode ${mode}.`);\n                }\n                const now = new Date();\n                if (!(options.expiresOn.getTime() > now.getTime())) {\n                    throw new Error(`options.expiresOn should be later than now: ${now.toUTCString()} when using mode ${mode}, but is ${(_a = options.expiresOn) === null || _a === void 0 ? void 0 : _a.toUTCString()}`);\n                }\n                expiresOn = options.expiresOn.toUTCString();\n            }\n            const adaptedOptions = Object.assign(Object.assign({}, options), { expiresOn });\n            return await this.pathContextInternalToBlobEndpoint.setExpiry(mode, Object.assign(Object.assign({}, adaptedOptions), { tracingOptions: updatedOptions.tracingOptions }));\n        }\n        catch (e) {\n            span.setStatus({\n                code: SpanStatusCode.ERROR,\n                message: e.message\n            });\n            throw e;\n        }\n        finally {\n            span.end();\n        }\n    }\n    /**\n     * Only available for clients constructed with a shared key credential.\n     *\n     * Generates a Service Shared Access Signature (SAS) URI based on the client properties\n     * and parameters passed in. The SAS is signed by the shared key credential of the client.\n     *\n     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas\n     *\n     * @param options - Optional parameters.\n     * @returns The SAS URI consisting of the URI to the resource represented by this client, followed by the generated SAS token.\n     */\n    generateSasUrl(options) {\n        return new Promise((resolve) => {\n            if (!(this.credential instanceof StorageSharedKeyCredential)) {\n                throw RangeError(\"Can only generate the SAS when the client is initialized with a shared key credential\");\n            }\n            const sas = generateDataLakeSASQueryParameters(Object.assign({ fileSystemName: this.fileSystemName, pathName: this.name }, options), this.credential).toString();\n            resolve(appendToURLQuery(this.url, sas));\n        });\n    }\n}\n//# sourceMappingURL=clients.js.map"]},"metadata":{},"sourceType":"module"}