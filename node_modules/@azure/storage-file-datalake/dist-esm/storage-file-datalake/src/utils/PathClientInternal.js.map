{"version":3,"file":"PathClientInternal.js","sourceRoot":"","sources":["../../../../src/utils/PathClientInternal.ts"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC;AAClC,OAAO,EAAE,kBAAkB,EAAE,MAAM,YAAY,CAAC;AAChD,OAAO,EAAE,IAAI,EAAE,MAAM,6BAA6B,CAAC;AAGnD;;;GAGG;AACH,MAAM,OAAO,kBAAmB,SAAQ,kBAAkB;IAMxD;;;;;;;;OAQG;IACH,YAAmB,GAAW,EAAE,QAAkB;QAChD,KAAK,CAAC,GAAG,EAAE,QAAQ,CAAC,CAAC;QACrB,IAAI,CAAC,eAAe,GAAG,IAAI,IAAI,CAAC,IAAI,CAAC,kCAAkC,CAAC,CAAC;IAC3E,CAAC;CACF","sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\nimport { DataLakePathClient } from \"../clients\";\nimport { Path } from \"../generated/src/operations\";\nimport { Pipeline } from \"../Pipeline\";\n\n/**\n * A PathClientInternal represents a URL to the Azure Storage path (directory or file) to\n * help to construct a path client to expose Path context with blob endpoint.\n */\nexport class PathClientInternal extends DataLakePathClient {\n  /**\n   * Path context with blob endpoint.\n   */\n  public blobPathContext: Path;\n\n  /**\n   * Creates an instance of DataLakePathClient from url and pipeline.\n   *\n   * @param url - A Client string pointing to Azure Storage data lake path (directory or file), such as\n   *                     \"https://myaccount.dfs.core.windows.net/filesystem/directory\" or \"https://myaccount.dfs.core.windows.net/filesystem/file\".\n   *                     You can append a SAS if using AnonymousCredential, such as \"https://myaccount.dfs.core.windows.net/filesystem/directory?sasString\".\n   * @param pipeline - Call newPipeline() to create a default\n   *                            pipeline, or provide a customized pipeline.\n   */\n  public constructor(url: string, pipeline: Pipeline) {\n    super(url, pipeline);\n    this.blobPathContext = new Path(this.storageClientContextToBlobEndpoint);\n  }\n}\n"]}