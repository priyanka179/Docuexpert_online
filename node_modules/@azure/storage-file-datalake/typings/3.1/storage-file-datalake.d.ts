/// <reference types="node" />
import { AbortSignalLike } from '@azure/abort-controller';
import { BaseRequestPolicy } from '@azure/core-http';
import { BlobLeaseClient } from '@azure/storage-blob';
import { BlobQueryArrowConfiguration } from '@azure/storage-blob';
import { ContainerRenameResponse } from '@azure/storage-blob';
import { ContainerUndeleteResponse } from '@azure/storage-blob';
import * as coreHttp from '@azure/core-http';
import { ServiceGetPropertiesResponse as DataLakeServiceGetPropertiesResponse } from '@azure/storage-blob';
import { BlobServiceProperties as DataLakeServiceProperties } from '@azure/storage-blob';
import { deserializationPolicy } from '@azure/core-http';
import { HttpHeaders } from '@azure/core-http';
import { HttpOperationResponse } from '@azure/core-http';
import { HttpRequestBody } from '@azure/core-http';
import { HttpResponse } from '@azure/core-http';
import { HttpClient as IHttpClient } from '@azure/core-http';
import { KeepAliveOptions } from '@azure/core-http';
import { Lease } from '@azure/storage-blob';
import { LeaseAccessConditions } from '@azure/storage-blob';
import { LeaseOperationOptions } from '@azure/storage-blob';
import { LeaseOperationResponse } from '@azure/storage-blob';
import { ModifiedAccessConditions as ModifiedAccessConditions_2 } from '@azure/storage-blob';
import { OperationTracingOptions } from '@azure/core-tracing';
import { PagedAsyncIterableIterator } from '@azure/core-paging';
import { ProxyOptions } from '@azure/core-http';
import { Readable } from 'stream';
import { RequestPolicy } from '@azure/core-http';
import { RequestPolicyFactory } from '@azure/core-http';
import { RequestPolicyOptions } from '@azure/core-http';
import { RestError } from '@azure/core-http';
import { ServiceClientOptions } from '@azure/core-http';
import { ServiceGetPropertiesOptions } from '@azure/storage-blob';
import { ServiceListContainersSegmentResponse } from '@azure/storage-blob';
import { ServiceRenameContainerOptions } from '@azure/storage-blob';
import { ServiceSetPropertiesOptions } from '@azure/storage-blob';
import { ServiceSetPropertiesResponse } from '@azure/storage-blob';
import { TokenCredential } from '@azure/core-http';
import { TransferProgressEvent } from '@azure/core-http';
import { UserAgentOptions } from '@azure/core-http';
import { UserDelegationKeyModel } from '@azure/storage-blob';
import { WebResource } from '@azure/core-http';
/**
 * AccessControlChangeCounters contains counts of operations that change Access Control Lists recursively.
 */
export declare interface AccessControlChangeCounters {
    /**
     * Returns number of directories where Access Control List has been updated successfully.
     */
    changedDirectoriesCount: number;
    /**
     * Returns number of files where Access Control List has been updated successfully.
     */
    changedFilesCount: number;
    /**
     * Returns number of paths where Access Control List update has failed.
     */
    failedChangesCount: number;
}
/**
 * Represents an entry that failed to update Access Control List during `setAccessControlRecursive`, `updateAccessControlRecursive` and `removeAccessControlRecursive`.
 */
export declare interface AccessControlChangeError {
    /**
     * Returns name of an entry.
     */
    name: string;
    /**
     * Returns whether entry is a directory.
     */
    isDirectory: boolean;
    /**
     * Returns error message that is the reason why entry failed to update.
     */
    message: string;
}
/**
 * AccessControlChanges contains batch and cumulative counts of operations that change Access Control Lists recursively.
 * Additionally it exposes path entries that failed to update while these operations progress.
 */
export declare interface AccessControlChanges {
    /**
     * Path entries that failed to update Access Control List within single batch.
     */
    batchFailures: AccessControlChangeError[];
    /**
     * Counts of paths changed within single batch.
     */
    batchCounters: AccessControlChangeCounters;
    /**
     * Counts of paths changed from start of the operation.
     */
    aggregateCounters: AccessControlChangeCounters;
    /**
     * Optional. Value is present when operation is split into multiple batches and can be used to resume progress.
     */
    continuationToken?: string;
}
export declare type AccessControlType = "user" | "group" | "mask" | "other";
export declare interface AccessPolicy {
    startsOn?: Date;
    expiresOn?: Date;
    permissions: string;
}
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * This is a helper class to construct a string representing the permissions granted by an AccountSAS. Setting a value
 * to true means that any SAS which uses these permissions will grant permissions for that operation. Once all the
 * values are set, this should be serialized with toString and set as the permissions field on an
 * {@link AccountSASSignatureValues} object. It is possible to construct the permissions string without this class, but
 * the order of the permissions is particular and this class guarantees correctness.
 */
export declare class AccountSASPermissions {
    /**
     * Parse initializes the AccountSASPermissions fields from a string.
     *
     * @param permissions -
     */
    static parse(permissions: string): AccountSASPermissions;
    /**
     * Permission to read resources and list queues and tables granted.
     */
    read: boolean;
    /**
     * Permission to write resources granted.
     */
    write: boolean;
    /**
     * Permission to delete blobs and files granted.
     */
    delete: boolean;
    /**
     * Permission to list blob containers, blobs, shares, directories, and files granted.
     */
    list: boolean;
    /**
     * Permission to add messages, table entities, and append to blobs granted.
     */
    add: boolean;
    /**
     * Permission to create blobs and files granted.
     */
    create: boolean;
    /**
     * Permissions to update messages and table entities granted.
     */
    update: boolean;
    /**
     * Permission to get and delete messages granted.
     */
    process: boolean;
    /**
     * Produces the SAS permissions string for an Azure Storage account.
     * Call this method to set AccountSASSignatureValues Permissions field.
     *
     * Using this method will guarantee the resource types are in
     * an order accepted by the service.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-an-account-sas
     *
     */
    toString(): string;
}
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * This is a helper class to construct a string representing the resources accessible by an AccountSAS. Setting a value
 * to true means that any SAS which uses these permissions will grant access to that resource type. Once all the
 * values are set, this should be serialized with toString and set as the resources field on an
 * {@link AccountSASSignatureValues} object. It is possible to construct the resources string without this class, but
 * the order of the resources is particular and this class guarantees correctness.
 */
export declare class AccountSASResourceTypes {
    /**
     * Creates an {@link AccountSASResourceTypes} from the specified resource types string. This method will throw an
     * Error if it encounters a character that does not correspond to a valid resource type.
     *
     * @param resourceTypes -
     */
    static parse(resourceTypes: string): AccountSASResourceTypes;
    /**
     * Permission to access service level APIs granted.
     */
    service: boolean;
    /**
     * Permission to access container level APIs (Blob Containers, Tables, Queues, File Shares, File Systems) granted.
     */
    container: boolean;
    /**
     * Permission to access object level APIs (Blobs, Table Entities, Queue Messages, Files, Directories) granted.
     */
    object: boolean;
    /**
     * Converts the given resource types to a string.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-an-account-sas
     *
     */
    toString(): string;
}
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * This is a helper class to construct a string representing the services accessible by an AccountSAS. Setting a value
 * to true means that any SAS which uses these permissions will grant access to that service. Once all the
 * values are set, this should be serialized with toString and set as the services field on an
 * {@link AccountSASSignatureValues} object. It is possible to construct the services string without this class, but
 * the order of the services is particular and this class guarantees correctness.
 */
export declare class AccountSASServices {
    /**
     * Creates an {@link AccountSASServices} from the specified services string. This method will throw an
     * Error if it encounters a character that does not correspond to a valid service.
     *
     * @param services -
     */
    static parse(services: string): AccountSASServices;
    /**
     * Permission to access blob and data lake resources granted.
     */
    blob: boolean;
    /**
     * Permission to access file resources granted.
     */
    file: boolean;
    /**
     * Permission to access queue resources granted.
     */
    queue: boolean;
    /**
     * Permission to access table resources granted.
     */
    table: boolean;
    /**
     * Converts the given services to a string.
     *
     */
    toString(): string;
}
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * AccountSASSignatureValues is used to generate a Shared Access Signature (SAS) for an Azure Storage account. Once
 * all the values here are set appropriately, call {@link generateAccountSASQueryParameters} to obtain a representation
 * of the SAS which can actually be applied to data lake urls. Note: that both this class and {@link SASQueryParameters}
 * exist because the former is mutable and a logical representation while the latter is immutable and used to generate
 * actual REST requests.
 *
 * @see https://docs.microsoft.com/en-us/azure/storage/common/storage-dotnet-shared-access-signature-part-1
 * for more conceptual information on SAS
 *
 * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-an-account-sas
 * for descriptions of the parameters, including which are required
 */
export declare interface AccountSASSignatureValues {
    /**
     * If not provided, this defaults to the service version targeted by this version of the library.
     */
    version?: string;
    /**
     * Optional. SAS protocols allowed.
     */
    protocol?: SASProtocol;
    /**
     * Optional. When the SAS will take effect.
     */
    startsOn?: Date;
    /**
     * The time after which the SAS will no longer work.
     */
    expiresOn: Date;
    /**
     * Specifies which operations the SAS user may perform. Please refer to {@link AccountSASPermissions} for help
     * constructing the permissions string.
     */
    permissions: AccountSASPermissions;
    /**
     * Optional. IP range allowed.
     */
    ipRange?: SasIPRange;
    /**
     * The values that indicate the services accessible with this SAS. Please refer to {@link AccountSASServices} to
     * construct this value.
     */
    services: string;
    /**
     * The values that indicate the resource types accessible with this SAS. Please refer
     * to {@link AccountSASResourceTypes} to construct this value.
     */
    resourceTypes: string;
}
/**
 * AnonymousCredential provides a credentialPolicyCreator member used to create
 * AnonymousCredentialPolicy objects. AnonymousCredentialPolicy is used with
 * HTTP(S) requests that read public resources or for use with Shared Access
 * Signatures (SAS).
 */
export declare class AnonymousCredential extends Credential {
    /**
     * Creates an {@link AnonymousCredentialPolicy} object.
     *
     * @param nextPolicy -
     * @param options -
     */
    create(nextPolicy: RequestPolicy, options: RequestPolicyOptions): AnonymousCredentialPolicy;
}
/**
 * AnonymousCredentialPolicy is used with HTTP(S) requests that read public resources
 * or for use with Shared Access Signatures (SAS).
 */
export declare class AnonymousCredentialPolicy extends CredentialPolicy {
    /**
     * Creates an instance of AnonymousCredentialPolicy.
     * @param nextPolicy -
     * @param options -
     */
    constructor(nextPolicy: RequestPolicy, options: RequestPolicyOptions);
}
export { BaseRequestPolicy };
export declare interface BlobHierarchyListSegment {
    blobPrefixes?: BlobPrefix[];
    blobItems: BlobItemModel[];
}
/** An Azure Storage blob */
export declare interface BlobItemModel {
    name: string;
    deleted: boolean;
    snapshot: string;
    versionId?: string;
    isCurrentVersion?: boolean;
    /** Properties of a blob */
    properties: BlobPropertiesModel;
    deletionId?: string;
}
export declare interface BlobPrefix {
    name: string;
}
/** Properties of a blob */
export declare interface BlobPropertiesModel {
    creationTime?: Date;
    lastModified: Date;
    etag: string;
    /** Size in bytes */
    contentLength?: number;
    contentType?: string;
    contentEncoding?: string;
    contentLanguage?: string;
    contentMD5?: Uint8Array;
    contentDisposition?: string;
    cacheControl?: string;
    blobSequenceNumber?: number;
    copyId?: string;
    copySource?: string;
    copyProgress?: string;
    copyCompletionTime?: Date;
    copyStatusDescription?: string;
    serverEncrypted?: boolean;
    incrementalCopy?: boolean;
    destinationSnapshot?: string;
    deletedTime?: Date;
    remainingRetentionDays?: number;
    accessTierInferred?: boolean;
    customerProvidedKeySha256?: string;
    /** The name of the encryption scope under which the blob is encrypted. */
    encryptionScope?: string;
    accessTierChangeTime?: Date;
    tagCount?: number;
    expiresOn?: Date;
    sealed?: boolean;
    lastAccessedOn?: Date;
}
/**
 * Common options of the {@link FileSystemGenerateSasUrlOptions}, {@link DirectoryGenerateSasUrlOptions}
 * and {@link FileGenerateSasUrlOptions}.
 */
export declare interface CommonGenerateSasUrlOptions {
    /**
     * The version of the service this SAS will target. If not specified, it will default to the version targeted by the
     * library.
     */
    version?: string;
    /**
     * Optional. SAS protocols, HTTPS only or HTTPSandHTTP
     */
    protocol?: SASProtocol;
    /**
     * Optional. When the SAS will take effect.
     */
    startsOn?: Date;
    /**
     * Optional only when identifier is provided. The time after which the SAS will no longer work.
     */
    expiresOn?: Date;
    /**
     * Optional. IP ranges allowed in this SAS.
     */
    ipRange?: SasIPRange;
    /**
     * Optional. The name of the access policy on the container this SAS references if any.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/establishing-a-stored-access-policy
     */
    identifier?: string;
    /**
     * Optional. The cache-control header for the SAS.
     */
    cacheControl?: string;
    /**
     * Optional. The content-disposition header for the SAS.
     */
    contentDisposition?: string;
    /**
     * Optional. The content-encoding header for the SAS.
     */
    contentEncoding?: string;
    /**
     * Optional. The content-language header for the SAS.
     */
    contentLanguage?: string;
    /**
     * Optional. The content-type header for the SAS.
     */
    contentType?: string;
}
/**
 * An interface for options common to every remote operation.
 */
export declare interface CommonOptions {
    /**
     * Options to configure spans created when tracing is enabled.
     */
    tracingOptions?: OperationTracingOptions;
}
export declare type CopyStatusType = "pending" | "success" | "aborted" | "failed";
/**
 * Credential is an abstract class for Azure Storage HTTP requests signing. This
 * class will host an credentialPolicyCreator factory which generates CredentialPolicy.
 */
export declare abstract class Credential implements RequestPolicyFactory {
    /**
     * Creates a RequestPolicy object.
     *
     * @param _nextPolicy -
     * @param _options -
     */
    create(_nextPolicy: RequestPolicy, _options: RequestPolicyOptions): RequestPolicy;
}
/**
 * Credential policy used to sign HTTP(S) requests before sending. This is an
 * abstract class.
 */
export declare abstract class CredentialPolicy extends BaseRequestPolicy {
    /**
     * Sends out request.
     *
     * @param request -
     */
    sendRequest(request: WebResource): Promise<HttpOperationResponse>;
    /**
     * Child classes must implement this method with request signing. This method
     * will be executed in {@link sendRequest}.
     *
     * @param request -
     */
    protected signRequest(request: WebResource): WebResource;
}
/**
 * A factory function that creates a new CredentialPolicy that uses the provided nextPolicy.
 */
export declare type CredentialPolicyCreator = (nextPolicy: RequestPolicy, options: RequestPolicyOptions) => CredentialPolicy;
/**
 * An error thrown when an operation is interrupted and can be continued later on.
 */
export declare class DataLakeAclChangeFailedError extends Error {
    /**
     * Continuation token to continue next batch of operations.
     */
    continuationToken?: string;
    /**
     * Internal error.
     */
    innerError: RestError | Error;
    constructor(error: RestError | Error, continuationToken?: string);
}
/**
 * A DataLakeDirectoryClient represents a URL to the Azure Storage directory.
 */
export declare class DataLakeDirectoryClient extends DataLakePathClient {
    /**
     * Create a directory.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
     *
     * @param resourceType - Resource type, must be "directory" for DataLakeDirectoryClient.
     * @param options - Optional. Options when creating directory.
     */
    create(resourceType: PathResourceTypeModel, options?: PathCreateOptions): Promise<PathCreateResponse>;
    /**
     * Create a directory.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
     *
     * @param options - Optional. Options when creating directory.
     */
    create(options?: DirectoryCreateOptions): Promise<DirectoryCreateResponse>;
    /**
     * Create a directory if it doesn't already exists.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
     *
     * @param resourceType - Resource type, must be "directory" for DataLakeDirectoryClient.
     * @param options -
     */
    createIfNotExists(resourceType: PathResourceTypeModel, options?: PathCreateIfNotExistsOptions): Promise<PathCreateIfNotExistsResponse>;
    /**
     * Create a directory if it doesn't already exists.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
     *
     * @param options -
     */
    createIfNotExists(options?: DirectoryCreateIfNotExistsOptions): Promise<DirectoryCreateIfNotExistsResponse>;
    /**
     * Creates a {@link DataLakeDirectoryClient} object under current directory.
     *
     * @param subdirectoryName - Subdirectory name.
     */
    getSubdirectoryClient(subdirectoryName: string): DataLakeDirectoryClient;
    /**
     * Creates a {@link DataLakeFileClient} object under current directory.
     *
     * @param fileName -
     */
    getFileClient(fileName: string): DataLakeFileClient;
    /**
     * Only available for clients constructed with a shared key credential.
     *
     * Generates a Service Shared Access Signature (SAS) URI based on the client properties
     * and parameters passed in. The SAS is signed by the shared key credential of the client.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas
     *
     * @param options - Optional parameters.
     * @returns The SAS URI consisting of the URI to the resource represented by this client, followed by the generated SAS token.
     */
    generateSasUrl(options: DirectoryGenerateSasUrlOptions): Promise<string>;
}
/**
 * A DataLakeFileClient represents a URL to the Azure Storage file.
 */
export declare class DataLakeFileClient extends DataLakePathClient {
    /**
     * pathContextInternal provided by protocol layer.
     */
    private pathContextInternal;
    /**
     * pathContextInternal provided by protocol layer, with its url pointing to the Blob endpoint.
     */
    private pathContextInternalToBlobEndpoint;
    /**
     * blockBlobClientInternal provided by `@azure/storage-blob` package.
     */
    private blockBlobClientInternal;
    /**
     * Creates an instance of DataLakeFileClient from url and credential.
     *
     * @param url - A Client string pointing to Azure Storage data lake file, such as
     *                     "https://myaccount.dfs.core.windows.net/filesystem/file".
     *                     You can append a SAS if using AnonymousCredential, such as "https://myaccount.dfs.core.windows.net/filesystem/directory/file?sasString".
     * @param credential - Such as AnonymousCredential, StorageSharedKeyCredential or any credential from the `@azure/identity` package to authenticate requests to the service. You can also provide an object that implements the TokenCredential interface. If not specified, AnonymousCredential is used.
     * @param options - Optional. Options to configure the HTTP pipeline.
     */
    constructor(url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions);
    /**
     * Creates an instance of DataLakeFileClient from url and pipeline.
     *
     * @param url - A Client string pointing to Azure Storage data lake file, such as
     *                     "https://myaccount.dfs.core.windows.net/filesystem/file".
     *                     You can append a SAS if using AnonymousCredential, such as "https://myaccount.dfs.core.windows.net/filesystem/directory/file?sasString".
     * @param pipeline - Call newPipeline() to create a default
     *                            pipeline, or provide a customized pipeline.
     */
    constructor(url: string, pipeline: Pipeline);
    /**
     * Create a file.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
     *
     * @param resourceType - Resource type, must be "file" for DataLakeFileClient.
     * @param options - Optional. Options when creating file.
     */
    create(resourceType: PathResourceTypeModel, options?: PathCreateOptions): Promise<PathCreateResponse>;
    /**
     * Create a file.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
     *
     * @param options - Optional. Options when creating file.
     */
    create(options?: FileCreateOptions): Promise<FileCreateResponse>;
    /**
     * Create a file if it doesn't already exists.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
     *
     * @param resourceType - Resource type, must be "file" for DataLakeFileClient.
     * @param options -
     */
    createIfNotExists(resourceType: PathResourceTypeModel, options?: PathCreateIfNotExistsOptions): Promise<PathCreateIfNotExistsResponse>;
    /**
     * Create a file if it doesn't already exists.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
     *
     * @param options - Optional. Options when creating file.
     */
    createIfNotExists(options?: FileCreateIfNotExistsOptions): Promise<FileCreateIfNotExistsResponse>;
    /**
     * Downloads a file from the service, including its metadata and properties.
     *
     * * In Node.js, data returns in a Readable stream readableStreamBody
     * * In browsers, data returns in a promise contentAsBlob
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob
     *
     * * Example usage (Node.js):
     *
     * ```js
     * // Download and convert a file to a string
     * const downloadResponse = await fileClient.read();
     * const downloaded = await streamToBuffer(downloadResponse.readableStreamBody);
     * console.log("Downloaded file content:", downloaded.toString());
     *
     * async function streamToBuffer(readableStream) {
     *   return new Promise((resolve, reject) => {
     *     const chunks = [];
     *     readableStream.on("data", (data) => {
     *       chunks.push(data instanceof Buffer ? data : Buffer.from(data));
     *     });
     *     readableStream.on("end", () => {
     *       resolve(Buffer.concat(chunks));
     *     });
     *     readableStream.on("error", reject);
     *   });
     * }
     * ```
     *
     * Example usage (browser):
     *
     * ```js
     * // Download and convert a file to a string
     * const downloadResponse = await fileClient.read();
     * const downloaded = await blobToString(await downloadResponse.contentAsBlob);
     * console.log("Downloaded file content", downloaded);
     *
     * async function blobToString(blob: Blob): Promise<string> {
     *   const fileReader = new FileReader();
     *   return new Promise<string>((resolve, reject) => {
     *     fileReader.onloadend = (ev: any) => {
     *       resolve(ev.target!.result);
     *     };
     *     fileReader.onerror = reject;
     *     fileReader.readAsText(blob);
     *   });
     * }
     * ```
     *
     * @param offset - Optional. Offset to read file, default value is 0.
     * @param count - Optional. How many bytes to read, default will read from offset to the end.
     * @param options - Optional. Options when reading file.
     */
    read(offset?: number, count?: number, options?: FileReadOptions): Promise<FileReadResponse>;
    /**
     * Uploads data to be appended to a file. Data can only be appended to a file.
     * To apply perviously uploaded data to a file, call flush.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update
     *
     * @param body - Content to be uploaded.
     * @param offset - Append offset in bytes.
     * @param length - Length of content to append in bytes.
     * @param options - Optional. Options when appending data.
     */
    append(body: HttpRequestBody, offset: number, length: number, options?: FileAppendOptions): Promise<FileAppendResponse>;
    /**
     * Flushes (writes) previously appended data to a file.
     *
     * @param position - File position to flush.
     *                          This parameter allows the caller to upload data in parallel and control the order in which it is appended to the file.
     *                          It is required when uploading data to be appended to the file and when flushing previously uploaded data to the file.
     *                          The value must be the position where the data is to be appended. Uploaded data is not immediately flushed, or written,
     *                          to the file. To flush, the previously uploaded data must be contiguous, the position parameter must be specified and
     *                          equal to the length of the file after all data has been written, and there must not be a request entity body included
     *                          with the request.
     * @param options - Optional. Options when flushing data.
     */
    flush(position: number, options?: FileFlushOptions): Promise<PathFlushDataResponse>;
    /**
     * ONLY AVAILABLE IN NODE.JS RUNTIME.
     *
     * Uploads a local file to a Data Lake file.
     *
     * @param filePath - Full path of the local file
     * @param options -
     */
    uploadFile(filePath: string, options?: FileParallelUploadOptions): Promise<PathFlushDataResponse>;
    /**
     * Uploads a Buffer(Node.js)/Blob/ArrayBuffer/ArrayBufferView to a File.
     *
     * @param data - Buffer(Node), Blob, ArrayBuffer or ArrayBufferView
     * @param options -
     */
    upload(data: Buffer | Blob | ArrayBuffer | ArrayBufferView, options?: FileParallelUploadOptions): Promise<PathFlushDataResponse>;
    private uploadSeekableInternal;
    /**
     * ONLY AVAILABLE IN NODE.JS RUNTIME.
     *
     * Uploads a Node.js Readable stream into a Data Lake file.
     * This method will try to create a file, then starts uploading chunk by chunk.
     * Please make sure potential size of stream doesn't exceed FILE_MAX_SIZE_BYTES and
     * potential number of chunks doesn't exceed BLOCK_BLOB_MAX_BLOCKS.
     *
     * PERFORMANCE IMPROVEMENT TIPS:
     * * Input stream highWaterMark is better to set a same value with options.chunkSize
     *   parameter, which will avoid Buffer.concat() operations.
     *
     * @param stream - Node.js Readable stream.
     * @param options -
     */
    uploadStream(stream: Readable, options?: FileParallelUploadOptions): Promise<PathFlushDataResponse>;
    /**
     * ONLY AVAILABLE IN NODE.JS RUNTIME.
     *
     * Reads a Data Lake file in parallel to a buffer.
     * Offset and count are optional, pass 0 for both to read the entire file.
     *
     * Warning: Buffers can only support files up to about one gigabyte on 32-bit systems or about two
     * gigabytes on 64-bit systems due to limitations of Node.js/V8. For files larger than this size,
     * consider {@link readToFile}.
     *
     * @param buffer - Buffer to be fill, must have length larger than count
     * @param offset - From which position of the Data Lake file to read
     * @param count - How much data to be read. Will read to the end when passing undefined
     * @param options -
     */
    readToBuffer(buffer: Buffer, offset?: number, count?: number, options?: FileReadToBufferOptions): Promise<Buffer>;
    /**
     * ONLY AVAILABLE IN NODE.JS RUNTIME
     *
     * Reads a Data Lake file in parallel to a buffer.
     * Offset and count are optional, pass 0 for both to read the entire file
     *
     * Warning: Buffers can only support files up to about one gigabyte on 32-bit systems or about two
     * gigabytes on 64-bit systems due to limitations of Node.js/V8. For files larger than this size,
     * consider {@link readToFile}.
     *
     * @param offset - From which position of the Data Lake file to read(in bytes)
     * @param count - How much data(in bytes) to be read. Will read to the end when passing undefined
     * @param options -
     */
    readToBuffer(offset?: number, count?: number, options?: FileReadToBufferOptions): Promise<Buffer>;
    /**
     * ONLY AVAILABLE IN NODE.JS RUNTIME.
     *
     * Downloads a Data Lake file to a local file.
     * Fails if the the given file path already exits.
     * Offset and count are optional, pass 0 and undefined respectively to download the entire file.
     *
     * @param filePath -
     * @param offset - From which position of the file to download.
     * @param count - How much data to be downloaded. Will download to the end when passing undefined.
     * @param options - Options to read Data Lake file.
     * @returns The response data for file read operation,
     *                                      but with readableStreamBody set to undefined since its
     *                                      content is already read and written into a local file
     *                                      at the specified path.
     */
    readToFile(filePath: string, offset?: number, count?: number, options?: FileReadOptions): Promise<FileReadResponse>;
    /**
     * Quick query for a JSON or CSV formatted file.
     *
     * Example usage (Node.js):
     *
     * ```js
     * // Query and convert a file to a string
     * const queryResponse = await fileClient.query("select * from BlobStorage");
     * const downloaded = (await streamToBuffer(queryResponse.readableStreamBody)).toString();
     * console.log("Query file content:", downloaded);
     *
     * async function streamToBuffer(readableStream) {
     *   return new Promise((resolve, reject) => {
     *     const chunks = [];
     *     readableStream.on("data", (data) => {
     *       chunks.push(data instanceof Buffer ? data : Buffer.from(data));
     *     });
     *     readableStream.on("end", () => {
     *       resolve(Buffer.concat(chunks));
     *     });
     *     readableStream.on("error", reject);
     *   });
     * }
     * ```
     *
     * @param query -
     * @param options -
     */
    query(query: string, options?: FileQueryOptions): Promise<FileReadResponse>;
    /**
     * Sets an expiry time on a file, once that time is met the file is deleted.
     *
     * @param mode -
     * @param options -
     */
    setExpiry(mode: FileExpiryMode, options?: FileSetExpiryOptions): Promise<FileSetExpiryResponse>;
    /**
     * Only available for clients constructed with a shared key credential.
     *
     * Generates a Service Shared Access Signature (SAS) URI based on the client properties
     * and parameters passed in. The SAS is signed by the shared key credential of the client.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas
     *
     * @param options - Optional parameters.
     * @returns The SAS URI consisting of the URI to the resource represented by this client, followed by the generated SAS token.
     */
    generateSasUrl(options: FileGenerateSasUrlOptions): Promise<string>;
}
/**
 * A DataLakeFileSystemClient represents a URL to the Azure Storage file system
 * allowing you to manipulate its directories and files.
 */
export declare class DataLakeFileSystemClient extends StorageClient {
    /**
     * fileSystemContext provided by protocol layer.
     */
    private fileSystemContext;
    /**
     * fileSystemContext provided by protocol layer.
     */
    private fileSystemContextToBlobEndpoint;
    /**
     * blobContainerClient provided by `@azure/storage-blob` package.
     */
    private blobContainerClient;
    /**
     * Creates an instance of DataLakeFileSystemClient from url and credential.
     *
     * @param url - A Client string pointing to Azure Storage data lake file system, such as
     *                     "https://myaccount.dfs.core.windows.net/filesystem". You can append a SAS
     *                     if using AnonymousCredential, such as "https://myaccount.dfs.core.windows.net/filesystem?sasString".
     * @param credential - Such as AnonymousCredential, StorageSharedKeyCredential or any credential from the `@azure/identity` package to authenticate requests to the service. You can also provide an object that implements the TokenCredential interface. If not specified, AnonymousCredential is used.
     * @param options - Optional. Options to configure the HTTP pipeline.
     */
    constructor(url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions);
    /**
     * Creates an instance of DataLakeFileSystemClient from url and pipeline.
     *
     * @param url - A Client string pointing to Azure Storage data lake file system, such as
     *                     "https://myaccount.dfs.core.windows.net/filesystem". You can append a SAS
     *                     if using AnonymousCredential, such as "https://myaccount.dfs.core.windows.net/filesystem?sasString".
     * @param pipeline - Call newPipeline() to create a default
     *                            pipeline, or provide a customized pipeline.
     */
    constructor(url: string, pipeline: Pipeline);
    readonly name: string;
    /**
     * Creates a {@link DataLakeDirectoryClient} object under current file system.
     *
     * @param directoryName -
     */
    getDirectoryClient(directoryName: string): DataLakeDirectoryClient;
    /**
     * Creates a {@link DataLakeFileClient} object under current file system.
     *
     * @param fileName -
     */
    getFileClient(fileName: string): DataLakeFileClient;
    /**
     * Get a {@link DataLakeLeaseClient} that manages leases on the file system.
     *
     * @param proposeLeaseId - Optional. Initial proposed lease Id.
     */
    getDataLakeLeaseClient(proposeLeaseId?: string): DataLakeLeaseClient;
    /**
     * Creates a new file system under the specified account. If the file system with
     * the same name already exists, the operation fails.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/create-container
     *
     * @param options - Optional. Options when creating file system.
     */
    create(options?: FileSystemCreateOptions): Promise<FileSystemCreateResponse>;
    /**
     * Creates a new file system under the specified account. If the file system with
     * the same name already exists, it is not changed.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/create-container
     *
     * @param options -
     */
    createIfNotExists(options?: FileSystemCreateOptions): Promise<FileSystemCreateIfNotExistsResponse>;
    /**
     * Returns true if the File system represented by this client exists; false otherwise.
     *
     * NOTE: use this function with care since an existing file system might be deleted by other clients or
     * applications. Vice versa new file system with the same name might be added by other clients or
     * applications after this function completes.
     *
     * @param options -
     */
    exists(options?: FileSystemExistsOptions): Promise<boolean>;
    /**
     * Delete current file system.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/delete-container
     *
     * @param options - Optional. Options when deleting file system.
     */
    delete(options?: FileSystemDeleteOptions): Promise<FileSystemDeleteResponse>;
    /**
     * Delete current file system if it exists.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/delete-container
     *
     * @param options -
     */
    deleteIfExists(options?: FileSystemDeleteOptions): Promise<FileSystemDeleteIfExistsResponse>;
    /**
     * Returns all user-defined metadata and system properties for the specified
     * file system.
     *
     * WARNING: The `metadata` object returned in the response will have its keys in lowercase, even if
     * they originally contained uppercase characters. This differs from the metadata keys returned by
     * the `listFileSystems` method of {@link DataLakeServiceClient} using the `includeMetadata` option, which
     * will retain their original casing.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-container-properties
     *
     * @param options - Optional. Options when getting file system properties.
     */
    getProperties(options?: FileSystemGetPropertiesOptions): Promise<FileSystemGetPropertiesResponse>;
    /**
     * Sets one or more user-defined name-value pairs for the specified file system.
     *
     * If no option provided, or no metadata defined in the parameter, the file system
     * metadata will be removed.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-container-metadata
     *
     * @param metadata - Replace existing metadata with this value.
     *                              If no value provided the existing metadata will be removed.
     * @param options - Optional. Options when setting file system metadata.
     */
    setMetadata(metadata?: Metadata, options?: FileSystemSetMetadataOptions): Promise<FileSystemSetMetadataResponse>;
    /**
     * Gets the permissions for the specified file system. The permissions indicate
     * whether file system data may be accessed publicly.
     *
     * WARNING: JavaScript Date will potentially lose precision when parsing startsOn and expiresOn strings.
     * For example, new Date("2018-12-31T03:44:23.8827891Z").toISOString() will get "2018-12-31T03:44:23.882Z".
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-container-acl
     *
     * @param options - Optional. Options when getting file system access policy.
     */
    getAccessPolicy(options?: FileSystemGetAccessPolicyOptions): Promise<FileSystemGetAccessPolicyResponse>;
    /**
     * Sets the permissions for the specified file system. The permissions indicate
     * whether directories or files in a file system may be accessed publicly.
     *
     * When you set permissions for a file system, the existing permissions are replaced.
     * If no access or containerAcl provided, the existing file system ACL will be
     * removed.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-container-acl
     *
     * @param access - Optional. The level of public access to data in the file system.
     * @param fileSystemAcl - Optional. Array of elements each having a unique Id and details of the access policy.
     * @param options - Optional. Options when setting file system access policy.
     */
    setAccessPolicy(access?: PublicAccessType, fileSystemAcl?: SignedIdentifier<AccessPolicy>[], options?: FileSystemSetAccessPolicyOptions): Promise<FileSystemSetAccessPolicyResponse>;
    /**
     * Returns an async iterable iterator to list all the paths (directories and files)
     * under the specified file system.
     *
     * .byPage() returns an async iterable iterator to list the paths in pages.
     *
     * Example using `for await` syntax:
     *
     * ```js
     * // Get the fileSystemClient before you run these snippets,
     * // Can be obtained from `serviceClient.getFileSystemClient("<your-filesystem-name>");`
     * let i = 1;
     * for await (const path of fileSystemClient.listPaths()) {
     *   console.log(`Path ${i++}: ${path.name}, isDirectory?: ${path.isDirectory}`);
     * }
     * ```
     *
     * Example using `iter.next()`:
     *
     * ```js
     * let i = 1;
     * let iter = fileSystemClient.listPaths();
     * let pathItem = await iter.next();
     * while (!pathItem.done) {
     *   console.log(`Path ${i++}: ${pathItem.value.name}, isDirectory?: ${pathItem.value.isDirectory}`);
     *   pathItem = await iter.next();
     * }
     * ```
     *
     * Example using `byPage()`:
     *
     * ```js
     * // passing optional maxPageSize in the page settings
     * let i = 1;
     * for await (const response of fileSystemClient.listPaths().byPage({ maxPageSize: 20 })) {
     *   for (const path of response.pathItems) {
     *     console.log(`Path ${i++}: ${path.name}, isDirectory?: ${path.isDirectory}`);
     *   }
     * }
     * ```
     *
     * Example using paging with a marker:
     *
     * ```js
     * let i = 1;
     * let iterator = fileSystemClient.listPaths().byPage({ maxPageSize: 2 });
     * let response = (await iterator.next()).value;
     *
     * // Prints 2 path names
     * for (const path of response.pathItems) {
     *   console.log(`Path ${i++}: ${path.name}, isDirectory?: ${path.isDirectory}`);
     * }
     *
     * // Gets next marker
     * let marker = response.continuationToken;
     *
     * // Passing next marker as continuationToken
     *
     * iterator = fileSystemClient.listPaths().byPage({ continuationToken: marker, maxPageSize: 10 });
     * response = (await iterator.next()).value;
     *
     * // Prints 10 path names
     * for (const path of response.pathItems) {
     *   console.log(`Path ${i++}: ${path.name}, isDirectory?: ${path.isDirectory}`);
     * }
     * ```
     *
     * @see https://docs.microsoft.com/rest/api/storageservices/list-blobs
     *
     * @param options - Optional. Options when listing paths.
     */
    listPaths(options?: ListPathsOptions): PagedAsyncIterableIterator<Path, FileSystemListPathsResponse>;
    private listItems;
    private listSegments;
    private listPathsSegment;
    /**
     * Returns an async iterable iterator to list all the paths (directories and files)
     * under the specified file system.
     *
     * .byPage() returns an async iterable iterator to list the paths in pages.
     *
     * Example using `for await` syntax:
     *
     * ```js
     * // Get the fileSystemClient before you run these snippets,
     * // Can be obtained from `serviceClient.getFileSystemClient("<your-filesystem-name>");`
     * let i = 1;
     * for await (const deletePath of fileSystemClient.listDeletedPaths()) {
     *   console.log(`Path ${i++}: ${deletePath.name}`);
     * }
     * ```
     *
     * Example using `iter.next()`:
     *
     * ```js
     * let i = 1;
     * let iter = fileSystemClient.listDeletedPaths();
     * let deletedPathItem = await iter.next();
     * while (!deletedPathItem.done) {
     *   console.log(`Path ${i++}: ${deletedPathItem.value.name}`);
     *   pathItem = await iter.next();
     * }
     * ```
     *
     * Example using `byPage()`:
     *
     * ```js
     * // passing optional maxPageSize in the page settings
     * let i = 1;
     * for await (const response of fileSystemClient.listDeletedPaths().byPage({ maxPageSize: 20 })) {
     *   for (const deletePath of response.pathItems) {
     *     console.log(`Path ${i++}: ${deletePath.name}`);
     *   }
     * }
     * ```
     *
     * Example using paging with a marker:
     *
     * ```js
     * let i = 1;
     * let iterator = fileSystemClient.listDeletedPaths().byPage({ maxPageSize: 2 });
     * let response = (await iterator.next()).value;
     *
     * // Prints 2 path names
     * for (const path of response.pathItems) {
     *   console.log(`Path ${i++}: ${path.name}}`);
     * }
     *
     * // Gets next marker
     * let marker = response.continuationToken;
     *
     * // Passing next marker as continuationToken
     *
     * iterator = fileSystemClient.listDeletedPaths().byPage({ continuationToken: marker, maxPageSize: 10 });
     * response = (await iterator.next()).value;
     *
     * // Prints 10 path names
     * for (const deletePath of response.deletedPathItems) {
     *   console.log(`Path ${i++}: ${deletePath.name}`);
     * }
     * ```
     *
     * @see https://docs.microsoft.com/rest/api/storageservices/list-blobs
     *
     * @param options - Optional. Options when listing deleted paths.
     */
    listDeletedPaths(options?: ListDeletedPathsOptions): PagedAsyncIterableIterator<DeletedPath, FileSystemListDeletedPathsResponse>;
    private listDeletedItems;
    private listDeletedSegments;
    private listDeletedPathsSegment;
    /**
     * Restores a soft deleted path.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/undelete-blob
     *
     * @param deletedPath - Required.  The path of the deleted path.
     *
     * @param deletionId - Required.  The deletion ID associated with the soft deleted path.
     *
     */
    undeletePath(deletedPath: string, deletionId: string, options?: FileSystemUndeletePathOption): Promise<FileSystemUndeletePathResponse>;
    /**
     * Only available for DataLakeFileSystemClient constructed with a shared key credential.
     *
     * Generates a Service Shared Access Signature (SAS) URI based on the client properties
     * and parameters passed in. The SAS is signed by the shared key credential of the client.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas
     *
     * @param options - Optional parameters.
     * @returns The SAS URI consisting of the URI to the resource represented by this client, followed by the generated SAS token.
     */
    generateSasUrl(options: FileSystemGenerateSasUrlOptions): Promise<string>;
}
export declare class DataLakeLeaseClient {
    private readonly client;
    readonly leaseId: string;
    readonly url: string;
    constructor(client: BlobLeaseClient);
    acquireLease(duration: number, options?: LeaseOperationOptions): Promise<LeaseOperationResponse>;
    changeLease(proposedLeaseId: string, options?: LeaseOperationOptions): Promise<LeaseOperationResponse>;
    releaseLease(options?: LeaseOperationOptions): Promise<LeaseOperationResponse>;
    renewLease(options?: LeaseOperationOptions): Promise<Lease>;
    breakLease(breakPeriod: number, options?: LeaseOperationOptions): Promise<LeaseOperationResponse>;
}
/**
 * A DataLakePathClient represents a URL to the Azure Storage path (directory or file).
 */
export declare class DataLakePathClient extends StorageClient {
    /**
     * pathContext provided by protocol layer.
     */
    private pathContext;
    /**
     * blobClient provided by `@azure/storage-blob` package.
     */
    private blobClient;
    /**
     * SetAccessControlRecursiveInternal operation sets the Access Control on a path and sub paths.
     *
     * @param mode - Mode \"set\" sets POSIX access control rights on files and directories,
     *                                                 Mode \"modify\" modifies one or more POSIX access control rights that pre-exist on files and directories,
     *                                                 Mode \"remove\" removes one or more POSIX access control rights that were present earlier on files and directories.
     * @param acl - The POSIX access control list for the file or directory.
     * @param options - Optional. Options
     */
    private setAccessControlRecursiveInternal;
    /**
     * Creates an instance of DataLakePathClient from url and credential.
     *
     * @param url - A Client string pointing to Azure Storage data lake path (directory or file), such as
     *                     "https://myaccount.dfs.core.windows.net/filesystem/directory" or "https://myaccount.dfs.core.windows.net/filesystem/file".
     *                     You can append a SAS if using AnonymousCredential, such as "https://myaccount.dfs.core.windows.net/filesystem/directory?sasString".
     * @param credential - Such as AnonymousCredential, StorageSharedKeyCredential or any credential from the `@azure/identity` package to authenticate requests to the service. You can also provide an object that implements the TokenCredential interface. If not specified, AnonymousCredential is used.
     * @param options - Optional. Options to configure the HTTP pipeline.
     */
    constructor(url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions);
    /**
     * Creates an instance of DataLakePathClient from url and pipeline.
     *
     * @param url - A Client string pointing to Azure Storage data lake path (directory or file), such as
     *                     "https://myaccount.dfs.core.windows.net/filesystem/directory" or "https://myaccount.dfs.core.windows.net/filesystem/file".
     *                     You can append a SAS if using AnonymousCredential, such as "https://myaccount.dfs.core.windows.net/filesystem/directory?sasString".
     * @param pipeline - Call newPipeline() to create a default
     *                            pipeline, or provide a customized pipeline.
     */
    constructor(url: string, pipeline: Pipeline);
    readonly fileSystemName: string;
    readonly name: string;
    /**
     * Convert current DataLakePathClient to DataLakeDirectoryClient if current path is a directory.
     *
     */
    toDirectoryClient(): DataLakeDirectoryClient;
    /**
     * Convert current DataLakePathClient to DataLakeFileClient if current path is a file.
     *
     */
    toFileClient(): DataLakeFileClient;
    /**
     * Get a {@link DataLakeLeaseClient} that manages leases on the path (directory or file).
     *
     * @param proposeLeaseId - Optional. Initial proposed lease Id.
     */
    getDataLakeLeaseClient(proposeLeaseId?: string): DataLakeLeaseClient;
    /**
     * Create a directory or path.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
     *
     * @param resourceType - Resource type, "directory" or "file".
     * @param options - Optional. Options when creating path.
     */
    create(resourceType: PathResourceTypeModel, options?: PathCreateOptions): Promise<PathCreateResponse>;
    /**
     * Create a directory or file. If the resource already exists, it is not changed.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
     *
     * @param resourceType - Resource type, "directory" or "file".
     * @param options -
     */
    createIfNotExists(resourceType: PathResourceTypeModel, options?: PathCreateIfNotExistsOptions): Promise<PathCreateIfNotExistsResponse>;
    /**
     * Returns true if the Data Lake file represented by this client exists; false otherwise.
     *
     * NOTE: use this function with care since an existing file might be deleted by other clients or
     * applications. Vice versa new files might be added by other clients or applications after this
     * function completes.
     *
     * @param options - options to Exists operation.
     */
    exists(options?: PathExistsOptions): Promise<boolean>;
    /**
     * Delete current path (directory or file).
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete
     *
     * @param recursive - Required and valid only when the resource is a directory. If "true", all paths beneath the directory will be deleted.
     * @param options - Optional. Options when deleting path.
     */
    delete(recursive?: boolean, options?: PathDeleteOptions): Promise<PathDeleteResponse>;
    /**
     * Delete current path (directory or file) if it exists.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete
     *
     * @param recursive - Required and valid only when the resource is a directory. If "true", all paths beneath the directory will be deleted.
     * @param options -
     */
    deleteIfExists(recursive?: boolean, options?: PathDeleteOptions): Promise<PathDeleteIfExistsResponse>;
    /**
     * Returns the access control data for a path (directory of file).
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/getproperties
     *
     * @param options - Optional. Options when getting file access control.
     */
    getAccessControl(options?: PathGetAccessControlOptions): Promise<PathGetAccessControlResponse>;
    /**
     * Set the access control data for a path (directory of file).
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update
     *
     * @param acl - The POSIX access control list for the file or directory.
     * @param options - Optional. Options when setting path access control.
     */
    setAccessControl(acl: PathAccessControlItem[], options?: PathSetAccessControlOptions): Promise<PathSetAccessControlResponse>;
    /**
     * Sets the Access Control on a path and sub paths.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update
     *
     * @param acl - The POSIX access control list for the file or directory.
     * @param options - Optional. Options
     */
    setAccessControlRecursive(acl: PathAccessControlItem[], options?: PathChangeAccessControlRecursiveOptions): Promise<PathChangeAccessControlRecursiveResponse>;
    /**
     * Modifies the Access Control on a path and sub paths.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update
     *
     * @param acl - The POSIX access control list for the file or directory.
     * @param options - Optional. Options
     */
    updateAccessControlRecursive(acl: PathAccessControlItem[], options?: PathChangeAccessControlRecursiveOptions): Promise<PathChangeAccessControlRecursiveResponse>;
    /**
     * Removes the Access Control on a path and sub paths.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update
     *
     * @param acl - The POSIX access control list for the file or directory.
     * @param options - Optional. Options
     */
    removeAccessControlRecursive(acl: RemovePathAccessControlItem[], options?: PathChangeAccessControlRecursiveOptions): Promise<PathChangeAccessControlRecursiveResponse>;
    /**
     * Sets the file permissions on a path.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update
     *
     * @param permissions - The POSIX access permissions for the file owner, the file owning group, and others.
     * @param options - Optional. Options when setting path permissions.
     */
    setPermissions(permissions: PathPermissions, options?: PathSetPermissionsOptions): Promise<PathSetAccessControlResponse>;
    /**
     * Returns all user-defined metadata, standard HTTP properties, and system properties
     * for the path (directory or file).
     *
     * WARNING: The `metadata` object returned in the response will have its keys in lowercase, even if
     * they originally contained uppercase characters. This differs from the metadata keys returned by
     * the methods of {@link DataLakeFileSystemClient} that list paths using the `includeMetadata` option, which
     * will retain their original casing.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob-properties
     *
     * @param options - Optional. Options when getting path properties.
     */
    getProperties(options?: PathGetPropertiesOptions): Promise<PathGetPropertiesResponse>;
    /**
     * Sets system properties on the path (directory or file).
     *
     * If no value provided, or no value provided for the specified blob HTTP headers,
     * these blob HTTP headers without a value will be cleared.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-blob-properties
     *
     * @param httpHeaders -
     * @param options -
     */
    setHttpHeaders(httpHeaders: PathHttpHeaders, options?: PathSetHttpHeadersOptions): Promise<PathSetHttpHeadersResponse>;
    /**
     * Sets user-defined metadata for the specified path (directory of file) as one or more name-value pairs.
     *
     * If no option provided, or no metadata defined in the parameter, the path
     * metadata will be removed.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-blob-metadata
     *
     * @param metadata - Optional. Replace existing metadata with this value.
     *                              If no value provided the existing metadata will be removed.
     * @param options - Optional. Options when setting path metadata.
     */
    setMetadata(metadata?: Metadata, options?: PathSetMetadataOptions): Promise<PathSetMetadataResponse>;
    /**
     * Move directory or file within same file system.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
     *
     * @param destinationPath - Destination directory path like "directory" or file path "directory/file".
     *                                 If the destinationPath is authenticated with SAS, add the SAS to the destination path like "directory/file?sasToken".
     * @param options - Optional. Options when moving directory or file.
     */
    move(destinationPath: string, options?: PathMoveOptions): Promise<PathMoveResponse>;
    /**
     * Move directory or file to another file system.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
     *
     * @param destinationFileSystem - Destination file system like "filesystem".
     * @param destinationPath - Destination directory path like "directory" or file path "directory/file"
     *                                 If the destinationPath is authenticated with SAS, add the SAS to the destination path like "directory/file?sasToken".
     * @param options - Optional. Options when moving directory or file.
     */
    move(destinationFileSystem: string, destinationPath: string, options?: PathMoveOptions): Promise<PathMoveResponse>;
}
export declare interface DataLakeRequestConditions extends ModifiedAccessConditions, LeaseAccessConditions {
}
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * This is a helper class to construct a string representing the permissions granted by a ServiceSAS. Setting
 * a value to true means that any SAS which uses these permissions will grant permissions for that operation. Once all
 * the values are set, this should be serialized with toString and set as the permissions field on a
 * {@link DataLakeSASSignatureValues} object. It is possible to construct the permissions string without this class, but
 * the order of the permissions is particular and this class guarantees correctness.
 */
export declare class DataLakeSASPermissions {
    /**
     * Creates a {@link DataLakeSASPermissions} from the specified permissions string. This method will throw an
     * Error if it encounters a character that does not correspond to a valid permission.
     *
     * @param permissions -
     */
    static parse(permissions: string): DataLakeSASPermissions;
    /**
     * Specifies Read access granted.
     */
    read: boolean;
    /**
     * Specifies Add access granted.
     */
    add: boolean;
    /**
     * Specifies Create access granted.
     */
    create: boolean;
    /**
     * Specifies Write access granted.
     */
    write: boolean;
    /**
     * Specifies Delete access granted.
     */
    delete: boolean;
    /**
     * Specifies Move access granted.
     */
    move: boolean;
    /**
     * Specifies Execute access granted.
     */
    execute: boolean;
    /**
     * Specifies Ownership access granted, which allows the caller to set owner, owning group,
     * or act as the owner when renaming or deleting a blob (file or directory) within a folder
     * that has the sticky bit set.
     */
    manageOwnership: boolean;
    /**
     * Specifies Permission access granted, which allows the caller to set permissions and
     * POSIX ACLs on blobs (files and directories).
     */
    manageAccessControl: boolean;
    /**
     * Converts the given permissions to a string. Using this method will guarantee the permissions are in an
     * order accepted by the service.
     *
     * @returns A string which represents the DataLakeSASPermissions
     */
    toString(): string;
}
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * DataLakeSASSignatureValues is used to help generating Blob and DataLake service SAS tokens for containers, blobs, filesystem, directories and files.
 */
export declare interface DataLakeSASSignatureValues {
    /**
     * The version of the service this SAS will target. If not specified, it will default to the version targeted by the
     * library.
     */
    version?: string;
    /**
     * Optional. SAS protocols, HTTPS only or HTTPSandHTTP
     */
    protocol?: SASProtocol;
    /**
     * Optional. When the SAS will take effect.
     */
    startsOn?: Date;
    /**
     * Optional only when identifier is provided. The time after which the SAS will no longer work.
     */
    expiresOn?: Date;
    /**
     * Optional only when identifier is provided.
     * Please refer to {@link FileSystemSASPermissions}, {@link DirectorySASPermissions} or {@link DataLakeSASPermissions} depending on the resource
     * being accessed for help constructing the permissions string.
     */
    permissions?: DataLakeSASPermissions | DirectorySASPermissions | FileSystemSASPermissions;
    /**
     * Optional. IP ranges allowed in this SAS.
     */
    ipRange?: SasIPRange;
    /**
     * The name of the file system the SAS user may access.
     */
    fileSystemName: string;
    /**
     * Optional. The path name of the directory or file SAS user may access. Required if snapshotTime is provided.
     */
    pathName?: string;
    /**
     * Optional. Beginning in version 2020-02-10, this value defines whether or not the {@link pathName} is a directory.
     * If this value is set to true, the Path is a Directory for a Directory SAS. If set to false or default, the Path
     * is a File Path for a File Path SAS.
     */
    isDirectory?: boolean;
    /**
     * Optional. Beginning in version 2020-02-10, indicate the depth of the directory specified in the canonicalizedresource field of the string-to-sign.
     * The depth of the directory is the number of directories beneath the root folder.
     */
    directoryDepth?: number;
    /**
     * Optional. Beginning in version 2020-02-10, specifies the Authorized AAD Object Id in GUID format. The AAD Object ID of a user
     * authorized by the owner of the user delegation key to perform the action granted by the SAS. The Azure Storage service will
     * ensure that the owner of the user delegation key has the required permissions before granting access but no additional permission
     * check for the user specified in this value will be performed. This cannot be used in conjuction with {@link agentObjectId}.
     * This is only used for User Delegation SAS.
     */
    preauthorizedAgentObjectId?: string;
    /**
     * Optional. Beginning in version 2020-02-10, specifies the Unauthorized AAD Object Id in GUID format. The AAD Object Id of a user that is assumed
     * to be unauthorized by the owner of the user delegation key. The Azure Storage Service will perform an additional POSIX ACL check to determine
     * if the user is authorized to perform the requested operation. This cannot be used in conjuction with {@link preauthorizedAgentObjectId}.
     * This is only used for User Delegation SAS.
     */
    agentObjectId?: string;
    /**
     * Optional. Beginning in version 2020-02-10, this is a GUID value that will be logged in the storage diagnostic logs and can be used to
     * correlate SAS generation with storage resource access. This is only used for User Delegation SAS.
     */
    correlationId?: string;
    /**
     * Optional. Snapshot timestamp string the SAS user may access. Only supported from API version 2018-11-09.
     */
    snapshotTime?: string;
    /**
     * Optional. The name of the access policy on the file system this SAS references if any.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/establishing-a-stored-access-policy
     */
    identifier?: string;
    /**
     * Optional. The cache-control header for the SAS.
     */
    cacheControl?: string;
    /**
     * Optional. The content-disposition header for the SAS.
     */
    contentDisposition?: string;
    /**
     * Optional. The content-encoding header for the SAS.
     */
    contentEncoding?: string;
    /**
     * Optional. The content-language header for the SAS.
     */
    contentLanguage?: string;
    /**
     * Optional. The content-type header for the SAS.
     */
    contentType?: string;
}
/**
 * DataLakeServiceClient allows you to manipulate Azure
 * Data Lake service resources and file systems. The storage account provides
 * the top-level namespace for the Data Lake service.
 */
export declare class DataLakeServiceClient extends StorageClient {
    /**
     * blobServiceClient provided by `@azure/storage-blob` package.
     */
    private blobServiceClient;
    /**
     *
     * Creates an instance of DataLakeServiceClient from connection string.
     *
     * @param connectionString - Account connection string or a SAS connection string of an Azure storage account.
     *                                  [ Note - Account connection string can only be used in NODE.JS runtime. ]
     *                                  Account connection string example -
     *                                  `DefaultEndpointsProtocol=https;AccountName=myaccount;AccountKey=accountKey;EndpointSuffix=core.windows.net`
     *                                  SAS connection string example -
     *                                  `BlobEndpoint=https://myaccount.blob.core.windows.net/;QueueEndpoint=https://myaccount.queue.core.windows.net/;FileEndpoint=https://myaccount.file.core.windows.net/;TableEndpoint=https://myaccount.table.core.windows.net/;SharedAccessSignature=sasString`
     * @param options - Optional. Options to configure the HTTP pipeline.
     */
    static fromConnectionString(connectionString: string, options?: StoragePipelineOptions): DataLakeServiceClient;
    /**
     * Creates an instance of DataLakeServiceClient from url.
     *
     * @param url - A Client string pointing to Azure Storage data lake service, such as
     *                     "https://myaccount.dfs.core.windows.net". You can append a SAS
     *                     if using AnonymousCredential, such as "https://myaccount.dfs.core.windows.net?sasString".
     * @param credential - Such as AnonymousCredential, StorageSharedKeyCredential or any credential from the `@azure/identity` package to authenticate requests to the service. You can also provide an object that implements the TokenCredential interface. If not specified, AnonymousCredential is used.
     * @param options - Optional. Options to configure the HTTP pipeline.
     */
    constructor(url: string, credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, options?: StoragePipelineOptions);
    /**
     * Creates an instance of DataLakeServiceClient from url and pipeline.
     *
     * @param url - A Client string pointing to Azure Storage data lake service, such as
     *                     "https://myaccount.dfs.core.windows.net". You can append a SAS
     *                     if using AnonymousCredential, such as "https://myaccount.dfs.core.windows.net?sasString".
     * @param pipeline - Call newPipeline() to create a default
     *                            pipeline, or provide a customized pipeline.
     */
    constructor(url: string, pipeline: Pipeline);
    /**
     * Creates a {@link DataLakeFileSystemClient} object.
     *
     * @param fileSystemName - File system name.
     */
    getFileSystemClient(fileSystemName: string): DataLakeFileSystemClient;
    /**
     * ONLY AVAILABLE WHEN USING BEARER TOKEN AUTHENTICATION (TokenCredential).
     *
     * Retrieves a user delegation key for the Data Lake service. This is only a valid operation when using
     * bearer token authentication.
     *
     * @example
     * ```js
     * // Generate user delegation SAS for a file system
     * const userDelegationKey = await dataLakeServiceClient.getUserDelegationKey(startsOn, expiresOn);
     * const fileSystemSAS = generateDataLakeSASQueryParameters({
     *     fileSystemName, // Required
     *     permissions: FileSystemSASPermissions.parse("racwdl"), // Required
     *     startsOn, // Required. Date type
     *     expiresOn, // Optional. Date type
     *     ipRange: { start: "0.0.0.0", end: "255.255.255.255" }, // Optional
     *     protocol: SASProtocol.HttpsAndHttp, // Optional
     *     version: "2018-11-09" // Must greater than or equal to 2018-11-09 to generate user delegation SAS
     *   },
     *   userDelegationKey, // UserDelegationKey
     *   accountName
     * ).toString();
     * ```
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-user-delegation-key
     *
     * @param startsOn - The start time for the user delegation SAS. Must be within 7 days of the current time.
     * @param expiresOn - The end time for the user delegation SAS. Must be within 7 days of the current time.
     * @param options -
     */
    getUserDelegationKey(startsOn: Date, expiresOn: Date, options?: ServiceGetUserDelegationKeyOptions): Promise<ServiceGetUserDelegationKeyResponse>;
    /**
     * Returns an async iterable iterator to list all the file systems
     * under the specified account.
     *
     * .byPage() returns an async iterable iterator to list the file systems in pages.
     *
     * Example using `for await` syntax:
     *
     * ```js
     * let i = 1;
     * for await (const fileSystem of serviceClient.listFileSystems()) {
     *   console.log(`FileSystem ${i++}: ${fileSystem.name}`);
     * }
     * ```
     *
     * Example using `iter.next()`:
     *
     * ```js
     * let i = 1;
     * const iter = serviceClient.listFileSystems();
     * let fileSystemItem = await iter.next();
     * while (!fileSystemItem.done) {
     *   console.log(`FileSystem ${i++}: ${fileSystemItem.value.name}`);
     *   fileSystemItem = await iter.next();
     * }
     * ```
     *
     * Example using `byPage()`:
     *
     * ```js
     * // passing optional maxPageSize in the page settings
     * let i = 1;
     * for await (const response of serviceClient.listFileSystems().byPage({ maxPageSize: 20 })) {
     *   if (response.fileSystemItems) {
     *     for (const fileSystem of response.fileSystemItems) {
     *       console.log(`FileSystem ${i++}: ${fileSystem.name}`);
     *     }
     *   }
     * }
     * ```
     *
     * Example using paging with a marker:
     *
     * ```js
     * let i = 1;
     * let iterator = serviceClient.listFileSystems().byPage({ maxPageSize: 2 });
     * let response = (await iterator.next()).value;
     *
     * // Prints 2 file system names
     * if (response.fileSystemItems) {
     *   for (const fileSystem of response.fileSystemItems) {
     *     console.log(`FileSystem ${i++}: ${fileSystem.name}`);
     *   }
     * }
     *
     * // Gets next marker
     * let marker = response.continuationToken;
     * // Passing next marker as continuationToken
     * iterator = serviceClient
     *   .listContainers()
     *   .byPage({ continuationToken: marker, maxPageSize: 10 });
     * response = (await iterator.next()).value;
     *
     * // Prints 10 file system names
     * if (response.fileSystemItems) {
     *   for (const fileSystem of response.fileSystemItems) {
     *      console.log(`FileSystem ${i++}: ${fileSystem.name}`);
     *   }
     * }
     * ```
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/list-containers2
     *
     * @param options -
     */
    listFileSystems(options?: ServiceListFileSystemsOptions): PagedAsyncIterableIterator<FileSystemItem, ServiceListFileSystemsSegmentResponse>;
    /**
     * Only available for DataLakeServiceClient constructed with a shared key credential.
     *
     * Generates an account Shared Access Signature (SAS) URI based on the client properties
     * and parameters passed in. The SAS is signed by the shared key credential of the client.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/create-account-sas
     *
     * @param expiresOn - Optional. The time at which the shared access signature becomes invalid. Default to an hour later if not specified.
     * @param permissions - Specifies the list of permissions to be associated with the SAS.
     * @param resourceTypes - Specifies the resource types associated with the shared access signature.
     * @param options - Optional parameters.
     * @returns An account SAS URI consisting of the URI to the resource represented by this client, followed by the generated SAS token.
     */
    generateAccountSasUrl(expiresOn?: Date, permissions?: AccountSASPermissions, resourceTypes?: string, options?: ServiceGenerateAccountSasUrlOptions): string;
    /**
     * Renames an existing File System.
     *
     * @param sourceFileSystemName - The name of the source File System.
     * @param destinationContainerName - The new name of the File System.
     * @param options - Options to configure File System Rename operation.
     */
    private renameFileSystem;
    /**
     * Restore a previously deleted File System.
     * This API is only functional if Container Soft Delete is enabled for the storage account.
     *
     * @param deletedFileSystemName - The name of the source File System.
     * @param deleteFileSystemVersion - The new name of the File System.
     * @param options - Options to configure File System Restore operation.
     */
    undeleteFileSystem(deletedFileSystemName: string, deleteFileSystemVersion: string, options?: ServiceUndeleteFileSystemOptions): Promise<{
        fileSystemClient: DataLakeFileSystemClient;
        fileSystemUndeleteResponse: FileSystemUndeleteResponse;
    }>;
    /**
     * Gets the properties of a storage accounts Blob service endpoint, including properties
     * for Storage Analytics and CORS (Cross-Origin Resource Sharing) rules.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob-service-properties
     *
     * @param options - Options to the Service Get Properties operation.
     * @returns Response data for the Service Get Properties operation.
     */
    getProperties(options?: ServiceGetPropertiesOptions): Promise<DataLakeServiceGetPropertiesResponse>;
    /**
     * Sets properties for a storage accounts Blob service endpoint, including properties
     * for Storage Analytics, CORS (Cross-Origin Resource Sharing) rules and soft delete settings.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-blob-service-properties
     *
     * @param properties -
     * @param options - Options to the Service Set Properties operation.
     * @returns Response data for the Service Set Properties operation.
     */
    setProperties(properties: DataLakeServiceProperties, options?: ServiceSetPropertiesOptions): Promise<ServiceSetPropertiesResponse>;
}
export { DataLakeServiceGetPropertiesResponse };
export { DataLakeServiceProperties };
export declare interface DeletedPath {
    name: string;
    deletionId?: string;
    deletedOn?: Date;
    remainingRetentionDays?: number;
}
export declare interface DeletedPathList {
    pathItems?: DeletedPath[];
}
export { deserializationPolicy };
export declare interface DirectoryCreateIfNotExistsOptions extends PathCreateIfNotExistsOptions {
}
export declare interface DirectoryCreateIfNotExistsResponse extends PathCreateIfNotExistsResponse {
}
/** **************************************************************/
/** DataLakeDirectoryClient option and response related models **/
/** **************************************************************/
export declare interface DirectoryCreateOptions extends PathCreateOptions {
}
export declare interface DirectoryCreateResponse extends PathCreateResponse {
}
/**
 * Options to configure {@link DataLakeDirectoryClient.generateSasUrl} operation.
 */
export declare interface DirectoryGenerateSasUrlOptions extends CommonGenerateSasUrlOptions {
    /**
     * Optional only when identifier is provided. Specifies the list of permissions to be associated with the SAS.
     */
    permissions?: DirectorySASPermissions;
}
/**
 * This is a helper class to construct a string representing the permissions granted by a ServiceSAS to a directory.
 * Setting a value to true means that any SAS which uses these permissions will grant permissions for that operation.
 * Once all the values are set, this should be serialized with toString and set as the permissions field on a
 * {@link DataLakeSASSignatureValues} object. It is possible to construct the permissions string without this class, but
 * the order of the permissions is particular and this class guarantees correctness.
 */
export declare class DirectorySASPermissions {
    /**
     * Creates an {@link DirectorySASPermissions} from the specified permissions string. This method will throw an
     * Error if it encounters a character that does not correspond to a valid permission.
     *
     * @param permissions -
     */
    static parse(permissions: string): DirectorySASPermissions;
    /**
     * Specifies Read access granted.
     */
    read: boolean;
    /**
     * Specifies Add access granted.
     */
    add: boolean;
    /**
     * Specifies Create access granted.
     */
    create: boolean;
    /**
     * Specifies Write access granted.
     */
    write: boolean;
    /**
     * Specifies Delete access granted.
     */
    delete: boolean;
    /**
     * Specifies List access granted.
     */
    list: boolean;
    /**
     * Specifies Move access granted.
     */
    move: boolean;
    /**
     * Specifies Execute access granted.
     */
    execute: boolean;
    /**
     * Specifies Ownership access granted, which allows the caller to set owner, owning group,
     * or act as the owner when renaming or deleting a blob (file or directory) within a folder
     * that has the sticky bit set.
     */
    manageOwnership: boolean;
    /**
     * Specifies Permission access granted, which allows the caller to set permissions and
     * POSIX ACLs on blobs (files and directories).
     */
    manageAccessControl: boolean;
    /**
     * Converts the given permissions to a string. Using this method will guarantee the permissions are in an
     * order accepted by the service.
     *
     * The order of the characters should be as specified here to ensure correctness.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas
     *
     */
    toString(): string;
}
export declare interface FileAppendOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    conditions?: LeaseAccessConditions;
    transactionalContentMD5?: Uint8Array;
    onProgress?: (progress: TransferProgressEvent) => void;
}
/** Contains response data for the appendData operation. */
export declare type FileAppendResponse = PathAppendDataHeaders & {
    /** The underlying HTTP response. */
    _response: coreHttp.HttpResponse & {
        /** The parsed HTTP response headers. */
        parsedHeaders: PathAppendDataHeaders;
    };
};
export declare interface FileCreateIfNotExistsOptions extends PathCreateIfNotExistsOptions {
}
export declare interface FileCreateIfNotExistsResponse extends PathCreateIfNotExistsResponse {
}
export declare interface FileCreateOptions extends PathCreateOptions {
}
export declare interface FileCreateResponse extends PathCreateResponse {
}
/** Defines values for PathExpiryOptions. */
export declare type FileExpiryMode = "NeverExpire" | "RelativeToCreation" | "RelativeToNow" | "Absolute";
export declare interface FileFlushOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    conditions?: DataLakeRequestConditions;
    retainUncommittedData?: boolean;
    close?: boolean;
    pathHttpHeaders?: PathHttpHeaders;
}
/**
 * Options to configure {@link DataLakeFileClient.generateSasUrl} operation.
 */
export declare interface FileGenerateSasUrlOptions extends CommonGenerateSasUrlOptions {
    /**
     * Optional only when identifier is provided. Specifies the list of permissions to be associated with the SAS.
     */
    permissions?: DataLakeSASPermissions;
}
/**
 * Option interface for Data Lake file - Upload operations
 *
 * See:
 * - {@link DataLakeFileClient.upload}
 * - {@link DataLakeFileClient.uploadFile}
 * - {@link DataLakeFileClient.uploadStream}
 */
export declare interface FileParallelUploadOptions extends CommonOptions {
    /**
     * An implementation of the `AbortSignalLike` interface to signal the request to cancel the operation.
     * For example, use the &commat;azure/abort-controller to create an `AbortSignal`.
     */
    abortSignal?: AbortSignalLike;
    /**
     * Access conditions headers.
     */
    conditions?: DataLakeRequestConditions;
    /**
     * Http headers.
     */
    pathHttpHeaders?: PathHttpHeaders;
    /**
     * A collection of key-value string pair to associate with the Data Lake file.
     */
    metadata?: Metadata;
    /**
     * Sets POSIX access permissions for the file owner, the file owning group, and others.
     * Each class may be granted read, write, or execute permission. The sticky bit is also supported.
     * Both symbolic (rwxrw-rw-) and 4-digit octal notation (e.g. 0766) are supported.
     */
    permissions?: string;
    /**
     * The umask restricts the permissions of the file to be created.
     * The resulting permission is given by p & ^u, where p is the permission and u is the umask.
     * For example, if p is 0777 and u is 0057, then the resulting permission is 0720.
     * The default permission is 0666 for a file. The default umask is 0027.
     * The umask must be specified in 4-digit octal notation (e.g. 0766).
     */
    umask?: string;
    /**
     * Progress updater.
     */
    onProgress?: (progress: TransferProgressEvent) => void;
    /**
     * When Azure Storage Events are enabled, a file changed event is raised.
     * This event has a property indicating whether this is the final change
     * to distinguish the difference between an intermediate flush to a file stream (when close set to "false")
     * and the final close of a file stream (when close set to "true").
     */
    close?: boolean;
    /**
     * Data size threshold in bytes to use a single upload operation rather than parallel uploading.
     * Data of smaller size than this limit will be transferred in a single upload.
     * Data larger than this limit will be transferred in chunks in parallel.
     * Its default and max value is FILE_MAX_SINGLE_UPLOAD_THRESHOLD.
     * Note: {@link DataLakeFileClient.uploadStream} do not respect this field and always do parallel uploading.
     */
    singleUploadThreshold?: number;
    /**
     * The size of data in bytes that will be transferred in parallel.
     * If set to 0 or undefined, it will be automatically calculated according
     * to the data size. Its max value is FILE_UPLOAD_MAX_CHUNK_SIZE.
     */
    chunkSize?: number;
    /**
     * Max concurrency of parallel uploading. Must be greater than or equal to 0. Its default value is DEFAULT_HIGH_LEVEL_CONCURRENCY.
     */
    maxConcurrency?: number;
}
/**
 * Options to query file with Apache Arrow format. Only valid for {@link FileQueryOptions.outputTextConfiguration}.
 */
export declare type FileQueryArrowConfiguration = BlobQueryArrowConfiguration;
/**
 * Options to query file with CSV format.
 */
export declare interface FileQueryCsvTextConfiguration {
    /**
     * Record separator.
     */
    recordSeparator: string;
    /**
     * Query for a CSV format file.
     */
    kind: "csv";
    /**
     * Column separator. Default is ",".
     */
    columnSeparator?: string;
    /**
     * Field quote.
     */
    fieldQuote?: string;
    /**
     * Escape character.
     */
    escapeCharacter?: string;
    /**
     * Has headers. Default is false.
     */
    hasHeaders?: boolean;
}
/**
 * File query error type.
 */
export declare interface FileQueryError {
    /**
     * Whether the error is fatal or not. A fatal error will stop the query.
     */
    isFatal: boolean;
    /**
     * Error name.
     */
    name: string;
    /**
     * Position in bytes of the query.
     */
    position: number;
    /**
     * Error description.
     */
    description: string;
}
/**
 * Options to query file with JSON format.
 */
export declare interface FileQueryJsonTextConfiguration {
    /**
     * Record separator.
     */
    recordSeparator: string;
    /**
     * Query for a JSON format file.
     */
    kind: "json";
}
/**
 * Option interface for Data Lake file - query operations
 *
 * See:
 * - {@link DataLakeFileClient.query}
 */
export declare interface FileQueryOptions extends CommonOptions {
    /**
     * An implementation of the `AbortSignalLike` interface to signal the request to cancel the operation.
     * For example, use the &commat;azure/abort-controller to create an `AbortSignal`.
     */
    abortSignal?: AbortSignalLike;
    /**
     * Configurations for the query input.
     */
    inputTextConfiguration?: FileQueryJsonTextConfiguration | FileQueryCsvTextConfiguration | FileQueryParquetConfiguration;
    /**
     * Configurations for the query output.
     */
    outputTextConfiguration?: FileQueryJsonTextConfiguration | FileQueryCsvTextConfiguration | FileQueryArrowConfiguration;
    /**
     * Callback to receive events on the progress of query operation.
     */
    onProgress?: (progress: TransferProgressEvent) => void;
    /**
     * Callback to receive error events during the query operaiton.
     */
    onError?: (error: FileQueryError) => void;
    /**
     * Conditions to meet when uploading to the block file.
     */
    conditions?: DataLakeRequestConditions;
}
/**
 * Options to query file with Parquet format.
 */
export declare interface FileQueryParquetConfiguration {
    /**
     * Kind.
     */
    kind: "parquet";
}
export declare interface FileReadHeaders {
    lastModified?: Date;
    metadata?: Metadata;
    contentLength?: number;
    contentType?: string;
    contentRange?: string;
    etag?: string;
    contentMD5?: Uint8Array;
    contentEncoding?: string;
    cacheControl?: string;
    contentDisposition?: string;
    contentLanguage?: string;
    copyCompletedOn?: Date;
    copyStatusDescription?: string;
    copyId?: string;
    copyProgress?: string;
    copySource?: string;
    copyStatus?: CopyStatusType;
    leaseDuration?: LeaseDurationType;
    leaseState?: LeaseStateType;
    leaseStatus?: LeaseStatusType;
    clientRequestId?: string;
    requestId?: string;
    version?: string;
    acceptRanges?: string;
    date?: Date;
    isServerEncrypted?: boolean;
    encryptionKeySha256?: string;
    fileContentMD5?: Uint8Array;
    contentCrc64?: Uint8Array;
}
/** *********************************************************/
/** DataLakeFileClient option and response related models **/
/** *********************************************************/
export declare interface FileReadOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    rangeGetContentMD5?: boolean;
    rangeGetContentCrc64?: boolean;
    conditions?: DataLakeRequestConditions;
    onProgress?: (progress: TransferProgressEvent) => void;
    maxRetryRequests?: number;
}
export declare type FileReadResponse = FileReadHeaders & {
    contentAsBlob?: Promise<Blob>;
    readableStreamBody?: NodeJS.ReadableStream;
    _response: HttpResponse & {
        parsedHeaders: FileReadHeaders;
    };
};
/**
 * Option interface for Data Lake file - readToBuffer operations
 *
 * See:
 * - {@link DataLakeFileClient.readToBuffer}
 */
export declare interface FileReadToBufferOptions extends CommonOptions {
    /**
     * An implementation of the `AbortSignalLike` interface to signal the request to cancel the operation.
     * For example, use the &commat;azure/abort-controller to create an `AbortSignal`.
     */
    abortSignal?: AbortSignalLike;
    /**
     * Access conditions headers.
     */
    conditions?: DataLakeRequestConditions;
    /**
     * Progress updater.
     */
    onProgress?: (progress: TransferProgressEvent) => void;
    /**
     * How many retries will perform for each read when the original chunk read stream ends unexpectedly.
     * Above kind of ends will not trigger retry policy defined in a pipeline,
     * because they doesn't emit network errors. Default value is 5.
     */
    maxRetryRequestsPerChunk?: number;
    /**
     * chunkSize is size of data every request trying to read.
     * Must be greater than or equal to 0, if set to 0 or undefined, it will automatically calculated according
     * to the file size.
     */
    chunkSize?: number;
    /**
     * Concurrency of parallel read.
     */
    concurrency?: number;
}
/** Defines headers for Path_setExpiry operation. */
export declare interface FileSetExpiryHeaders {
    /** The ETag contains a value that you can use to perform operations conditionally. If the request version is 2011-08-18 or newer, the ETag value will be in quotes. */
    etag?: string;
    /** Returns the date and time the container was last modified. Any operation that modifies the blob, including an update of the blob's metadata or properties, changes the last-modified time of the blob. */
    lastModified?: Date;
    /** If a client request id header is sent in the request, this header will be present in the response with the same value. */
    clientRequestId?: string;
    /** This header uniquely identifies the request that was made and can be used for troubleshooting the request. */
    requestId?: string;
    /** Indicates the version of the Blob service used to execute the request. This header is returned for requests made against version 2009-09-19 and above. */
    version?: string;
    /** UTC date/time value generated by the service that indicates the time at which the response was initiated. */
    date?: Date;
    /** Error Code */
    errorCode?: string;
}
/**
 * Option interface for the {@link DataLakeFileClient.setExpiry} operation.
 */
export declare interface FileSetExpiryOptions extends CommonOptions {
    /**
     * An implementation of the `AbortSignalLike` interface to signal the request to cancel the operation.
     * For example, use the &commat;azure/abort-controller to create an `AbortSignal`.
     */
    abortSignal?: AbortSignalLike;
    /**
     * The time to set the file to expire on, used in combination with the "Absolute" {@link FileExpiryMode}.
     * A time in the past is not allowed and milliseconds will be dropped.
     */
    expiresOn?: Date;
    /**
     * The number of milliseconds to elapse before the file expires, used in combination with the "RelativeToCreation" or "RelativeToNow" {@link FileExpiryMode}.
     */
    timeToExpireInMs?: number;
}
/** Contains response data for the setExpiry operation. */
export declare type FileSetExpiryResponse = FileSetExpiryHeaders & {
    /** The underlying HTTP response. */
    _response: coreHttp.HttpResponse & {
        /** The parsed HTTP response headers. */
        parsedHeaders: FileSetExpiryHeaders;
    };
};
export declare interface FileSystemCreateHeaders {
    etag?: string;
    lastModified?: Date;
    clientRequestId?: string;
    requestId?: string;
    version?: string;
    date?: Date;
}
/**
 * Contains response data for the {@link DataLakeFileSystemClient.createIfNotExists} operation.
 */
export declare interface FileSystemCreateIfNotExistsResponse extends FileSystemCreateResponse {
    /**
     * Indicate whether the file system is successfully created. Is false when the file system is not changed as it already exists.
     */
    succeeded: boolean;
}
/** **************************************************************/
/** DataLakeFileSystemClient option and response related models */
/** **************************************************************/
export declare interface FileSystemCreateOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    metadata?: Metadata;
    access?: PublicAccessType;
}
export declare type FileSystemCreateResponse = FileSystemCreateHeaders & {
    _response: HttpResponse & {
        parsedHeaders: FileSystemCreateHeaders;
    };
};
export declare interface FileSystemDeleteHeaders {
    clientRequestId?: string;
    requestId?: string;
    version?: string;
    date?: Date;
}
/**
 * Contains response data for the {@link DataLakeFileSystemClient.deleteIfExists} operation.
 */
export declare interface FileSystemDeleteIfExistsResponse extends FileSystemDeleteResponse {
    /**
     * Indicate whether the file system is successfully deleted. Is false if the file system doesn't exist in the first place.
     */
    succeeded: boolean;
}
export declare interface FileSystemDeleteOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    conditions?: DataLakeRequestConditions;
}
export declare type FileSystemDeleteResponse = FileSystemDeleteHeaders & {
    _response: HttpResponse & {
        parsedHeaders: FileSystemDeleteHeaders;
    };
};
/**
 * Option interface for Data Lake file system exists operations
 *
 * See:
 * - {@link DataLakeFileSystemClient.exists}
 */
export declare interface FileSystemExistsOptions extends CommonOptions {
    /**
     * An implementation of the `AbortSignalLike` interface to signal the request to cancel the operation.
     * For example, use the &commat;azure/abort-controller to create an `AbortSignal`.
     */
    abortSignal?: AbortSignalLike;
}
/**
 * Options to configure {@link DataLakeFileSystemClient.generateSasUrl} operation.
 */
export declare interface FileSystemGenerateSasUrlOptions extends CommonGenerateSasUrlOptions {
    /**
     * Optional only when identifier is provided. Specifies the list of permissions to be associated with the SAS.
     */
    permissions?: FileSystemSASPermissions;
}
export declare interface FileSystemGetAccessPolicyHeaders {
    publicAccess?: PublicAccessType;
    etag?: string;
    lastModified?: Date;
    clientRequestId?: string;
    requestId?: string;
    version?: string;
    date?: Date;
}
export declare interface FileSystemGetAccessPolicyOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    conditions?: LeaseAccessConditions;
}
export declare type FileSystemGetAccessPolicyResponse = {
    signedIdentifiers: SignedIdentifier<AccessPolicy>[];
} & FileSystemGetAccessPolicyHeaders & {
    _response: HttpResponse & {
        parsedHeaders: FileSystemGetAccessPolicyHeaders;
        bodyAsText: string;
        parsedBody: SignedIdentifier<RawAccessPolicy>[];
    };
};
export declare interface FileSystemGetPropertiesHeaders {
    metadata?: Metadata;
    etag?: string;
    lastModified?: Date;
    leaseDuration?: LeaseDurationType;
    leaseState?: LeaseStateType;
    leaseStatus?: LeaseStatusType;
    clientRequestId?: string;
    requestId?: string;
    version?: string;
    date?: Date;
    publicAccess?: PublicAccessType;
    hasImmutabilityPolicy?: boolean;
    hasLegalHold?: boolean;
}
export declare interface FileSystemGetPropertiesOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    conditions?: LeaseAccessConditions;
}
export declare type FileSystemGetPropertiesResponse = FileSystemGetPropertiesHeaders & {
    _response: HttpResponse & {
        parsedHeaders: FileSystemGetPropertiesHeaders;
    };
};
export declare interface FileSystemItem {
    name: string;
    properties: FileSystemProperties;
    metadata?: Metadata;
    deleted?: boolean;
    versionId?: string;
}
/** Defines headers for FileSystem_listBlobHierarchySegment operation. */
export declare interface FileSystemListBlobHierarchySegmentHeaders {
    /** The media type of the body of the response. For List Blobs this is 'application/xml' */
    contentType?: string;
    /** If a client request id header is sent in the request, this header will be present in the response with the same value. */
    clientRequestId?: string;
    /** This header uniquely identifies the request that was made and can be used for troubleshooting the request. */
    requestId?: string;
    /** Indicates the version of the Blob service used to execute the request. This header is returned for requests made against version 2009-09-19 and above. */
    version?: string;
    /** UTC date/time value generated by the service that indicates the time at which the response was initiated */
    date?: Date;
    /** Error Code */
    errorCode?: string;
}
export declare type FileSystemListDeletedPathsResponse = DeletedPathList & FileSystemListBlobHierarchySegmentHeaders & ListBlobsHierarchySegmentResponse & {
    _response: HttpResponse & {
        /** The response body as text (string format) */
        bodyAsText: string;
        /** The response body as parsed JSON or XML */
        parsedBody: ListBlobsHierarchySegmentResponse;
        /** The parsed HTTP response headers. */
        parsedHeaders: FileSystemListBlobHierarchySegmentHeaders;
    };
    continuation?: string;
};
/** Defines headers for FileSystem_listPaths operation. */
export declare interface FileSystemListPathsHeaders {
    /** A UTC date/time value generated by the service that indicates the time at which the response was initiated. */
    date?: Date;
    /** An HTTP entity tag associated with the filesystem.  Changes to filesystem properties affect the entity tag, but operations on files and directories do not. */
    etag?: string;
    /** The data and time the filesystem was last modified.  Changes to filesystem properties update the last modified time, but operations on files and directories do not. */
    lastModified?: Date;
    /** A server-generated UUID recorded in the analytics logs for troubleshooting and correlation. */
    requestId?: string;
    /** The version of the REST protocol used to process the request. */
    version?: string;
    /** If the number of paths to be listed exceeds the maxResults limit, a continuation token is returned in this response header.  When a continuation token is returned in the response, it must be specified in a subsequent invocation of the list operation to continue listing the paths. */
    continuation?: string;
    /** Error Code */
    errorCode?: string;
}
export declare type FileSystemListPathsResponse = PathList & FileSystemListPathsHeaders & {
    _response: HttpResponse & {
        parsedHeaders: FileSystemListPathsHeaders;
        bodyAsText: string;
        parsedBody: PathListModel;
    };
};
export declare interface FileSystemProperties {
    lastModified: Date;
    etag: string;
    leaseStatus?: LeaseStatusType;
    leaseState?: LeaseStateType;
    leaseDuration?: LeaseDurationType;
    publicAccess?: PublicAccessType;
    hasImmutabilityPolicy?: boolean;
    hasLegalHold?: boolean;
    deletedOn?: Date;
    remainingRetentionDays?: number;
}
/**
 * Contains response data for the {@link DataLakeServiceClient.renameFileSystem} operation.
 */
export declare type FileSystemRenameResponse = ContainerRenameResponse;
/**
 * This is a helper class to construct a string representing the permissions granted by a ServiceSAS to a container.
 * Setting a value to true means that any SAS which uses these permissions will grant permissions for that operation.
 * Once all the values are set, this should be serialized with toString and set as the permissions field on a
 * {@link DataLakeSASSignatureValues} object. It is possible to construct the permissions string without this class, but
 * the order of the permissions is particular and this class guarantees correctness.
 */
export declare class FileSystemSASPermissions {
    /**
     * Creates an {@link FileSystemSASPermissions} from the specified permissions string. This method will throw an
     * Error if it encounters a character that does not correspond to a valid permission.
     *
     * @param permissions -
     */
    static parse(permissions: string): FileSystemSASPermissions;
    /**
     * Specifies Read access granted.
     */
    read: boolean;
    /**
     * Specifies Add access granted.
     */
    add: boolean;
    /**
     * Specifies Create access granted.
     */
    create: boolean;
    /**
     * Specifies Write access granted.
     */
    write: boolean;
    /**
     * Specifies Delete access granted.
     */
    delete: boolean;
    /**
     * Specifies List access granted.
     */
    list: boolean;
    /**
     * Specifies Move access granted.
     */
    move: boolean;
    /**
     * Specifies Execute access granted.
     */
    execute: boolean;
    /**
     * Specifies Ownership access granted, which allows the caller to set owner, owning group,
     * or act as the owner when renaming or deleting a blob (file or directory) within a folder
     * that has the sticky bit set.
     */
    manageOwnership: boolean;
    /**
     * Specifies Permission access granted, which allows the caller to set permissions and
     * POSIX ACLs on blobs (files and directories).
     */
    manageAccessControl: boolean;
    /**
     * Converts the given permissions to a string. Using this method will guarantee the permissions are in an
     * order accepted by the service.
     *
     * The order of the characters should be as specified here to ensure correctness.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas
     *
     */
    toString(): string;
}
export declare interface FileSystemSetAccessPolicyHeaders {
    etag?: string;
    lastModified?: Date;
    clientRequestId?: string;
    requestId?: string;
    version?: string;
    date?: Date;
}
export declare interface FileSystemSetAccessPolicyOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    conditions?: DataLakeRequestConditions;
}
export declare type FileSystemSetAccessPolicyResponse = FileSystemSetAccessPolicyHeaders & {
    _response: HttpResponse & {
        parsedHeaders: FileSystemSetAccessPolicyHeaders;
    };
};
export declare interface FileSystemSetMetadataHeaders {
    etag?: string;
    lastModified?: Date;
    clientRequestId?: string;
    requestId?: string;
    version?: string;
    date?: Date;
}
export declare interface FileSystemSetMetadataOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    conditions?: DataLakeRequestConditions;
}
export declare type FileSystemSetMetadataResponse = FileSystemSetMetadataHeaders & {
    _response: HttpResponse & {
        parsedHeaders: FileSystemSetMetadataHeaders;
    };
};
export declare interface FileSystemUndeletePathOption extends CommonOptions {
    abortSignal?: AbortSignalLike;
}
export declare type FileSystemUndeletePathResponse = PathUndeleteHeaders & {
    _response: HttpResponse & {
        parsedHeaders: PathUndeleteHeaders;
    };
    pathClient: DataLakePathClient;
};
/**
 * Contains response data for the {@link DataLakeServiceClient.undeleteFileSystem} operation.
 */
export declare type FileSystemUndeleteResponse = ContainerUndeleteResponse;
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * Generates a {@link SASQueryParameters} object which contains all SAS query parameters needed to make an actual
 * REST request.
 *
 * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-an-account-sas
 *
 * @param accountSASSignatureValues -
 * @param sharedKeyCredential -
 */
export declare function generateAccountSASQueryParameters(accountSASSignatureValues: AccountSASSignatureValues, sharedKeyCredential: StorageSharedKeyCredential): SASQueryParameters;
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * Creates an instance of SASQueryParameters.
 *
 * Only accepts required settings needed to create a SAS. For optional settings please
 * set corresponding properties directly, such as permissions, startsOn and identifier.
 *
 * WARNING: When identifier is not provided, permissions and expiresOn are required.
 * You MUST assign value to identifier or expiresOn & permissions manually if you initial with
 * this constructor.
 *
 * Fill in the required details before running the following snippets.
 * @example
 * ```js
 * // Generate service level SAS for a file system
 * const containerSAS = generateDataLakeSASQueryParameters({
 *     fileSystemName, // Required
 *     permissions: ContainerSASPermissions.parse("racwdl"), // Required
 *     startsOn: new Date(), // Optional
 *     expiresOn: new Date(new Date().valueOf() + 86400), // Required. Date type
 *     ipRange: { start: "0.0.0.0", end: "255.255.255.255" }, // Optional
 *     protocol: SASProtocol.HttpsAndHttp, // Optional
 *     version: "2016-05-31" // Optional
 *   },
 *   sharedKeyCredential // StorageSharedKeyCredential - `new StorageSharedKeyCredential(account, accountKey)`
 * ).toString();
 * ```
 *
 * // Fill in the required details before running the snippet.
 * @example
 * ```js
 * // Generate service level SAS for a file
 * const fileSAS = generateDataLakeSASQueryParameters({
 *     fileSystemName, // Required
 *     fileName, // Required
 *     permissions: DataLakeSASPermissions.parse("racwd"), // Required
 *     startsOn: new Date(), // Optional
 *     expiresOn: new Date(new Date().valueOf() + 86400), // Required. Date type
 *     cacheControl: "cache-control-override", // Optional
 *     contentDisposition: "content-disposition-override", // Optional
 *     contentEncoding: "content-encoding-override", // Optional
 *     contentLanguage: "content-language-override", // Optional
 *     contentType: "content-type-override", // Optional
 *     ipRange: { start: "0.0.0.0", end: "255.255.255.255" }, // Optional
 *     protocol: SASProtocol.HttpsAndHttp, // Optional
 *     version: "2016-05-31" // Optional
 *   },
 *   sharedKeyCredential // StorageSharedKeyCredential - `new StorageSharedKeyCredential(account, accountKey)`
 * ).toString();
 * ```
 *
 * @param dataLakeSASSignatureValues -
 * @param sharedKeyCredential -
 */
export declare function generateDataLakeSASQueryParameters(dataLakeSASSignatureValues: DataLakeSASSignatureValues, sharedKeyCredential: StorageSharedKeyCredential): SASQueryParameters;
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * Creates an instance of SASQueryParameters.
 * WARNING: identifier will be ignored when generating user delegation SAS, permissions and expiresOn are required.
 *
 * @example
 * ```js
 * // Generate user delegation SAS for a file system
 * const userDelegationKey = await dataLakeServiceClient.getUserDelegationKey(startsOn, expiresOn);
 * const fileSystemSAS = generateDataLakeSASQueryParameters({
 *     fileSystemName, // Required
 *     permissions: FileSystemSASPermissions.parse("racwdl"), // Required
 *     startsOn, // Optional. Date type
 *     expiresOn, // Required. Date type
 *     ipRange: { start: "0.0.0.0", end: "255.255.255.255" }, // Optional
 *     protocol: SASProtocol.HttpsAndHttp, // Optional
 *     version: "2018-11-09" // Must greater than or equal to 2018-11-09 to generate user delegation SAS
 *   },
 *   userDelegationKey, // UserDelegationKey
 *   accountName
 * ).toString();
 * ```
 *
 * @param dataLakeSASSignatureValues -
 * @param userDelegationKey - Return value of `blobServiceClient.getUserDelegationKey()`
 * @param accountName -
 */
export declare function generateDataLakeSASQueryParameters(dataLakeSASSignatureValues: DataLakeSASSignatureValues, userDelegationKey: UserDelegationKey, accountName: string): SASQueryParameters;
export { HttpHeaders };
export { HttpOperationResponse };
export { HttpRequestBody };
export { IHttpClient };
export { Lease };
export { LeaseAccessConditions };
export declare type LeaseDurationType = "infinite" | "fixed";
export { LeaseOperationOptions };
export { LeaseOperationResponse };
export declare type LeaseStateType = "available" | "leased" | "expired" | "breaking" | "broken";
export declare type LeaseStatusType = "locked" | "unlocked";
/** An enumeration of blobs */
export declare interface ListBlobsHierarchySegmentResponse {
    serviceEndpoint: string;
    containerName: string;
    prefix?: string;
    marker?: string;
    maxResults?: number;
    delimiter?: string;
    segment: BlobHierarchyListSegment;
    nextMarker?: string;
}
export declare interface ListDeletedPathsOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    /** Filters results to filesystems within the specified prefix. */
    prefix?: string;
}
export declare interface ListDeletedPathsSegmentOptions extends ListDeletedPathsOptions {
    maxResults?: number;
}
export declare interface ListFileSystemsSegmentResponse {
    serviceEndpoint: string;
    prefix?: string;
    marker?: string;
    maxPageSize?: number;
    fileSystemItems: FileSystemItem[];
    continuationToken?: string;
}
export declare interface ListPathsOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    recursive?: boolean;
    path?: string;
    userPrincipalName?: boolean;
}
export declare interface ListPathsSegmentOptions extends ListPathsOptions {
    maxResults?: number;
}
/** Contains response data for the listPaths operation. */
export declare type ListPathsSegmentResponse = FileSystemListPathsHeaders & PathListModel & {
    /** The underlying HTTP response. */
    _response: coreHttp.HttpResponse & {
        /** The response body as text (string format) */
        bodyAsText: string;
        /** The response body as parsed JSON or XML */
        parsedBody: PathListModel;
        /** The parsed HTTP response headers. */
        parsedHeaders: FileSystemListPathsHeaders;
    };
};
/**
 * The `@azure/logger` configuration for this package.
 */
export declare const logger: import("@azure/logger").AzureLogger;
/** ********************************************************/
/** DataLakePathClient option and response related models */
/** ********************************************************/
export declare interface Metadata {
    [propertyName: string]: string;
}
export declare type ModifiedAccessConditions = Pick<ModifiedAccessConditions_2, Exclude<keyof ModifiedAccessConditions_2, "ifTags">>;
/**
 * Creates a new Pipeline object with Credential provided.
 *
 * @param credential -  Such as AnonymousCredential, StorageSharedKeyCredential or any credential from the `@azure/identity` package to authenticate requests to the service. You can also provide an object that implements the TokenCredential interface. If not specified, AnonymousCredential is used.
 * @param pipelineOptions - Optional. Options.
 * @returns A new Pipeline object.
 */
export declare function newPipeline(credential?: StorageSharedKeyCredential | AnonymousCredential | TokenCredential, pipelineOptions?: StoragePipelineOptions): Pipeline;
export declare interface Path {
    name?: string;
    isDirectory?: boolean;
    lastModified?: Date;
    etag?: string;
    contentLength?: number;
    owner?: string;
    group?: string;
    permissions?: PathPermissions;
}
export declare interface PathAccessControl {
    owner?: string;
    group?: string;
    permissions?: PathPermissions;
    acl: PathAccessControlItem[];
}
export declare interface PathAccessControlItem {
    /**
     * Indicates whether this is the default entry for the ACL.
     */
    defaultScope: boolean;
    /**
     * Specifies which role this entry targets.
     */
    accessControlType: AccessControlType;
    /**
     * Specifies the entity for which this entry applies.
     */
    entityId: string;
    /**
     * Access control permissions.
     */
    permissions: RolePermissions;
}
/** Defines headers for Path_appendData operation. */
export declare interface PathAppendDataHeaders {
    /** A UTC date/time value generated by the service that indicates the time at which the response was initiated. */
    date?: Date;
    /** A server-generated UUID recorded in the analytics logs for troubleshooting and correlation. */
    requestId?: string;
    /** If a client request id header is sent in the request, this header will be present in the response with the same value. */
    clientRequestId?: string;
    /** The version of the REST protocol used to process the request. */
    version?: string;
    /** An HTTP entity tag associated with the file or directory. */
    etag?: string;
    /** If the blob has an MD5 hash and this operation is to read the full blob, this response header is returned so that the client can check for message content integrity. */
    contentMD5?: Uint8Array;
    /** This header is returned so that the client can check for message content integrity. The value of this header is computed by the Blob service; it is not necessarily the same value specified in the request headers. */
    xMsContentCrc64?: Uint8Array;
    /** The value of this header is set to true if the contents of the request are successfully encrypted using the specified algorithm, and false otherwise. */
    isServerEncrypted?: boolean;
}
/**
 * Options type for `setAccessControlRecursive`, `updateAccessControlRecursive` and `removeAccessControlRecursive`.
 */
export declare interface PathChangeAccessControlRecursiveOptions extends CommonOptions {
    /**
     * An implementation of the `AbortSignalLike` interface to signal the request to cancel the operation.
     * For example, use the &commat;azure/abort-controller to create an `AbortSignal`.
     */
    abortSignal?: AbortSignalLike;
    /**
     * Optional. If data set size exceeds batch size then operation will be split into multiple requests so that progress can be tracked.
     * Batch size should be between 1 and 2000. The default when unspecified is 2000.
     */
    batchSize?: number;
    /**
     * Optional. Defines maximum number of batches that single change Access Control operation can execute.
     * If maximum is reached before all subpaths are processed then continuation token can be used to resume operation.
     * Empty value indicates that maximum number of batches in unbound and operation continues till end.
     */
    maxBatches?: number;
    /**
     * Optional. Default false. If set to false, the operation will terminate quickly on encountering user failures.
     * If true, the operation will ignore user failures and proceed with the operation on other sub-entities of the directory.
     */
    continueOnFailure?: boolean;
    /**
     * Continuation token to continue next batch of operations.
     */
    continuationToken?: string;
    /**
     * Callback where caller can track progress of the operation
     * as well as collect paths that failed to change Access Control.
     */
    onProgress?: (progress: AccessControlChanges) => void;
}
/**
 * Response type for `setAccessControlRecursive`, `updateAccessControlRecursive` and `removeAccessControlRecursive`.
 */
export declare interface PathChangeAccessControlRecursiveResponse {
    /**
     * Contains counts of paths changed from start of the operation.
     */
    counters: AccessControlChangeCounters;
    /**
     * Optional. Value is present when operation is split into multiple batches and can be used to resume progress.
     */
    continuationToken?: string;
}
/** Defines headers for Path_create operation. */
export declare interface PathCreateHeaders {
    /** A UTC date/time value generated by the service that indicates the time at which the response was initiated. */
    date?: Date;
    /** An HTTP entity tag associated with the file or directory. */
    etag?: string;
    /** The data and time the file or directory was last modified.  Write operations on the file or directory update the last modified time. */
    lastModified?: Date;
    /** A server-generated UUID recorded in the analytics logs for troubleshooting and correlation. */
    requestId?: string;
    /** The version of the REST protocol used to process the request. */
    version?: string;
    /** When renaming a directory, the number of paths that are renamed with each invocation is limited.  If the number of paths to be renamed exceeds this limit, a continuation token is returned in this response header.  When a continuation token is returned in the response, it must be specified in a subsequent invocation of the rename operation to continue renaming the directory. */
    continuation?: string;
    /** The size of the resource in bytes. */
    contentLength?: number;
    /** Error Code */
    errorCode?: string;
}
export declare interface PathCreateHttpHeaders {
    cacheControl?: string;
    contentEncoding?: string;
    contentLanguage?: string;
    contentDisposition?: string;
    contentType?: string;
}
export declare interface PathCreateIfNotExistsOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    metadata?: Metadata;
    permissions?: string;
    umask?: string;
    pathHttpHeaders?: PathCreateHttpHeaders;
}
/**
 * Contains response data for the {@link DataLakePathClient.createIfNotExists} operation.
 */
export declare interface PathCreateIfNotExistsResponse extends PathCreateResponse {
    /**
     * Indicate whether the directory/file is successfully created. Is false when the directory/file is not changed as it already exists.
     */
    succeeded: boolean;
}
export declare interface PathCreateOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    metadata?: Metadata;
    permissions?: string;
    umask?: string;
    conditions?: DataLakeRequestConditions;
    pathHttpHeaders?: PathCreateHttpHeaders;
}
/** Contains response data for the create operation. */
export declare type PathCreateResponse = PathCreateHeaders & {
    /** The underlying HTTP response. */
    _response: coreHttp.HttpResponse & {
        /** The parsed HTTP response headers. */
        parsedHeaders: PathCreateHeaders;
    };
};
/** Defines headers for Path_delete operation. */
export declare interface PathDeleteHeaders {
    /** A UTC date/time value generated by the service that indicates the time at which the response was initiated. */
    date?: Date;
    /** A server-generated UUID recorded in the analytics logs for troubleshooting and correlation. */
    requestId?: string;
    /** The version of the REST protocol used to process the request. */
    version?: string;
    /** When deleting a directory, the number of paths that are deleted with each invocation is limited.  If the number of paths to be deleted exceeds this limit, a continuation token is returned in this response header.  When a continuation token is returned in the response, it must be specified in a subsequent invocation of the delete operation to continue deleting the directory. */
    continuation?: string;
    /** Returned only for hierarchical namespace space enabled accounts when soft delete is enabled. A unique identifier for the entity that can be used to restore it. See the Undelete REST API for more information. */
    deletionId?: string;
    /** Error Code */
    errorCode?: string;
}
/**
 * Contains response data for the {@link DataLakePathClient.deleteIfExists} operation.
 */
export declare interface PathDeleteIfExistsResponse extends PathDeleteResponse {
    /**
     * Indicate whether the directory/file is successfully deleted. Is false if the directory/file doesn't exist in the first place.
     */
    succeeded: boolean;
}
export declare interface PathDeleteOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    conditions?: DataLakeRequestConditions;
}
/** Contains response data for the delete operation. */
export declare type PathDeleteResponse = PathDeleteHeaders & {
    /** The underlying HTTP response. */
    _response: coreHttp.HttpResponse & {
        /** The parsed HTTP response headers. */
        parsedHeaders: PathDeleteHeaders;
    };
};
/**
 * Option interface for Data Lake directory/file exists operations
 *
 * See:
 * - {@link DataLakePathClient.exists}
 */
export declare interface PathExistsOptions extends CommonOptions {
    /**
     * An implementation of the `AbortSignalLike` interface to signal the request to cancel the operation.
     * For example, use the &commat;azure/abort-controller to create an `AbortSignal`.
     */
    abortSignal?: AbortSignalLike;
}
/** Defines headers for Path_flushData operation. */
export declare interface PathFlushDataHeaders {
    /** A UTC date/time value generated by the service that indicates the time at which the response was initiated. */
    date?: Date;
    /** An HTTP entity tag associated with the file or directory. */
    etag?: string;
    /** The data and time the file or directory was last modified.  Write operations on the file or directory update the last modified time. */
    lastModified?: Date;
    /** The size of the resource in bytes. */
    contentLength?: number;
    /** If a client request id header is sent in the request, this header will be present in the response with the same value. */
    clientRequestId?: string;
    /** A server-generated UUID recorded in the analytics logs for troubleshooting and correlation. */
    requestId?: string;
    /** The version of the REST protocol used to process the request. */
    version?: string;
}
/** Contains response data for the flushData operation. */
declare type PathFlushDataResponse = PathFlushDataHeaders & {
    /** The underlying HTTP response. */
    _response: coreHttp.HttpResponse & {
        /** The parsed HTTP response headers. */
        parsedHeaders: PathFlushDataHeaders;
    };
};
export { PathFlushDataResponse as FileFlushResponse };
export { PathFlushDataResponse as FileUploadResponse };
export declare interface PathGetAccessControlHeaders {
    date?: Date;
    etag?: string;
    lastModified?: Date;
    owner?: string;
    group?: string;
    requestId?: string;
    version?: string;
}
export declare interface PathGetAccessControlOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    conditions?: DataLakeRequestConditions;
    userPrincipalName?: boolean;
}
export declare type PathGetAccessControlResponse = PathAccessControl & PathGetAccessControlHeaders & {
    _response: HttpResponse & {
        parsedHeaders: PathGetPropertiesHeadersModel;
    };
};
/**
 * Defines values for PathGetPropertiesAction.
 * Possible values include: 'getAccessControl', 'getStatus'
 * @readonly
 */
export declare enum PathGetPropertiesAction {
    GetAccessControl = "getAccessControl",
    GetStatus = "getStatus"
}
/** Defines values for PathGetPropertiesAction. */
export declare type PathGetPropertiesActionModel = "getAccessControl" | "getStatus";
export declare interface PathGetPropertiesHeaders {
    lastModified?: Date;
    createdOn?: Date;
    metadata?: Metadata;
    copyCompletedOn?: Date;
    copyStatusDescription?: string;
    copyId?: string;
    copyProgress?: string;
    copySource?: string;
    copyStatus?: CopyStatusType;
    isIncrementalCopy?: boolean;
    destinationSnapshot?: string;
    leaseDuration?: LeaseDurationType;
    leaseState?: LeaseStateType;
    leaseStatus?: LeaseStatusType;
    contentLength?: number;
    contentType?: string;
    etag?: string;
    contentMD5?: Uint8Array;
    contentEncoding?: string;
    contentDisposition?: string;
    contentLanguage?: string;
    cacheControl?: string;
    clientRequestId?: string;
    requestId?: string;
    version?: string;
    date?: Date;
    acceptRanges?: string;
    isServerEncrypted?: boolean;
    encryptionKeySha256?: string;
    accessTier?: string;
    accessTierInferred?: boolean;
    archiveStatus?: string;
    accessTierChangedOn?: Date;
    /**
     * The time the file will expire.
     */
    expiresOn?: Date;
}
/** Defines headers for Path_getProperties operation. */
export declare interface PathGetPropertiesHeadersModel {
    /** Indicates that the service supports requests for partial file content. */
    acceptRanges?: string;
    /** If the Cache-Control request header has previously been set for the resource, that value is returned in this header. */
    cacheControl?: string;
    /** If the Content-Disposition request header has previously been set for the resource, that value is returned in this header. */
    contentDisposition?: string;
    /** If the Content-Encoding request header has previously been set for the resource, that value is returned in this header. */
    contentEncoding?: string;
    /** If the Content-Language request header has previously been set for the resource, that value is returned in this header. */
    contentLanguage?: string;
    /** The size of the resource in bytes. */
    contentLength?: number;
    /** Indicates the range of bytes returned in the event that the client requested a subset of the file by setting the Range request header. */
    contentRange?: string;
    /** The content type specified for the resource. If no content type was specified, the default content type is application/octet-stream. */
    contentType?: string;
    /** The MD5 hash of complete file stored in storage. This header is returned only for "GetProperties" operation. If the Content-MD5 header has been set for the file, this response header is returned for GetProperties call so that the client can check for message content integrity. */
    contentMD5?: string;
    /** A UTC date/time value generated by the service that indicates the time at which the response was initiated. */
    date?: Date;
    /** An HTTP entity tag associated with the file or directory. */
    etag?: string;
    /** The data and time the file or directory was last modified.  Write operations on the file or directory update the last modified time. */
    lastModified?: Date;
    /** A server-generated UUID recorded in the analytics logs for troubleshooting and correlation. */
    requestId?: string;
    /** The version of the REST protocol used to process the request. */
    version?: string;
    /** The type of the resource.  The value may be "file" or "directory".  If not set, the value is "file". */
    resourceType?: string;
    /** The user-defined properties associated with the file or directory, in the format of a comma-separated list of name and value pairs "n1=v1, n2=v2, ...", where each value is a base64 encoded string. Note that the string may only contain ASCII characters in the ISO-8859-1 character set. */
    properties?: string;
    /** The owner of the file or directory. Included in the response if Hierarchical Namespace is enabled for the account. */
    owner?: string;
    /** The owning group of the file or directory. Included in the response if Hierarchical Namespace is enabled for the account. */
    group?: string;
    /** The POSIX access permissions for the file owner, the file owning group, and others. Included in the response if Hierarchical Namespace is enabled for the account. */
    permissions?: string;
    /** The POSIX access control list for the file or directory.  Included in the response only if the action is "getAccessControl" and Hierarchical Namespace is enabled for the account. */
    acl?: string;
    /** When a resource is leased, specifies whether the lease is of infinite or fixed duration. */
    leaseDuration?: string;
    /** Lease state of the resource. */
    leaseState?: string;
    /** The lease status of the resource. */
    leaseStatus?: string;
    /** Error Code */
    errorCode?: string;
}
export declare interface PathGetPropertiesOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    conditions?: DataLakeRequestConditions;
}
export declare type PathGetPropertiesResponse = PathGetPropertiesHeaders & {
    _response: HttpResponse & {
        parsedHeaders: PathGetPropertiesHeaders;
    };
};
export declare interface PathHttpHeaders {
    cacheControl?: string;
    contentEncoding?: string;
    contentLanguage?: string;
    contentDisposition?: string;
    contentType?: string;
    contentMD5?: Uint8Array;
}
export declare interface PathList {
    pathItems?: Path[];
}
export declare interface PathListModel {
    paths?: PathModel[];
}
export declare interface PathModel {
    name?: string;
    isDirectory?: boolean;
    lastModified?: Date;
    etag?: string;
    contentLength?: number;
    owner?: string;
    group?: string;
    permissions?: string;
}
export declare interface PathMoveOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    conditions?: DataLakeRequestConditions;
    destinationConditions?: DataLakeRequestConditions;
}
export declare type PathMoveResponse = PathRemoveHeaders & {
    _response: HttpResponse & {
        parsedHeaders: PathRemoveHeaders;
    };
};
export declare interface PathPermissions {
    owner: RolePermissions;
    group: RolePermissions;
    other: RolePermissions;
    stickyBit: boolean;
    extendedAcls: boolean;
}
export declare interface PathRemoveHeaders {
    date?: Date;
    etag?: string;
    lastModified?: Date;
    requestId?: string;
    version?: string;
    contentLength?: number;
}
/**
 * Defines values for PathRenameMode.
 * Possible values include: 'legacy', 'posix'
 * @readonly
 */
export declare enum PathRenameMode {
    Legacy = "legacy",
    Posix = "posix"
}
/** Defines values for PathRenameMode. */
export declare type PathRenameModeModel = "legacy" | "posix";
/**
 * Defines values for PathResourceType.
 * Possible values include: 'directory', 'file'
 * @readonly
 */
export declare enum PathResourceType {
    Directory = "directory",
    File = "file"
}
/** Defines values for PathResourceType. */
export declare type PathResourceTypeModel = "directory" | "file";
/** Defines headers for Path_setAccessControl operation. */
export declare interface PathSetAccessControlHeaders {
    /** A UTC date/time value generated by the service that indicates the time at which the response was initiated. */
    date?: Date;
    /** An HTTP entity tag associated with the file or directory. */
    etag?: string;
    /** The data and time the file or directory was last modified. Write operations on the file or directory update the last modified time. */
    lastModified?: Date;
    /** If a client request id header is sent in the request, this header will be present in the response with the same value. */
    clientRequestId?: string;
    /** A server-generated UUID recorded in the analytics logs for troubleshooting and correlation. */
    requestId?: string;
    /** The version of the REST protocol used to process the request. */
    version?: string;
}
export declare interface PathSetAccessControlOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    conditions?: DataLakeRequestConditions;
    owner?: string;
    group?: string;
}
/** Contains response data for the setAccessControl operation. */
declare type PathSetAccessControlResponse = PathSetAccessControlHeaders & {
    /** The underlying HTTP response. */
    _response: coreHttp.HttpResponse & {
        /** The parsed HTTP response headers. */
        parsedHeaders: PathSetAccessControlHeaders;
    };
};
export { PathSetAccessControlResponse };
export { PathSetAccessControlResponse as PathSetPermissionsResponse };
export declare interface PathSetHttpHeadersHeaders {
    etag?: string;
    lastModified?: Date;
    clientRequestId?: string;
    requestId?: string;
    version?: string;
    date?: Date;
}
export declare interface PathSetHttpHeadersOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    conditions?: DataLakeRequestConditions;
}
export declare type PathSetHttpHeadersResponse = PathSetHttpHeadersHeaders & {
    _response: HttpResponse & {
        parsedHeaders: PathSetHttpHeadersHeaders;
    };
};
export declare interface PathSetMetadataHeaders {
    etag?: string;
    lastModified?: Date;
    clientRequestId?: string;
    requestId?: string;
    version?: string;
    date?: Date;
    isServerEncrypted?: boolean;
    encryptionKeySha256?: string;
}
export declare interface PathSetMetadataOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    conditions?: DataLakeRequestConditions;
}
export declare type PathSetMetadataResponse = PathSetMetadataHeaders & {
    _response: HttpResponse & {
        parsedHeaders: PathSetMetadataHeaders;
    };
};
export declare interface PathSetPermissionsOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    conditions?: DataLakeRequestConditions;
    owner?: string;
    group?: string;
}
/** Defines headers for Path_undelete operation. */
export declare interface PathUndeleteHeaders {
    /** If a client request id header is sent in the request, this header will be present in the response with the same value. */
    clientRequestId?: string;
    /** This header uniquely identifies the request that was made and can be used for troubleshooting the request. */
    requestId?: string;
    /** The type of the resource.  The value may be "file" or "directory".  If not set, the value is "file". */
    resourceType?: string;
    /** Indicates the version of the Blob service used to execute the request. This header is returned for requests made against version 2009-09-19 and above. */
    version?: string;
    /** UTC date/time value generated by the service that indicates the time at which the response was initiated. */
    date?: Date;
}
/** Defines headers for Path_update operation. */
export declare interface PathUpdateHeaders {
    /** A UTC date/time value generated by the service that indicates the time at which the response was initiated. */
    date?: Date;
    /** An HTTP entity tag associated with the file or directory. */
    etag?: string;
    /** The data and time the file or directory was last modified.  Write operations on the file or directory update the last modified time. */
    lastModified?: Date;
    /** Indicates that the service supports requests for partial file content. */
    acceptRanges?: string;
    /** If the Cache-Control request header has previously been set for the resource, that value is returned in this header. */
    cacheControl?: string;
    /** If the Content-Disposition request header has previously been set for the resource, that value is returned in this header. */
    contentDisposition?: string;
    /** If the Content-Encoding request header has previously been set for the resource, that value is returned in this header. */
    contentEncoding?: string;
    /** If the Content-Language request header has previously been set for the resource, that value is returned in this header. */
    contentLanguage?: string;
    /** The size of the resource in bytes. */
    contentLength?: number;
    /** Indicates the range of bytes returned in the event that the client requested a subset of the file by setting the Range request header. */
    contentRange?: string;
    /** The content type specified for the resource. If no content type was specified, the default content type is application/octet-stream. */
    contentType?: string;
    /** An MD5 hash of the request content. This header is only returned for "Flush" operation. This header is returned so that the client can check for message content integrity. This header refers to the content of the request, not actual file content. */
    contentMD5?: string;
    /** User-defined properties associated with the file or directory, in the format of a comma-separated list of name and value pairs "n1=v1, n2=v2, ...", where each value is a base64 encoded string. Note that the string may only contain ASCII characters in the ISO-8859-1 character set. */
    properties?: string;
    /** When performing setAccessControlRecursive on a directory, the number of paths that are processed with each invocation is limited.  If the number of paths to be processed exceeds this limit, a continuation token is returned in this response header.  When a continuation token is returned in the response, it must be specified in a subsequent invocation of the setAccessControlRecursive operation to continue the setAccessControlRecursive operation on the directory. */
    xMsContinuation?: string;
    /** A server-generated UUID recorded in the analytics logs for troubleshooting and correlation. */
    requestId?: string;
    /** The version of the REST protocol used to process the request. */
    version?: string;
    /** Error Code */
    errorCode?: string;
}
/**
 * A Pipeline class containing HTTP request policies.
 * You can create a default Pipeline by calling {@link newPipeline}.
 * Or you can create a Pipeline with your own policies by the constructor of Pipeline.
 *
 * Refer to {@link newPipeline} and provided policies before implementing your
 * customized Pipeline.
 */
export declare class Pipeline {
    /**
     * A list of chained request policy factories.
     */
    readonly factories: RequestPolicyFactory[];
    /**
     * Configures pipeline logger and HTTP client.
     */
    readonly options: PipelineOptions;
    /**
     * Creates an instance of Pipeline. Customize HTTPClient by implementing IHttpClient interface.
     *
     * @param factories -
     * @param options -
     */
    constructor(factories: RequestPolicyFactory[], options?: PipelineOptions);
    /**
     * Transfer Pipeline object to ServiceClientOptions object which is required by
     * ServiceClient constructor.
     *
     * @returns The ServiceClientOptions object from this Pipeline.
     */
    toServiceClientOptions(): ServiceClientOptions;
}
/**
 * Option interface for Pipeline constructor.
 */
export declare interface PipelineOptions {
    /**
     * Optional. Configures the HTTP client to send requests and receive responses.
     */
    httpClient?: IHttpClient;
}
export declare type PublicAccessType = "filesystem" | "file";
export declare interface RawAccessPolicy {
    startsOn?: string;
    expiresOn?: string;
    permissions: string;
}
export declare interface RemovePathAccessControlItem {
    /**
     * Indicates whether this is the default entry for the ACL.
     */
    defaultScope: boolean;
    /**
     * Specifies which role this entry targets.
     */
    accessControlType: AccessControlType;
    /**
     * Specifies the entity for which this entry applies.
     * Must be omitted for types mask or other. It must also be omitted when the user or group is the owner.
     */
    entityId?: string;
}
export { RequestPolicy };
export { RequestPolicyFactory };
export { RequestPolicyOptions };
export { RestError };
export declare interface RolePermissions {
    read: boolean;
    write: boolean;
    execute: boolean;
}
/**
 * Allowed IP range for a SAS.
 */
export declare interface SasIPRange {
    /**
     * Starting IP address in the IP range.
     * If end IP doesn't provide, start IP will the only IP allowed.
     */
    start: string;
    /**
     * Optional. IP address that ends the IP range.
     * If not provided, start IP will the only IP allowed.
     */
    end?: string;
}
/**
 * Protocols for generated SAS.
 */
export declare enum SASProtocol {
    /**
     * Protocol that allows HTTPS only
     */
    Https = "https",
    /**
     * Protocol that allows both HTTPS and HTTP
     */
    HttpsAndHttp = "https,http"
}
/**
 * Represents the components that make up an Azure Storage SAS' query parameters. This type is not constructed directly
 * by the user; it is only generated by the {@link AccountSASSignatureValues} and {@link BlobSASSignatureValues}
 * types. Once generated, it can be encoded into a {@link String} and appended to a URL directly (though caution should
 * be taken here in case there are existing query parameters, which might affect the appropriate means of appending
 * these query parameters).
 *
 * NOTE: Instances of this class are immutable.
 */
export declare class SASQueryParameters {
    /**
     * The storage API version.
     */
    readonly version: string;
    /**
     * Optional. The allowed HTTP protocol(s).
     */
    readonly protocol?: SASProtocol;
    /**
     * Optional. The start time for this SAS token.
     */
    readonly startsOn?: Date;
    /**
     * Optional only when identifier is provided. The expiry time for this SAS token.
     */
    readonly expiresOn?: Date;
    /**
     * Optional only when identifier is provided.
     * Please refer to {@link AccountSASPermissions}, {@link BlobSASPermissions}, or {@link ContainerSASPermissions} for
     * more details.
     */
    readonly permissions?: string;
    /**
     * Optional. The storage services being accessed (only for Account SAS). Please refer to {@link AccountSASServices}
     * for more details.
     */
    readonly services?: string;
    /**
     * Optional. The storage resource types being accessed (only for Account SAS). Please refer to
     * {@link AccountSASResourceTypes} for more details.
     */
    readonly resourceTypes?: string;
    /**
     * Optional. The signed identifier (only for {@link BlobSASSignatureValues}).
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/establishing-a-stored-access-policy
     */
    readonly identifier?: string;
    /**
     * Optional. Specifies which resources are accessible via the SAS (only for {@link BlobSASSignatureValues}).
     * @see https://docs.microsoft.com/rest/api/storageservices/create-service-sas#specifying-the-signed-resource-blob-service-only
     */
    readonly resource?: string;
    /**
     * The signature for the SAS token.
     */
    readonly signature: string;
    /**
     * Value for cache-control header in Blob/File Service SAS.
     */
    readonly cacheControl?: string;
    /**
     * Value for content-disposition header in Blob/File Service SAS.
     */
    readonly contentDisposition?: string;
    /**
     * Value for content-encoding header in Blob/File Service SAS.
     */
    readonly contentEncoding?: string;
    /**
     * Value for content-length header in Blob/File Service SAS.
     */
    readonly contentLanguage?: string;
    /**
     * Value for content-type header in Blob/File Service SAS.
     */
    readonly contentType?: string;
    /**
     * Inner value of getter ipRange.
     */
    private readonly ipRangeInner?;
    /**
     * The Azure Active Directory object ID in GUID format.
     * Property of user delegation key.
     */
    private readonly signedOid?;
    /**
     * The Azure Active Directory tenant ID in GUID format.
     * Property of user delegation key.
     */
    private readonly signedTenantId?;
    /**
     * The date-time the key is active.
     * Property of user delegation key.
     */
    private readonly signedStartsOn?;
    /**
     * The date-time the key expires.
     * Property of user delegation key.
     */
    private readonly signedExpiresOn?;
    /**
     * Abbreviation of the Azure Storage service that accepts the user delegation key.
     * Property of user delegation key.
     */
    private readonly signedService?;
    /**
     * The service version that created the user delegation key.
     * Property of user delegation key.
     */
    private readonly signedVersion?;
    /**
     * Indicate the depth of the directory specified in the canonicalizedresource field of the string-to-sign.
     * The depth of the directory is the number of directories beneath the root folder.
     */
    readonly directoryDepth?: number;
    /**
     * Authorized AAD Object ID in GUID format. The AAD Object ID of a user authorized by the owner of the User Delegation Key
     * to perform the action granted by the SAS. The Azure Storage service will ensure that the owner of the user delegation key
     * has the required permissions before granting access but no additional permission check for the user specified in
     * this value will be performed. This cannot be used in conjuction with {@link signedUnauthorizedUserObjectId}.
     * This is only used for User Delegation SAS.
     */
    readonly preauthorizedAgentObjectId?: string;
    /**
     * Unauthorized AAD Object ID in GUID format. The AAD Object ID of a user that is assumed to be unauthorized by the owner of the User Delegation Key.
     * The Azure Storage Service will perform an additional POSIX ACL check to determine if the user is authorized to perform the requested operation.
     * This cannot be used in conjuction with {@link signedAuthorizedUserObjectId}.
     * This is only used for User Delegation SAS.
     */
    readonly agentObjectId?: string;
    /**
     * A GUID value that will be logged in the storage diagnostic logs and can be used to correlate SAS generation with storage resource access.
     * This is only used for User Delegation SAS.
     */
    readonly correlationId?: string;
    readonly ipRange: SasIPRange | undefined;
    /**
     * Creates an instance of SASQueryParameters.
     *
     * @param version - Representing the storage version
     * @param signature - Representing the signature for the SAS token
     * @param permissions - Representing the storage permissions
     * @param services - Representing the storage services being accessed (only for Account SAS)
     * @param resourceTypes - Representing the storage resource types being accessed (only for Account SAS)
     * @param protocol - Representing the allowed HTTP protocol(s)
     * @param startsOn - Representing the start time for this SAS token
     * @param expiresOn - Representing the expiry time for this SAS token
     * @param ipRange - Representing the range of valid IP addresses for this SAS token
     * @param identifier - Representing the signed identifier (only for Service SAS)
     * @param resource - Representing the storage container or blob (only for Service SAS)
     * @param cacheControl - Representing the cache-control header (only for Blob/File Service SAS)
     * @param contentDisposition - Representing the content-disposition header (only for Blob/File Service SAS)
     * @param contentEncoding - Representing the content-encoding header (only for Blob/File Service SAS)
     * @param contentLanguage - Representing the content-language header (only for Blob/File Service SAS)
     * @param contentType - Representing the content-type header (only for Blob/File Service SAS)
     * @param userDelegationKey - Representing the user delegation key properties
     * @param preauthorizedAgentObjectId - Representing the authorized AAD Object ID (only for User Delegation SAS)
     * @param agentObjectId - Representing the unauthorized AAD Object ID (only for User Delegation SAS)
     * @param correlationId - Representing the correlation ID (only for User Delegation SAS)
     */
    constructor(version: string, signature: string, permissions?: string, services?: string, resourceTypes?: string, protocol?: SASProtocol, startsOn?: Date, expiresOn?: Date, ipRange?: SasIPRange, identifier?: string, resource?: string, cacheControl?: string, contentDisposition?: string, contentEncoding?: string, contentLanguage?: string, contentType?: string, userDelegationKey?: UserDelegationKey, directoryDepth?: number, preauthorizedAgentObjectId?: string, agentObjectId?: string, correlationId?: string);
    /**
     * Creates an instance of SASQueryParameters.
     *
     * @param version - Representing the storage version
     * @param signature - Representing the signature for the SAS token
     * @param options - Optional. Options to construct the SASQueryParameters.
     */
    constructor(version: string, signature: string, options?: SASQueryParametersOptions);
    /**
     * Encodes all SAS query parameters into a string that can be appended to a URL.
     *
     */
    toString(): string;
    /**
     * A private helper method used to filter and append query key/value pairs into an array.
     *
     * @param queries -
     * @param key -
     * @param value -
     */
    private tryAppendQueryParameter;
}
/**
 * Options to construct {@link SASQueryParameters}.
 */
export declare interface SASQueryParametersOptions {
    /**
     * Optional only when identifier is provided.
     * Please refer to {@link AccountSASPermissions}, {@link BlobSASPermissions}, or {@link ContainerSASPermissions} for
     * more details.
     */
    permissions?: string;
    /**
     * Optional. The storage services being accessed (only for Account SAS). Please refer to {@link AccountSASServices}
     * for more details.
     */
    services?: string;
    /**
     * Optional. The storage resource types being accessed (only for Account SAS). Please refer to
     * {@link AccountSASResourceTypes} for more details.
     */
    resourceTypes?: string;
    /**
     * Optional. The allowed HTTP protocol(s).
     */
    protocol?: SASProtocol;
    /**
     * Optional. The start time for this SAS token.
     */
    startsOn?: Date;
    /**
     * Optional only when identifier is provided. The expiry time for this SAS token.
     */
    expiresOn?: Date;
    /**
     * Optional. IP ranges allowed in this SAS.
     */
    ipRange?: SasIPRange;
    /**
     * Optional. The signed identifier (only for {@link BlobSASSignatureValues}).
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/establishing-a-stored-access-policy
     */
    identifier?: string;
    /**
     * Optional. Specifies which resources are accessible via the SAS (only for {@link BlobSASSignatureValues}).
     * @see https://docs.microsoft.com/rest/api/storageservices/create-service-sas#specifying-the-signed-resource-blob-service-only
     */
    resource?: string;
    /**
     * Value for cache-control header in Blob/File Service SAS.
     */
    cacheControl?: string;
    /**
     * Value for content-disposition header in Blob/File Service SAS.
     */
    contentDisposition?: string;
    /**
     * Value for content-encoding header in Blob/File Service SAS.
     */
    contentEncoding?: string;
    /**
     * Value for content-length header in Blob/File Service SAS.
     */
    contentLanguage?: string;
    /**
     * Value for content-type header in Blob/File Service SAS.
     */
    contentType?: string;
    /**
     * User delegation key properties.
     */
    userDelegationKey?: UserDelegationKey;
    /**
     * Indicate the depth of the directory specified in the canonicalizedresource field of the string-to-sign.
     * The depth of the directory is the number of directories beneath the root folder.
     */
    directoryDepth?: number;
    /**
     * Authorized AAD Object ID in GUID format. The AAD Object ID of a user authorized by the owner of the User Delegation Key
     * to perform the action granted by the SAS. The Azure Storage service will ensure that the owner of the user delegation key
     * has the required permissions before granting access but no additional permission check for the user specified in
     * this value will be performed. This cannot be used in conjuction with {@link signedUnauthorizedUserObjectId}.
     * This is only used for User Delegation SAS.
     */
    preauthorizedAgentObjectId?: string;
    /**
     * Unauthorized AAD Object ID in GUID format. The AAD Object ID of a user that is assumed to be unauthorized by the owner of the User Delegation Key.
     * The Azure Storage Service will perform an additional POSIX ACL check to determine if the user is authorized to perform the requested operation.
     * This cannot be used in conjuction with {@link signedAuthorizedUserObjectId}. This is only used for User Delegation SAS.
     */
    agentObjectId?: string;
    /**
     * A GUID value that will be logged in the storage diagnostic logs and can be used to correlate SAS generation with storage resource access.
     * This is only used for User Delegation SAS.
     */
    correlationId?: string;
}
/**
 * Options to configure {@link DataLakeServiceClient.generateAccountSasUrl} operation.
 */
export declare interface ServiceGenerateAccountSasUrlOptions {
    /**
     * The version of the service this SAS will target. If not specified, it will default to the version targeted by the
     * library.
     */
    version?: string;
    /**
     * Optional. SAS protocols allowed.
     */
    protocol?: SASProtocol;
    /**
     * Optional. When the SAS will take effect.
     */
    startsOn?: Date;
    /**
     * Optional. IP range allowed.
     */
    ipRange?: SasIPRange;
}
export declare interface ServiceGetUserDelegationKeyHeaders {
    clientRequestId?: string;
    requestId?: string;
    version?: string;
    date?: Date;
}
/** ***********************************************************/
/** DataLakeServiceClient option and response related models */
/** ***********************************************************/
export declare interface ServiceGetUserDelegationKeyOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
}
export declare type ServiceGetUserDelegationKeyResponse = UserDelegationKey & ServiceGetUserDelegationKeyHeaders & {
    _response: HttpResponse & {
        parsedHeaders: ServiceGetUserDelegationKeyHeaders;
        bodyAsText: string;
        parsedBody: UserDelegationKeyModel;
    };
};
export { ServiceListContainersSegmentResponse };
export declare interface ServiceListFileSystemsOptions extends CommonOptions {
    abortSignal?: AbortSignalLike;
    prefix?: string;
    includeMetadata?: boolean;
    /**
     * Specifies whether soft deleted File System should be included in the response.
     */
    includeDeleted?: boolean;
}
export declare interface ServiceListFileSystemsSegmentHeaders {
    clientRequestId?: string;
    requestId?: string;
    version?: string;
}
export declare type ServiceListFileSystemsSegmentResponse = ListFileSystemsSegmentResponse & ServiceListFileSystemsSegmentHeaders & {
    _response: HttpResponse & {
        parsedHeaders: ServiceListFileSystemsSegmentHeaders;
        bodyAsText: string;
        parsedBody: ListFileSystemsSegmentResponse;
    };
};
/**
 * Options to configure {@link DataLakeServiceClient.renameFileSystem}.
 */
export declare type ServiceRenameFileSystemOptions = ServiceRenameContainerOptions;
/**
 * Options to configure {@link DataLakeServiceClient.undeleteFileSystem}.
 */
export declare interface ServiceUndeleteFileSystemOptions extends CommonOptions {
    /**
     * An implementation of the `AbortSignalLike` interface to signal the request to cancel the operation.
     * For example, use the &commat;azure/abort-controller to create an `AbortSignal`.
     */
    abortSignal?: AbortSignalLike;
    /**
     * Optional. Specifies the new name of the restored File System.
     * Will use its original name if this is not specified.
     * @deprecated Restore FileSystem to a different name is not supported by service anymore.
     */
    destinationFileSystemName?: string;
}
export declare interface SignedIdentifier<T> {
    id: string;
    accessPolicy: T;
}
/**
 * StorageBrowserPolicy will handle differences between Node.js and browser runtime, including:
 *
 * 1. Browsers cache GET/HEAD requests by adding conditional headers such as 'IF_MODIFIED_SINCE'.
 * StorageBrowserPolicy is a policy used to add a timestamp query to GET/HEAD request URL
 * thus avoid the browser cache.
 *
 * 2. Remove cookie header for security
 *
 * 3. Remove content-length header to avoid browsers warning
 */
export declare class StorageBrowserPolicy extends BaseRequestPolicy {
    /**
     * Creates an instance of StorageBrowserPolicy.
     * @param nextPolicy -
     * @param options -
     */
    constructor(nextPolicy: RequestPolicy, options: RequestPolicyOptions);
    /**
     * Sends out request.
     *
     * @param request -
     */
    sendRequest(request: WebResource): Promise<HttpOperationResponse>;
}
/**
 * StorageBrowserPolicyFactory is a factory class helping generating StorageBrowserPolicy objects.
 */
export declare class StorageBrowserPolicyFactory implements RequestPolicyFactory {
    /**
     * Creates a StorageBrowserPolicyFactory object.
     *
     * @param nextPolicy -
     * @param options -
     */
    create(nextPolicy: RequestPolicy, options: RequestPolicyOptions): StorageBrowserPolicy;
}
/**
 * A StorageClient represents a based URL class for {@link BlobServiceClient}, {@link ContainerClient}
 * and etc.
 */
declare abstract class StorageClient {
    /**
     * Encoded URL string value.
     */
    readonly url: string;
    readonly accountName: string;
    /**
     * Encoded URL string value for corresponding blob endpoint.
     */
    protected readonly blobEndpointUrl: string;
    /**
     * Encoded URL string value for corresponding dfs endpoint.
     */
    protected readonly dfsEndpointUrl: string;
    /* Excluded from this release type: pipeline */
    /**
     * Such as AnonymousCredential, StorageSharedKeyCredential or any credential from the `@azure/identity` package to authenticate requests to the service. You can also provide an object that implements the TokenCredential interface. If not specified, AnonymousCredential is used.
     */
    readonly credential: StorageSharedKeyCredential | AnonymousCredential | TokenCredential;
    /**
     * StorageClient is a reference to protocol layer operations entry, which is
     * generated by AutoRest generator.
     */
    protected readonly storageClientContext: StorageClientContext;
    /**
     * storageClientContextWithBlobEndpoint is a reference to protocol layer operations entry, which is
     * generated by AutoRest generator, with its url pointing to the Blob endpoint.
     */
    protected readonly storageClientContextToBlobEndpoint: StorageClientContext;
    /**
     */
    protected readonly isHttps: boolean;
    /**
     * Creates an instance of StorageClient.
     * @param url - url to resource
     * @param pipeline - request policy pipeline.
     */
    protected constructor(url: string, pipeline: Pipeline);
}
declare class StorageClientContext extends coreHttp.ServiceClient {
    url: string;
    version: string;
    resource: string;
    /**
     * Initializes a new instance of the StorageClientContext class.
     * @param url The URL of the service account, container, or blob that is the target of the desired
     *            operation.
     * @param options The parameter options
     */
    constructor(url: string, options?: StorageClientOptionalParams);
}
/** Optional parameters. */
declare interface StorageClientOptionalParams extends coreHttp.ServiceClientOptions {
    /** Specifies the version of the operation to use for this request. */
    version?: string;
    /** The value must be "filesystem" for all filesystem operations. */
    resource?: string;
    /** Overrides client endpoint. */
    endpoint?: string;
}
export declare const StorageOAuthScopes: string | string[];
/**
 * Options interface for the {@link newPipeline} function.
 */
export declare interface StoragePipelineOptions {
    /**
     * Options to configure a proxy for outgoing requests.
     */
    proxyOptions?: ProxyOptions;
    /**
     * Options for adding user agent details to outgoing requests.
     */
    userAgentOptions?: UserAgentOptions;
    /**
     * Configures the built-in retry policy behavior.
     */
    retryOptions?: StorageRetryOptions;
    /**
     * Keep alive configurations. Default keep-alive is enabled.
     */
    keepAliveOptions?: KeepAliveOptions;
    /**
     * Configures the HTTP client to send requests and receive responses.
     */
    httpClient?: IHttpClient;
}
/**
 * Storage Blob retry options interface.
 */
export declare interface StorageRetryOptions {
    /**
     * Optional. StorageRetryPolicyType, default is exponential retry policy.
     */
    readonly retryPolicyType?: StorageRetryPolicyType;
    /**
     * Optional. Max try number of attempts, default is 4.
     * A value of 1 means 1 try and no retries.
     * A value smaller than 1 means default retry number of attempts.
     */
    readonly maxTries?: number;
    /**
     * Optional. Indicates the maximum time in ms allowed for any single try of an HTTP request.
     * A value of zero or undefined means no default timeout on SDK client, Azure
     * Storage server's default timeout policy will be used.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/setting-timeouts-for-blob-service-operations
     */
    readonly tryTimeoutInMs?: number;
    /**
     * Optional. Specifies the amount of delay to use before retrying an operation (default is 4s or 4 * 1000ms).
     * The delay increases (exponentially or linearly) with each retry up to a maximum specified by
     * maxRetryDelayInMs. If you specify 0, then you must also specify 0 for maxRetryDelayInMs.
     */
    readonly retryDelayInMs?: number;
    /**
     * Optional. Specifies the maximum delay allowed before retrying an operation (default is 120s or 120 * 1000ms).
     * If you specify 0, then you must also specify 0 for retryDelayInMs.
     */
    readonly maxRetryDelayInMs?: number;
    /**
     * If a secondaryHost is specified, retries will be tried against this host. If secondaryHost is undefined
     * (the default) then operations are not retried against another host.
     *
     * NOTE: Before setting this field, make sure you understand the issues around
     * reading stale and potentially-inconsistent data at
     * {@link https://docs.microsoft.com/en-us/azure/storage/common/storage-designing-ha-apps-with-ragrs}
     */
    readonly secondaryHost?: string;
}
/**
 * Retry policy with exponential retry and linear retry implemented.
 */
export declare class StorageRetryPolicy extends BaseRequestPolicy {
    /**
     * RetryOptions.
     */
    private readonly retryOptions;
    /**
     * Creates an instance of RetryPolicy.
     *
     * @param nextPolicy -
     * @param options -
     * @param retryOptions -
     */
    constructor(nextPolicy: RequestPolicy, options: RequestPolicyOptions, retryOptions?: StorageRetryOptions);
    /**
     * Sends request.
     *
     * @param request -
     */
    sendRequest(request: WebResource): Promise<HttpOperationResponse>;
    /**
     * Decide and perform next retry. Won't mutate request parameter.
     *
     * @param request -
     * @param secondaryHas404 -  If attempt was against the secondary & it returned a StatusNotFound (404), then
     *                                   the resource was not found. This may be due to replication delay. So, in this
     *                                   case, we'll never try the secondary again for this operation.
     * @param attempt -           How many retries has been attempted to performed, starting from 1, which includes
     *                                   the attempt will be performed by this method call.
     */
    protected attemptSendRequest(request: WebResource, secondaryHas404: boolean, attempt: number): Promise<HttpOperationResponse>;
    /**
     * Decide whether to retry according to last HTTP response and retry counters.
     *
     * @param isPrimaryRetry -
     * @param attempt -
     * @param response -
     * @param err -
     */
    protected shouldRetry(isPrimaryRetry: boolean, attempt: number, response?: HttpOperationResponse, err?: RestError): boolean;
    /**
     * Delay a calculated time between retries.
     *
     * @param isPrimaryRetry -
     * @param attempt -
     * @param abortSignal -
     */
    private delay;
}
/**
 * StorageRetryPolicyFactory is a factory class helping generating {@link StorageRetryPolicy} objects.
 */
export declare class StorageRetryPolicyFactory implements RequestPolicyFactory {
    private retryOptions?;
    /**
     * Creates an instance of StorageRetryPolicyFactory.
     * @param retryOptions -
     */
    constructor(retryOptions?: StorageRetryOptions);
    /**
     * Creates a StorageRetryPolicy object.
     *
     * @param nextPolicy -
     * @param options -
     */
    create(nextPolicy: RequestPolicy, options: RequestPolicyOptions): StorageRetryPolicy;
}
/**
 * RetryPolicy types.
 */
export declare enum StorageRetryPolicyType {
    /**
     * Exponential retry. Retry time delay grows exponentially.
     */
    EXPONENTIAL = 0,
    /**
     * Linear retry. Retry time delay grows linearly.
     */
    FIXED = 1
}
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * StorageSharedKeyCredential for account key authorization of Azure Storage service.
 */
export declare class StorageSharedKeyCredential extends Credential {
    /**
     * Azure Storage account name; readonly.
     */
    readonly accountName: string;
    /**
     * Azure Storage account key; readonly.
     */
    private readonly accountKey;
    /**
     * Creates an instance of StorageSharedKeyCredential.
     * @param accountName -
     * @param accountKey -
     */
    constructor(accountName: string, accountKey: string);
    /**
     * Creates a StorageSharedKeyCredentialPolicy object.
     *
     * @param nextPolicy -
     * @param options -
     */
    create(nextPolicy: RequestPolicy, options: RequestPolicyOptions): StorageSharedKeyCredentialPolicy;
    /**
     * Generates a hash signature for an HTTP request or for a SAS.
     *
     * @param stringToSign -
     */
    computeHMACSHA256(stringToSign: string): string;
}
/**
 * StorageSharedKeyCredentialPolicy is a policy used to sign HTTP request with a shared key.
 */
export declare class StorageSharedKeyCredentialPolicy extends CredentialPolicy {
    /**
     * Reference to StorageSharedKeyCredential which generates StorageSharedKeyCredentialPolicy
     */
    private readonly factory;
    /**
     * Creates an instance of StorageSharedKeyCredentialPolicy.
     * @param nextPolicy -
     * @param options -
     * @param factory -
     */
    constructor(nextPolicy: RequestPolicy, options: RequestPolicyOptions, factory: StorageSharedKeyCredential);
    /**
     * Signs request.
     *
     * @param request -
     */
    protected signRequest(request: WebResource): WebResource;
    /**
     * Retrieve header value according to shared key sign rules.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/authenticate-with-shared-key
     *
     * @param request -
     * @param headerName -
     */
    private getHeaderValueToSign;
    /**
     * To construct the CanonicalizedHeaders portion of the signature string, follow these steps:
     * 1. Retrieve all headers for the resource that begin with x-ms-, including the x-ms-date header.
     * 2. Convert each HTTP header name to lowercase.
     * 3. Sort the headers lexicographically by header name, in ascending order.
     *    Each header may appear only once in the string.
     * 4. Replace any linear whitespace in the header value with a single space.
     * 5. Trim any whitespace around the colon in the header.
     * 6. Finally, append a new-line character to each canonicalized header in the resulting list.
     *    Construct the CanonicalizedHeaders string by concatenating all headers in this list into a single string.
     *
     * @param request -
     */
    private getCanonicalizedHeadersString;
    /**
     * Retrieves the webResource canonicalized resource string.
     *
     * @param request -
     */
    private getCanonicalizedResourceString;
}
export declare const ToBlobEndpointHostMappings: string[][];
export declare const ToDfsEndpointHostMappings: string[][];
export declare interface UserDelegationKey {
    signedObjectId: string;
    signedTenantId: string;
    signedStartsOn: Date;
    signedExpiresOn: Date;
    signedService: string;
    signedVersion: string;
    value: string;
}
export { UserDelegationKeyModel };
export { WebResource };
export {};
