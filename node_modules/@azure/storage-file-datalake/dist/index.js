'use strict';

Object.defineProperty(exports, '__esModule', { value: true });

require('@azure/core-paging');
var coreHttp = require('@azure/core-http');
var storageBlob = require('@azure/storage-blob');
var crypto = require('crypto');
var tslib = require('tslib');
var coreTracing = require('@azure/core-tracing');
var logger$1 = require('@azure/logger');
var abortController = require('@azure/abort-controller');
var os = require('os');
var events = require('events');
var stream = require('stream');
var fs = require('fs');
var util = require('util');

// Copyright (c) Microsoft Corporation.
/**
 * Credential policy used to sign HTTP(S) requests before sending. This is an
 * abstract class.
 */
class CredentialPolicy extends coreHttp.BaseRequestPolicy {
    /**
     * Sends out request.
     *
     * @param request -
     */
    sendRequest(request) {
        return this._nextPolicy.sendRequest(this.signRequest(request));
    }
    /**
     * Child classes must implement this method with request signing. This method
     * will be executed in {@link sendRequest}.
     *
     * @param request -
     */
    signRequest(request) {
        // Child classes must override this method with request signing. This method
        // will be executed in sendRequest().
        return request;
    }
}

// Copyright (c) Microsoft Corporation.
/**
 * AnonymousCredentialPolicy is used with HTTP(S) requests that read public resources
 * or for use with Shared Access Signatures (SAS).
 */
class AnonymousCredentialPolicy extends CredentialPolicy {
    /**
     * Creates an instance of AnonymousCredentialPolicy.
     * @param nextPolicy -
     * @param options -
     */
    // The base class has a protected constructor. Adding a public one to enable constructing of this class.
    /* eslint-disable-next-line @typescript-eslint/no-useless-constructor*/
    constructor(nextPolicy, options) {
        super(nextPolicy, options);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Credential is an abstract class for Azure Storage HTTP requests signing. This
 * class will host an credentialPolicyCreator factory which generates CredentialPolicy.
 */
class Credential {
    /**
     * Creates a RequestPolicy object.
     *
     * @param _nextPolicy -
     * @param _options -
     */
    create(_nextPolicy, _options) {
        throw new Error("Method should be implemented in children classes.");
    }
}

// Copyright (c) Microsoft Corporation.
/**
 * AnonymousCredential provides a credentialPolicyCreator member used to create
 * AnonymousCredentialPolicy objects. AnonymousCredentialPolicy is used with
 * HTTP(S) requests that read public resources or for use with Shared Access
 * Signatures (SAS).
 */
class AnonymousCredential extends Credential {
    /**
     * Creates an {@link AnonymousCredentialPolicy} object.
     *
     * @param nextPolicy -
     * @param options -
     */
    create(nextPolicy, options) {
        return new AnonymousCredentialPolicy(nextPolicy, options);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
const SDK_VERSION = "12.7.0";
const SERVICE_VERSION = "2020-10-02";
const KB = 1024;
const MB = KB * 1024;
const DEFAULT_HIGH_LEVEL_CONCURRENCY = 5;
const FILE_MAX_SINGLE_UPLOAD_THRESHOLD = 100 * MB;
const FILE_UPLOAD_MAX_CHUNK_SIZE = 4000 * MB;
const FILE_UPLOAD_DEFAULT_CHUNK_SIZE = 8 * MB;
const BLOCK_BLOB_MAX_BLOCKS = 50000;
const FILE_MAX_SIZE_BYTES = BLOCK_BLOB_MAX_BLOCKS * FILE_UPLOAD_MAX_CHUNK_SIZE;
const StorageOAuthScopes = "https://storage.azure.com/.default";
const StorageDataLakeLoggingAllowedHeaderNames = [
    "Access-Control-Allow-Origin",
    "Cache-Control",
    "Content-Length",
    "Content-Type",
    "Date",
    "Request-Id",
    "traceparent",
    "Transfer-Encoding",
    "User-Agent",
    "x-ms-client-request-id",
    "x-ms-date",
    "x-ms-error-code",
    "x-ms-request-id",
    "x-ms-return-client-request-id",
    "x-ms-version",
    "Accept-Ranges",
    "Content-Disposition",
    "Content-Encoding",
    "Content-Language",
    "Content-MD5",
    "Content-Range",
    "ETag",
    "Last-Modified",
    "Server",
    "Vary",
    "x-ms-content-crc64",
    "x-ms-copy-action",
    "x-ms-copy-completion-time",
    "x-ms-copy-id",
    "x-ms-copy-progress",
    "x-ms-copy-status",
    "x-ms-has-immutability-policy",
    "x-ms-has-legal-hold",
    "x-ms-lease-state",
    "x-ms-lease-status",
    "x-ms-range",
    "x-ms-request-server-encrypted",
    "x-ms-server-encrypted",
    "x-ms-snapshot",
    "x-ms-source-range",
    "If-Match",
    "If-Modified-Since",
    "If-None-Match",
    "If-Unmodified-Since",
    "x-ms-access-tier",
    "x-ms-access-tier-change-time",
    "x-ms-access-tier-inferred",
    "x-ms-account-kind",
    "x-ms-archive-status",
    "x-ms-blob-append-offset",
    "x-ms-blob-cache-control",
    "x-ms-blob-committed-block-count",
    "x-ms-blob-condition-appendpos",
    "x-ms-blob-condition-maxsize",
    "x-ms-blob-content-disposition",
    "x-ms-blob-content-encoding",
    "x-ms-blob-content-language",
    "x-ms-blob-content-length",
    "x-ms-blob-content-md5",
    "x-ms-blob-content-type",
    "x-ms-blob-public-access",
    "x-ms-blob-sequence-number",
    "x-ms-blob-type",
    "x-ms-copy-destination-snapshot",
    "x-ms-creation-time",
    "x-ms-default-encryption-scope",
    "x-ms-delete-snapshots",
    "x-ms-delete-type-permanent",
    "x-ms-deny-encryption-scope-override",
    "x-ms-encryption-algorithm",
    "x-ms-if-sequence-number-eq",
    "x-ms-if-sequence-number-le",
    "x-ms-if-sequence-number-lt",
    "x-ms-incremental-copy",
    "x-ms-lease-action",
    "x-ms-lease-break-period",
    "x-ms-lease-duration",
    "x-ms-lease-id",
    "x-ms-lease-time",
    "x-ms-page-write",
    "x-ms-proposed-lease-id",
    "x-ms-range-get-content-md5",
    "x-ms-rehydrate-priority",
    "x-ms-sequence-number-action",
    "x-ms-sku-name",
    "x-ms-source-content-md5",
    "x-ms-source-if-match",
    "x-ms-source-if-modified-since",
    "x-ms-source-if-none-match",
    "x-ms-source-if-unmodified-since",
    "x-ms-tag-count",
    "x-ms-encryption-key-sha256"
];
const StorageDataLakeLoggingAllowedQueryParameters = [
    "comp",
    "maxresults",
    "rscc",
    "rscd",
    "rsce",
    "rscl",
    "rsct",
    "se",
    "si",
    "sip",
    "sp",
    "spr",
    "sr",
    "srt",
    "ss",
    "st",
    "sv",
    "include",
    "marker",
    "prefix",
    "copyid",
    "restype",
    "blockid",
    "blocklisttype",
    "delimiter",
    "prevsnapshot",
    "ske",
    "skoid",
    "sks",
    "skt",
    "sktid",
    "skv",
    "snapshot"
];
const UrlConstants = {
    Parameters: {
        FORCE_BROWSER_NO_CACHE: "_",
        SIGNATURE: "sig",
        SNAPSHOT: "snapshot",
        TIMEOUT: "timeout"
    }
};
const HeaderConstants = {
    AUTHORIZATION: "Authorization",
    AUTHORIZATION_SCHEME: "Bearer",
    CONTENT_ENCODING: "Content-Encoding",
    CONTENT_ID: "Content-ID",
    CONTENT_LANGUAGE: "Content-Language",
    CONTENT_LENGTH: "Content-Length",
    CONTENT_MD5: "Content-Md5",
    CONTENT_TRANSFER_ENCODING: "Content-Transfer-Encoding",
    CONTENT_TYPE: "Content-Type",
    COOKIE: "Cookie",
    DATE: "date",
    IF_MATCH: "if-match",
    IF_MODIFIED_SINCE: "if-modified-since",
    IF_NONE_MATCH: "if-none-match",
    IF_UNMODIFIED_SINCE: "if-unmodified-since",
    PREFIX_FOR_STORAGE: "x-ms-",
    RANGE: "Range",
    USER_AGENT: "User-Agent",
    X_MS_CLIENT_REQUEST_ID: "x-ms-client-request-id",
    X_MS_COPY_SOURCE: "x-ms-copy-source",
    X_MS_DATE: "x-ms-date",
    X_MS_ERROR_CODE: "x-ms-error-code",
    X_MS_VERSION: "x-ms-version"
};
const DevelopmentConnectionString = `DefaultEndpointsProtocol=http;AccountName=devstoreaccount1;AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;BlobEndpoint=http://127.0.0.1:10000/devstoreaccount1;`;
// Mapping pairs to transform url from dfs endpoint to blob endpoint
// Customize this value to add more mapping patterns
const ToBlobEndpointHostMappings = [
    ["dfs.preprod.core.windows.net", "blob.preprod.core.windows.net"],
    ["dfs.core.windows.net", "blob.core.windows.net"],
    ["dfs.core.chinacloudapi.cn", "blob.core.chinacloudapi.cn"],
    ["dfs.core.usgovcloudapi.net", "blob.core.usgovcloudapi.net"],
    ["dfs.core.cloudapi.de", "blob.core.cloudapi.de"],
    ["dfs.core.microsoft.scloud", "blob.core.microsoft.scloud"],
    ["dfs.core.eaglex.ic.gov", "blob.core.eaglex.ic.gov"]
];
// Mapping pairs to transform url from blob endpoint to dfs endpoint
// Customize this value to add more mapping patterns
const ToDfsEndpointHostMappings = [
    ["blob.preprod.core.windows.net", "dfs.preprod.core.windows.net"],
    ["blob.core.windows.net", "dfs.core.windows.net"],
    ["blob.core.chinacloudapi.cn", "dfs.core.chinacloudapi.cn"],
    ["blob.core.usgovcloudapi.net", "dfs.core.usgovcloudapi.net"],
    ["blob.core.cloudapi.de", "dfs.core.cloudapi.de"],
    ["blob.core.microsoft.scloud", "dfs.core.microsoft.scloud"],
    ["blob.core.eaglex.ic.gov", "dfs.core.eaglex.ic.gov"]
];
const ETagAny = "*";
const DeletionIdKey = "deletionid";
const PathResultTypeConstants = {
    FileResourceType: "file",
    DirectoryResourceType: "directory"
};

/**
 * Reserved URL characters must be properly escaped for Storage services like Blob or File.
 *
 * ## URL encode and escape strategy for JS SDKs
 *
 * When customers pass a URL string into XxxClient classes constructors, the URL string may already be URL encoded or not.
 * But before sending to Azure Storage server, the URL must be encoded. However, it's hard for a SDK to guess whether the URL
 * string has been encoded or not. We have 2 potential strategies, and chose strategy two for the XxxClient constructors.
 *
 * ### Strategy One: Assume the customer URL string is not encoded, and always encode URL string in SDK.
 *
 * This is what legacy V2 SDK does, simple and works for most of the cases.
 * - When customer URL string is "http://account.blob.core.windows.net/con/b:",
 *   SDK will encode it to "http://account.blob.core.windows.net/con/b%3A" and send to server. A blob named "b:" will be created.
 * - When customer URL string is "http://account.blob.core.windows.net/con/b%3A",
 *   SDK will encode it to "http://account.blob.core.windows.net/con/b%253A" and send to server. A blob named "b%3A" will be created.
 *
 * But this strategy will make it not possible to create a blob with "?" in it's name. Because when customer URL string is
 * "http://account.blob.core.windows.net/con/blob?name", the "?name" will be treated as URL paramter instead of blob name.
 * If customer URL string is "http://account.blob.core.windows.net/con/blob%3Fname", a blob named "blob%3Fname" will be created.
 * V2 SDK doesn't have this issue because it doesn't allow customer pass in a full URL, it accepts a separate blob name and encodeURIComponent for it.
 * We cannot accept a SDK cannot create a blob name with "?". So we implement strategy two:
 *
 * ### Strategy Two: SDK doesn't assume the URL has been encoded or not. It will just escape the special characters.
 *
 * This is what V10 Blob Go SDK does. It accepts a URL type in Go, and call url.EscapedPath() to escape the special chars unescaped.
 * - When customer URL string is "http://account.blob.core.windows.net/con/b:",
 *   SDK will escape ":" like "http://account.blob.core.windows.net/con/b%3A" and send to server. A blob named "b:" will be created.
 * - When customer URL string is "http://account.blob.core.windows.net/con/b%3A",
 *   There is no special characters, so send "http://account.blob.core.windows.net/con/b%3A" to server. A blob named "b:" will be created.
 * - When customer URL string is "http://account.blob.core.windows.net/con/b%253A",
 *   There is no special characters, so send "http://account.blob.core.windows.net/con/b%253A" to server. A blob named "b%3A" will be created.
 *
 * This strategy gives us flexibility to create with any special characters. But "%" will be treated as a special characters, if the URL string
 * is not encoded, there shouldn't a "%" in the URL string, otherwise the URL is not a valid URL.
 * If customer needs to create a blob with "%" in it's blob name, use "%25" instead of "%". Just like above 3rd sample.
 * And following URL strings are invalid:
 * - "http://account.blob.core.windows.net/con/b%"
 * - "http://account.blob.core.windows.net/con/b%2"
 * - "http://account.blob.core.windows.net/con/b%G"
 *
 * Another special character is "?", use "%2F" to represent a blob name with "?" in a URL string.
 *
 * ### Strategy for containerName, blobName or other specific XXXName parameters in methods such as `containerClient.getBlobClient(blobName)`
 *
 * We will apply strategy one, and call encodeURIComponent for these parameters like blobName. Because what customers passes in is a plain name instead of a URL.
 *
 * @see https://docs.microsoft.com/en-us/rest/api/storageservices/naming-and-referencing-containers--blobs--and-metadata
 * @see https://docs.microsoft.com/en-us/rest/api/storageservices/naming-and-referencing-shares--directories--files--and-metadata
 *
 * @param url -
 */
function escapeURLPath(url) {
    const urlParsed = coreHttp.URLBuilder.parse(url);
    let path = urlParsed.getPath();
    path = path || "/";
    path = escape(path);
    urlParsed.setPath(path);
    return urlParsed.toString();
}
function getProxyUriFromDevConnString(connectionString) {
    // Development Connection String
    // https://docs.microsoft.com/en-us/azure/storage/common/storage-configure-connection-string#connect-to-the-emulator-account-using-the-well-known-account-name-and-key
    let proxyUri = "";
    if (connectionString.search("DevelopmentStorageProxyUri=") !== -1) {
        // CONNECTION_STRING=UseDevelopmentStorage=true;DevelopmentStorageProxyUri=http://myProxyUri
        const matchCredentials = connectionString.split(";");
        for (const element of matchCredentials) {
            if (element.trim().startsWith("DevelopmentStorageProxyUri=")) {
                proxyUri = element.trim().match("DevelopmentStorageProxyUri=(.*)")[1];
            }
        }
    }
    return proxyUri;
}
function getValueInConnString(connectionString, argument) {
    const elements = connectionString.split(";");
    for (const element of elements) {
        if (element.trim().startsWith(argument)) {
            return element.trim().match(argument + "=(.*)")[1];
        }
    }
    return "";
}
/**
 * Extracts the parts of an Azure Storage account connection string.
 *
 * @param connectionString - Connection string.
 * @returns String key value pairs of the storage account's url and credentials.
 */
function extractConnectionStringParts(connectionString) {
    let proxyUri = "";
    if (connectionString.startsWith("UseDevelopmentStorage=true")) {
        // Development connection string
        proxyUri = getProxyUriFromDevConnString(connectionString);
        connectionString = DevelopmentConnectionString;
    }
    // Matching BlobEndpoint in the Account connection string
    let blobEndpoint = getValueInConnString(connectionString, "BlobEndpoint");
    // Slicing off '/' at the end if exists
    // (The methods that use `extractConnectionStringParts` expect the url to not have `/` at the end)
    blobEndpoint = blobEndpoint.endsWith("/") ? blobEndpoint.slice(0, -1) : blobEndpoint;
    if (connectionString.search("DefaultEndpointsProtocol=") !== -1 &&
        connectionString.search("AccountKey=") !== -1) {
        // Account connection string
        let defaultEndpointsProtocol = "";
        let accountName = "";
        let accountKey = Buffer.from("accountKey", "base64");
        let endpointSuffix = "";
        // Get account name and key
        accountName = getValueInConnString(connectionString, "AccountName");
        accountKey = Buffer.from(getValueInConnString(connectionString, "AccountKey"), "base64");
        if (!blobEndpoint) {
            // BlobEndpoint is not present in the Account connection string
            // Can be obtained from `${defaultEndpointsProtocol}://${accountName}.blob.${endpointSuffix}`
            defaultEndpointsProtocol = getValueInConnString(connectionString, "DefaultEndpointsProtocol");
            const protocol = defaultEndpointsProtocol.toLowerCase();
            if (protocol !== "https" && protocol !== "http") {
                throw new Error("Invalid DefaultEndpointsProtocol in the provided Connection String. Expecting 'https' or 'http'");
            }
            endpointSuffix = getValueInConnString(connectionString, "EndpointSuffix");
            if (!endpointSuffix) {
                throw new Error("Invalid EndpointSuffix in the provided Connection String");
            }
            blobEndpoint = `${defaultEndpointsProtocol}://${accountName}.blob.${endpointSuffix}`;
        }
        if (!accountName) {
            throw new Error("Invalid AccountName in the provided Connection String");
        }
        else if (accountKey.length === 0) {
            throw new Error("Invalid AccountKey in the provided Connection String");
        }
        return {
            kind: "AccountConnString",
            url: blobEndpoint,
            accountName,
            accountKey,
            proxyUri
        };
    }
    else {
        // SAS connection string
        const accountSas = getValueInConnString(connectionString, "SharedAccessSignature");
        const accountName = getAccountNameFromUrl(blobEndpoint);
        if (!blobEndpoint) {
            throw new Error("Invalid BlobEndpoint in the provided SAS Connection String");
        }
        else if (!accountSas) {
            throw new Error("Invalid SharedAccessSignature in the provided SAS Connection String");
        }
        return { kind: "SASConnString", url: blobEndpoint, accountName, accountSas };
    }
}
/**
 * Internal escape method implemented Strategy Two mentioned in escapeURL() description.
 *
 * @param text -
 */
function escape(text) {
    return encodeURIComponent(text)
        .replace(/%2F/g, "/") // Don't escape for "/"
        .replace(/'/g, "%27") // Escape for "'"
        .replace(/\+/g, "%20")
        .replace(/%25/g, "%"); // Revert encoded "%"
}
/**
 * Append a string to URL path. Will remove duplicated "/" in front of the string
 * when URL path ends with a "/".
 *
 * @param url - Source URL string
 * @param name - String to be appended to URL
 * @returns An updated URL string
 */
function appendToURLPath(url, name) {
    const urlParsed = coreHttp.URLBuilder.parse(url);
    let path = urlParsed.getPath();
    path = path ? (path.endsWith("/") ? `${path}${name}` : `${path}/${name}`) : name;
    urlParsed.setPath(path);
    return urlParsed.toString();
}
/**
 * Append a string to URL query.
 *
 * @param url - Source URL string.
 * @param queryParts - String to be appended to the URL query.
 * @returns An updated URL string.
 */
function appendToURLQuery(url, queryParts) {
    const urlParsed = coreHttp.URLBuilder.parse(url);
    let query = urlParsed.getQuery();
    if (query) {
        query += "&" + queryParts;
    }
    else {
        query = queryParts;
    }
    urlParsed.setQuery(query);
    return urlParsed.toString();
}
/**
 * Set URL parameter name and value. If name exists in URL parameters, old value
 * will be replaced by name key. If not provide value, the parameter will be deleted.
 *
 * @param url - Source URL string
 * @param name - Parameter name
 * @param value - Parameter value
 * @returns An updated URL string
 */
function setURLParameter(url, name, value) {
    const urlParsed = coreHttp.URLBuilder.parse(url);
    urlParsed.setQueryParameter(name, value);
    return urlParsed.toString();
}
/**
 * Set URL host.
 *
 * @param url - Source URL string
 * @param host - New host string
 * @returns An updated URL string
 */
function setURLHost(url, host) {
    const urlParsed = coreHttp.URLBuilder.parse(url);
    urlParsed.setHost(host);
    return urlParsed.toString();
}
/**
 * Get URL path from an URL string.
 *
 * @param url - Source URL string
 */
function getURLPath(url) {
    const urlParsed = coreHttp.URLBuilder.parse(url);
    return urlParsed.getPath();
}
/**
 * Set URL path.
 *
 * @param url -
 * @param path -
 */
function setURLPath(url, path) {
    const urlParsed = coreHttp.URLBuilder.parse(url);
    urlParsed.setPath(path);
    return urlParsed.toString();
}
/**
 * Get URL scheme from an URL string.
 *
 * @param url - Source URL string
 */
function getURLScheme(url) {
    const urlParsed = coreHttp.URLBuilder.parse(url);
    return urlParsed.getScheme();
}
/**
 * Get URL path and query from an URL string.
 *
 * @param url - Source URL string
 */
function getURLPathAndQuery(url) {
    const urlParsed = coreHttp.URLBuilder.parse(url);
    const pathString = urlParsed.getPath();
    if (!pathString) {
        throw new RangeError("Invalid url without valid path.");
    }
    let queryString = urlParsed.getQuery() || "";
    queryString = queryString.trim();
    if (queryString !== "") {
        queryString = queryString.startsWith("?") ? queryString : `?${queryString}`; // Ensure query string start with '?'
    }
    return `${pathString}${queryString}`;
}
/**
 * Get URL query key value pairs from an URL string.
 *
 * @param url -
 */
function getURLQueries(url) {
    let queryString = coreHttp.URLBuilder.parse(url).getQuery();
    if (!queryString) {
        return {};
    }
    queryString = queryString.trim();
    queryString = queryString.startsWith("?") ? queryString.substr(1) : queryString;
    let querySubStrings = queryString.split("&");
    querySubStrings = querySubStrings.filter((value) => {
        const indexOfEqual = value.indexOf("=");
        const lastIndexOfEqual = value.lastIndexOf("=");
        return (indexOfEqual > 0 && indexOfEqual === lastIndexOfEqual && lastIndexOfEqual < value.length - 1);
    });
    const queries = {};
    for (const querySubString of querySubStrings) {
        const splitResults = querySubString.split("=");
        const key = splitResults[0];
        const value = splitResults[1];
        queries[key] = value;
    }
    return queries;
}
/**
 * Set URL query string.
 *
 * @param url -
 * @param queryString -
 */
function setURLQueries(url, queryString) {
    const urlParsed = coreHttp.URLBuilder.parse(url);
    urlParsed.setQuery(queryString);
    return urlParsed.toString();
}
/**
 * Rounds a date off to seconds.
 *
 * @param date -
 * @param withMilliseconds - If true, YYYY-MM-DDThh:mm:ss.fffffffZ will be returned;
 *                                          If false, YYYY-MM-DDThh:mm:ssZ will be returned.
 * @returns Date string in ISO8061 format, with or without 7 milliseconds component
 */
function truncatedISO8061Date(date, withMilliseconds = true) {
    // Date.toISOString() will return like "2018-10-29T06:34:36.139Z"
    const dateString = date.toISOString();
    return withMilliseconds
        ? dateString.substring(0, dateString.length - 1) + "0000" + "Z"
        : dateString.substring(0, dateString.length - 5) + "Z";
}
/**
 * Base64 encode.
 *
 * @param content -
 */
function base64encode(content) {
    return !coreHttp.isNode ? btoa(content) : Buffer.from(content).toString("base64");
}
/**
 * Delay specified time interval.
 *
 * @param timeInMs -
 * @param aborter -
 * @param abortError -
 */
async function delay(timeInMs, aborter, abortError) {
    return new Promise((resolve, reject) => {
        /* eslint-disable-next-line prefer-const*/
        let timeout;
        const abortHandler = () => {
            if (timeout !== undefined) {
                clearTimeout(timeout);
            }
            reject(abortError);
        };
        const resolveHandler = () => {
            if (aborter !== undefined) {
                aborter.removeEventListener("abort", abortHandler);
            }
            resolve();
        };
        timeout = setTimeout(resolveHandler, timeInMs);
        if (aborter !== undefined) {
            aborter.addEventListener("abort", abortHandler);
        }
    });
}
/**
 * If two strings are equal when compared case insensitive.
 *
 * @param str1 -
 * @param str2 -
 */
function iEqual(str1, str2) {
    return str1.toLocaleLowerCase() === str2.toLocaleLowerCase();
}
/**
 * Extracts account name from the blobEndpointUrl
 * @param blobEndpointUrl - blobEndpointUrl to extract the account name from
 * @returns account name
 */
function getAccountNameFromUrl(blobEndpointUrl) {
    const parsedUrl = coreHttp.URLBuilder.parse(blobEndpointUrl);
    let accountName;
    try {
        if (parsedUrl.getHost().split(".")[1] === "blob") {
            // `${defaultEndpointsProtocol}://${accountName}.blob.${endpointSuffix}`;
            accountName = parsedUrl.getHost().split(".")[0];
        }
        else if (isIpEndpointStyle(parsedUrl)) {
            // IPv4/IPv6 address hosts... Example - http://192.0.0.10:10001/devstoreaccount1/
            // Single word domain without a [dot] in the endpoint... Example - http://localhost:10001/devstoreaccount1/
            // .getPath() -> /devstoreaccount1/
            accountName = parsedUrl.getPath().split("/")[1];
        }
        else {
            // Custom domain case: "https://customdomain.com/containername/blob".
            accountName = "";
        }
        return accountName;
    }
    catch (error) {
        throw new Error("Unable to extract accountName with provided information.");
    }
}
function isIpEndpointStyle(parsedUrl) {
    if (parsedUrl.getHost() === undefined) {
        return false;
    }
    const host = parsedUrl.getHost() + (parsedUrl.getPort() === undefined ? "" : ":" + parsedUrl.getPort());
    // Case 1: Ipv6, use a broad regex to find out candidates whose host contains two ':'.
    // Case 2: localhost(:port), use broad regex to match port part.
    // Case 3: Ipv4, use broad regex which just check if host contains Ipv4.
    // For valid host please refer to https://man7.org/linux/man-pages/man7/hostname.7.html.
    return /^.*:.*:.*$|^localhost(:[0-9]+)?$|^(\d|[1-9]\d|1\d\d|2[0-4]\d|25[0-5])(\.(\d|[1-9]\d|1\d\d|2[0-4]\d|25[0-5])){3}(:[0-9]+)?$/.test(host);
}

/**
 * StorageSharedKeyCredentialPolicy is a policy used to sign HTTP request with a shared key.
 */
class StorageSharedKeyCredentialPolicy extends CredentialPolicy {
    /**
     * Creates an instance of StorageSharedKeyCredentialPolicy.
     * @param nextPolicy -
     * @param options -
     * @param factory -
     */
    constructor(nextPolicy, options, factory) {
        super(nextPolicy, options);
        this.factory = factory;
    }
    /**
     * Signs request.
     *
     * @param request -
     */
    signRequest(request) {
        request.headers.set(HeaderConstants.X_MS_DATE, new Date().toUTCString());
        if (request.body && typeof request.body === "string" && request.body.length > 0) {
            request.headers.set(HeaderConstants.CONTENT_LENGTH, Buffer.byteLength(request.body));
        }
        const stringToSign = [
            request.method.toUpperCase(),
            this.getHeaderValueToSign(request, HeaderConstants.CONTENT_LANGUAGE),
            this.getHeaderValueToSign(request, HeaderConstants.CONTENT_ENCODING),
            this.getHeaderValueToSign(request, HeaderConstants.CONTENT_LENGTH),
            this.getHeaderValueToSign(request, HeaderConstants.CONTENT_MD5),
            this.getHeaderValueToSign(request, HeaderConstants.CONTENT_TYPE),
            this.getHeaderValueToSign(request, HeaderConstants.DATE),
            this.getHeaderValueToSign(request, HeaderConstants.IF_MODIFIED_SINCE),
            this.getHeaderValueToSign(request, HeaderConstants.IF_MATCH),
            this.getHeaderValueToSign(request, HeaderConstants.IF_NONE_MATCH),
            this.getHeaderValueToSign(request, HeaderConstants.IF_UNMODIFIED_SINCE),
            this.getHeaderValueToSign(request, HeaderConstants.RANGE)
        ].join("\n") +
            "\n" +
            this.getCanonicalizedHeadersString(request) +
            this.getCanonicalizedResourceString(request);
        const signature = this.factory.computeHMACSHA256(stringToSign);
        request.headers.set(HeaderConstants.AUTHORIZATION, `SharedKey ${this.factory.accountName}:${signature}`);
        // Workaround for node-fetch which will set content-type for dfs append data operations based on Patch
        if (typeof request.body !== "function" && !request.headers.get(HeaderConstants.CONTENT_TYPE)) {
            request.headers.set(HeaderConstants.CONTENT_TYPE, "");
        }
        // console.log(`[URL]:${request.url}`);
        // console.log(`[HEADERS]:${request.headers.toString()}`);
        // console.log(`[STRING TO SIGN]:${JSON.stringify(stringToSign)}`);
        // console.log(`[KEY]: ${request.headers.get(HeaderConstants.AUTHORIZATION)}`);
        return request;
    }
    /**
     * Retrieve header value according to shared key sign rules.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/authenticate-with-shared-key
     *
     * @param request -
     * @param headerName -
     */
    getHeaderValueToSign(request, headerName) {
        const value = request.headers.get(headerName);
        if (!value) {
            return "";
        }
        // When using version 2015-02-21 or later, if Content-Length is zero, then
        // set the Content-Length part of the StringToSign to an empty string.
        // https://docs.microsoft.com/en-us/rest/api/storageservices/authenticate-with-shared-key
        if (headerName === HeaderConstants.CONTENT_LENGTH && value === "0") {
            return "";
        }
        return value;
    }
    /**
     * To construct the CanonicalizedHeaders portion of the signature string, follow these steps:
     * 1. Retrieve all headers for the resource that begin with x-ms-, including the x-ms-date header.
     * 2. Convert each HTTP header name to lowercase.
     * 3. Sort the headers lexicographically by header name, in ascending order.
     *    Each header may appear only once in the string.
     * 4. Replace any linear whitespace in the header value with a single space.
     * 5. Trim any whitespace around the colon in the header.
     * 6. Finally, append a new-line character to each canonicalized header in the resulting list.
     *    Construct the CanonicalizedHeaders string by concatenating all headers in this list into a single string.
     *
     * @param request -
     */
    getCanonicalizedHeadersString(request) {
        let headersArray = request.headers.headersArray().filter((value) => {
            return value.name.toLowerCase().startsWith(HeaderConstants.PREFIX_FOR_STORAGE);
        });
        headersArray.sort((a, b) => {
            return a.name.toLowerCase().localeCompare(b.name.toLowerCase());
        });
        // Remove duplicate headers
        headersArray = headersArray.filter((value, index, array) => {
            if (index > 0 && value.name.toLowerCase() === array[index - 1].name.toLowerCase()) {
                return false;
            }
            return true;
        });
        let canonicalizedHeadersStringToSign = "";
        headersArray.forEach((header) => {
            canonicalizedHeadersStringToSign += `${header.name
                .toLowerCase()
                .trimRight()}:${header.value.trimLeft()}\n`;
        });
        return canonicalizedHeadersStringToSign;
    }
    /**
     * Retrieves the webResource canonicalized resource string.
     *
     * @param request -
     */
    getCanonicalizedResourceString(request) {
        const path = getURLPath(request.url) || "/";
        let canonicalizedResourceString = "";
        canonicalizedResourceString += `/${this.factory.accountName}${path}`;
        const queries = getURLQueries(request.url);
        const lowercaseQueries = {};
        if (queries) {
            const queryKeys = [];
            for (const key in queries) {
                if (Object.prototype.hasOwnProperty.call(queries, key)) {
                    const lowercaseKey = key.toLowerCase();
                    lowercaseQueries[lowercaseKey] = queries[key];
                    queryKeys.push(lowercaseKey);
                }
            }
            queryKeys.sort();
            for (const key of queryKeys) {
                canonicalizedResourceString += `\n${key}:${decodeURIComponent(lowercaseQueries[key])}`;
            }
        }
        return canonicalizedResourceString;
    }
}

// Copyright (c) Microsoft Corporation.
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * StorageSharedKeyCredential for account key authorization of Azure Storage service.
 */
class StorageSharedKeyCredential extends Credential {
    /**
     * Creates an instance of StorageSharedKeyCredential.
     * @param accountName -
     * @param accountKey -
     */
    constructor(accountName, accountKey) {
        super();
        this.accountName = accountName;
        this.accountKey = Buffer.from(accountKey, "base64");
    }
    /**
     * Creates a StorageSharedKeyCredentialPolicy object.
     *
     * @param nextPolicy -
     * @param options -
     */
    create(nextPolicy, options) {
        return new StorageSharedKeyCredentialPolicy(nextPolicy, options, this);
    }
    /**
     * Generates a hash signature for an HTTP request or for a SAS.
     *
     * @param stringToSign -
     */
    computeHMACSHA256(stringToSign) {
        return crypto.createHmac("sha256", this.accountKey)
            .update(stringToSign, "utf8")
            .digest("base64");
    }
}

// Copyright (c) Microsoft Corporation.
/**
 * Creates a span using the global tracer.
 * @internal
 */
const createSpan = coreTracing.createSpanFunction({
    packagePrefix: "Azure.Storage.DataLake",
    namespace: "Microsoft.Storage"
});
/**
 * @internal
 *
 * Adapt the tracing options from OperationOptions to what they need to be for
 * RequestOptionsBase (when we update to later OpenTelemetry versions this is now
 * two separate fields, not just one).
 */
function convertTracingToRequestOptionsBase(options) {
    var _a, _b;
    return {
        // By passing spanOptions if they exist at runtime, we're backwards compatible with @azure/core-tracing@preview.13 and earlier.
        spanOptions: (_a = options === null || options === void 0 ? void 0 : options.tracingOptions) === null || _a === void 0 ? void 0 : _a.spanOptions,
        tracingContext: (_b = options === null || options === void 0 ? void 0 : options.tracingOptions) === null || _b === void 0 ? void 0 : _b.tracingContext
    };
}

class DataLakeLeaseClient {
    constructor(client) {
        this.client = client;
    }
    get leaseId() {
        return this.client.leaseId;
    }
    get url() {
        return this.client.url;
    }
    async acquireLease(duration, options = {}) {
        options.conditions = options.conditions || {};
        const { span, updatedOptions } = createSpan("DataLakeLeaseClient-acquireLease", options);
        try {
            return await this.client.acquireLease(duration, updatedOptions);
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    async changeLease(proposedLeaseId, options = {}) {
        options.conditions = options.conditions || {};
        const { span, updatedOptions } = createSpan("DataLakeLeaseClient-changeLease", options);
        try {
            return await this.client.changeLease(proposedLeaseId, updatedOptions);
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    async releaseLease(options = {}) {
        options.conditions = options.conditions || {};
        const { span, updatedOptions } = createSpan("DataLakeLeaseClient-releaseLease", options);
        try {
            return await this.client.releaseLease(updatedOptions);
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    async renewLease(options = {}) {
        options.conditions = options.conditions || {};
        const { span, updatedOptions } = createSpan("DataLakeLeaseClient-renewLease", options);
        try {
            return await this.client.renewLease(updatedOptions);
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    async breakLease(breakPeriod, options = {}) {
        options.conditions = options.conditions || {};
        const { span, updatedOptions } = createSpan("DataLakeLeaseClient-renewLease", options);
        try {
            return await this.client.breakLease(breakPeriod, updatedOptions);
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
}

/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */
const FileSystemList = {
    serializedName: "FileSystemList",
    type: {
        name: "Composite",
        className: "FileSystemList",
        modelProperties: {
            filesystems: {
                serializedName: "filesystems",
                xmlName: "filesystems",
                xmlElementName: "FileSystem",
                type: {
                    name: "Sequence",
                    element: {
                        type: {
                            name: "Composite",
                            className: "FileSystem"
                        }
                    }
                }
            }
        }
    }
};
const FileSystem = {
    serializedName: "FileSystem",
    type: {
        name: "Composite",
        className: "FileSystem",
        modelProperties: {
            name: {
                serializedName: "name",
                xmlName: "name",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "lastModified",
                xmlName: "lastModified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            etag: {
                serializedName: "eTag",
                xmlName: "eTag",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const StorageError = {
    serializedName: "StorageError",
    type: {
        name: "Composite",
        className: "StorageError",
        modelProperties: {
            error: {
                serializedName: "error",
                xmlName: "error",
                type: {
                    name: "Composite",
                    className: "StorageErrorError"
                }
            },
            code: {
                serializedName: "Code",
                xmlName: "Code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const StorageErrorError = {
    serializedName: "StorageErrorError",
    type: {
        name: "Composite",
        className: "StorageErrorError",
        modelProperties: {
            code: {
                serializedName: "Code",
                xmlName: "Code",
                type: {
                    name: "String"
                }
            },
            message: {
                serializedName: "Message",
                xmlName: "Message",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathList = {
    serializedName: "PathList",
    type: {
        name: "Composite",
        className: "PathList",
        modelProperties: {
            paths: {
                serializedName: "paths",
                xmlName: "paths",
                xmlElementName: "Path",
                type: {
                    name: "Sequence",
                    element: {
                        type: {
                            name: "Composite",
                            className: "Path"
                        }
                    }
                }
            }
        }
    }
};
const Path = {
    serializedName: "Path",
    type: {
        name: "Composite",
        className: "Path",
        modelProperties: {
            name: {
                serializedName: "name",
                xmlName: "name",
                type: {
                    name: "String"
                }
            },
            isDirectory: {
                serializedName: "isDirectory",
                xmlName: "isDirectory",
                type: {
                    name: "Boolean"
                }
            },
            lastModified: {
                serializedName: "lastModified",
                xmlName: "lastModified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            etag: {
                serializedName: "eTag",
                xmlName: "eTag",
                type: {
                    name: "String"
                }
            },
            contentLength: {
                serializedName: "contentLength",
                xmlName: "contentLength",
                type: {
                    name: "Number"
                }
            },
            owner: {
                serializedName: "owner",
                xmlName: "owner",
                type: {
                    name: "String"
                }
            },
            group: {
                serializedName: "group",
                xmlName: "group",
                type: {
                    name: "String"
                }
            },
            permissions: {
                serializedName: "permissions",
                xmlName: "permissions",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ListBlobsHierarchySegmentResponse = {
    serializedName: "ListBlobsHierarchySegmentResponse",
    xmlName: "EnumerationResults",
    type: {
        name: "Composite",
        className: "ListBlobsHierarchySegmentResponse",
        modelProperties: {
            serviceEndpoint: {
                serializedName: "ServiceEndpoint",
                required: true,
                xmlName: "ServiceEndpoint",
                xmlIsAttribute: true,
                type: {
                    name: "String"
                }
            },
            containerName: {
                serializedName: "ContainerName",
                required: true,
                xmlName: "ContainerName",
                xmlIsAttribute: true,
                type: {
                    name: "String"
                }
            },
            prefix: {
                serializedName: "Prefix",
                xmlName: "Prefix",
                type: {
                    name: "String"
                }
            },
            marker: {
                serializedName: "Marker",
                xmlName: "Marker",
                type: {
                    name: "String"
                }
            },
            maxResults: {
                serializedName: "MaxResults",
                xmlName: "MaxResults",
                type: {
                    name: "Number"
                }
            },
            delimiter: {
                serializedName: "Delimiter",
                xmlName: "Delimiter",
                type: {
                    name: "String"
                }
            },
            segment: {
                serializedName: "Segment",
                xmlName: "Blobs",
                type: {
                    name: "Composite",
                    className: "BlobHierarchyListSegment"
                }
            },
            nextMarker: {
                serializedName: "NextMarker",
                xmlName: "NextMarker",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobHierarchyListSegment = {
    serializedName: "BlobHierarchyListSegment",
    xmlName: "Blobs",
    type: {
        name: "Composite",
        className: "BlobHierarchyListSegment",
        modelProperties: {
            blobPrefixes: {
                serializedName: "BlobPrefixes",
                xmlName: "BlobPrefixes",
                xmlElementName: "BlobPrefix",
                type: {
                    name: "Sequence",
                    element: {
                        type: {
                            name: "Composite",
                            className: "BlobPrefix"
                        }
                    }
                }
            },
            blobItems: {
                serializedName: "BlobItems",
                required: true,
                xmlName: "BlobItems",
                xmlElementName: "Blob",
                type: {
                    name: "Sequence",
                    element: {
                        type: {
                            name: "Composite",
                            className: "BlobItemModel"
                        }
                    }
                }
            }
        }
    }
};
const BlobPrefix = {
    serializedName: "BlobPrefix",
    type: {
        name: "Composite",
        className: "BlobPrefix",
        modelProperties: {
            name: {
                serializedName: "Name",
                required: true,
                xmlName: "Name",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobItemModel = {
    serializedName: "BlobItemModel",
    xmlName: "Blob",
    type: {
        name: "Composite",
        className: "BlobItemModel",
        modelProperties: {
            name: {
                serializedName: "Name",
                required: true,
                xmlName: "Name",
                type: {
                    name: "String"
                }
            },
            deleted: {
                serializedName: "Deleted",
                required: true,
                xmlName: "Deleted",
                type: {
                    name: "Boolean"
                }
            },
            snapshot: {
                serializedName: "Snapshot",
                required: true,
                xmlName: "Snapshot",
                type: {
                    name: "String"
                }
            },
            versionId: {
                serializedName: "VersionId",
                xmlName: "VersionId",
                type: {
                    name: "String"
                }
            },
            isCurrentVersion: {
                serializedName: "IsCurrentVersion",
                xmlName: "IsCurrentVersion",
                type: {
                    name: "Boolean"
                }
            },
            properties: {
                serializedName: "Properties",
                xmlName: "Properties",
                type: {
                    name: "Composite",
                    className: "BlobPropertiesModel"
                }
            },
            deletionId: {
                serializedName: "DeletionId",
                xmlName: "DeletionId",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const BlobPropertiesModel = {
    serializedName: "BlobPropertiesModel",
    xmlName: "Properties",
    type: {
        name: "Composite",
        className: "BlobPropertiesModel",
        modelProperties: {
            creationTime: {
                serializedName: "Creation-Time",
                xmlName: "Creation-Time",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            lastModified: {
                serializedName: "Last-Modified",
                required: true,
                xmlName: "Last-Modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            etag: {
                serializedName: "Etag",
                required: true,
                xmlName: "Etag",
                type: {
                    name: "String"
                }
            },
            contentLength: {
                serializedName: "Content-Length",
                xmlName: "Content-Length",
                type: {
                    name: "Number"
                }
            },
            contentType: {
                serializedName: "Content-Type",
                xmlName: "Content-Type",
                type: {
                    name: "String"
                }
            },
            contentEncoding: {
                serializedName: "Content-Encoding",
                xmlName: "Content-Encoding",
                type: {
                    name: "String"
                }
            },
            contentLanguage: {
                serializedName: "Content-Language",
                xmlName: "Content-Language",
                type: {
                    name: "String"
                }
            },
            contentMD5: {
                serializedName: "Content-MD5",
                xmlName: "Content-MD5",
                type: {
                    name: "ByteArray"
                }
            },
            contentDisposition: {
                serializedName: "Content-Disposition",
                xmlName: "Content-Disposition",
                type: {
                    name: "String"
                }
            },
            cacheControl: {
                serializedName: "Cache-Control",
                xmlName: "Cache-Control",
                type: {
                    name: "String"
                }
            },
            blobSequenceNumber: {
                serializedName: "x-ms-blob-sequence-number",
                xmlName: "x-ms-blob-sequence-number",
                type: {
                    name: "Number"
                }
            },
            copyId: {
                serializedName: "CopyId",
                xmlName: "CopyId",
                type: {
                    name: "String"
                }
            },
            copySource: {
                serializedName: "CopySource",
                xmlName: "CopySource",
                type: {
                    name: "String"
                }
            },
            copyProgress: {
                serializedName: "CopyProgress",
                xmlName: "CopyProgress",
                type: {
                    name: "String"
                }
            },
            copyCompletionTime: {
                serializedName: "CopyCompletionTime",
                xmlName: "CopyCompletionTime",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            copyStatusDescription: {
                serializedName: "CopyStatusDescription",
                xmlName: "CopyStatusDescription",
                type: {
                    name: "String"
                }
            },
            serverEncrypted: {
                serializedName: "ServerEncrypted",
                xmlName: "ServerEncrypted",
                type: {
                    name: "Boolean"
                }
            },
            incrementalCopy: {
                serializedName: "IncrementalCopy",
                xmlName: "IncrementalCopy",
                type: {
                    name: "Boolean"
                }
            },
            destinationSnapshot: {
                serializedName: "DestinationSnapshot",
                xmlName: "DestinationSnapshot",
                type: {
                    name: "String"
                }
            },
            deletedTime: {
                serializedName: "DeletedTime",
                xmlName: "DeletedTime",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            remainingRetentionDays: {
                serializedName: "RemainingRetentionDays",
                xmlName: "RemainingRetentionDays",
                type: {
                    name: "Number"
                }
            },
            accessTierInferred: {
                serializedName: "AccessTierInferred",
                xmlName: "AccessTierInferred",
                type: {
                    name: "Boolean"
                }
            },
            customerProvidedKeySha256: {
                serializedName: "CustomerProvidedKeySha256",
                xmlName: "CustomerProvidedKeySha256",
                type: {
                    name: "String"
                }
            },
            encryptionScope: {
                serializedName: "EncryptionScope",
                xmlName: "EncryptionScope",
                type: {
                    name: "String"
                }
            },
            accessTierChangeTime: {
                serializedName: "AccessTierChangeTime",
                xmlName: "AccessTierChangeTime",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            tagCount: {
                serializedName: "TagCount",
                xmlName: "TagCount",
                type: {
                    name: "Number"
                }
            },
            expiresOn: {
                serializedName: "Expiry-Time",
                xmlName: "Expiry-Time",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            sealed: {
                serializedName: "Sealed",
                xmlName: "Sealed",
                type: {
                    name: "Boolean"
                }
            },
            lastAccessedOn: {
                serializedName: "LastAccessTime",
                xmlName: "LastAccessTime",
                type: {
                    name: "DateTimeRfc1123"
                }
            }
        }
    }
};
const SetAccessControlRecursiveResponse = {
    serializedName: "SetAccessControlRecursiveResponse",
    type: {
        name: "Composite",
        className: "SetAccessControlRecursiveResponse",
        modelProperties: {
            directoriesSuccessful: {
                serializedName: "directoriesSuccessful",
                xmlName: "directoriesSuccessful",
                type: {
                    name: "Number"
                }
            },
            filesSuccessful: {
                serializedName: "filesSuccessful",
                xmlName: "filesSuccessful",
                type: {
                    name: "Number"
                }
            },
            failureCount: {
                serializedName: "failureCount",
                xmlName: "failureCount",
                type: {
                    name: "Number"
                }
            },
            failedEntries: {
                serializedName: "failedEntries",
                xmlName: "failedEntries",
                xmlElementName: "AclFailedEntry",
                type: {
                    name: "Sequence",
                    element: {
                        type: {
                            name: "Composite",
                            className: "AclFailedEntry"
                        }
                    }
                }
            }
        }
    }
};
const AclFailedEntry = {
    serializedName: "AclFailedEntry",
    type: {
        name: "Composite",
        className: "AclFailedEntry",
        modelProperties: {
            name: {
                serializedName: "name",
                xmlName: "name",
                type: {
                    name: "String"
                }
            },
            type: {
                serializedName: "type",
                xmlName: "type",
                type: {
                    name: "String"
                }
            },
            errorMessage: {
                serializedName: "errorMessage",
                xmlName: "errorMessage",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ServiceListFileSystemsHeaders = {
    serializedName: "Service_listFileSystemsHeaders",
    type: {
        name: "Composite",
        className: "ServiceListFileSystemsHeaders",
        modelProperties: {
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            requestId: {
                constraints: {
                    Pattern: new RegExp("^[{(]?[0-9a-f]{8}[-]?([0-9a-f]{4}[-]?){3}[0-9a-f]{12}[)}]?$")
                },
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            continuation: {
                serializedName: "x-ms-continuation",
                xmlName: "x-ms-continuation",
                type: {
                    name: "String"
                }
            },
            contentType: {
                serializedName: "content-type",
                xmlName: "content-type",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const ServiceListFileSystemsExceptionHeaders = {
    serializedName: "Service_listFileSystemsExceptionHeaders",
    type: {
        name: "Composite",
        className: "ServiceListFileSystemsExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const FileSystemCreateHeaders = {
    serializedName: "FileSystem_createHeaders",
    type: {
        name: "Composite",
        className: "FileSystemCreateHeaders",
        modelProperties: {
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            clientRequestId: {
                constraints: {
                    Pattern: new RegExp("^[{(]?[0-9a-f]{8}[-]?([0-9a-f]{4}[-]?){3}[0-9a-f]{12}[)}]?$")
                },
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            namespaceEnabled: {
                serializedName: "x-ms-namespace-enabled",
                xmlName: "x-ms-namespace-enabled",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const FileSystemCreateExceptionHeaders = {
    serializedName: "FileSystem_createExceptionHeaders",
    type: {
        name: "Composite",
        className: "FileSystemCreateExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const FileSystemSetPropertiesHeaders = {
    serializedName: "FileSystem_setPropertiesHeaders",
    type: {
        name: "Composite",
        className: "FileSystemSetPropertiesHeaders",
        modelProperties: {
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            requestId: {
                constraints: {
                    Pattern: new RegExp("^[{(]?[0-9a-f]{8}[-]?([0-9a-f]{4}[-]?){3}[0-9a-f]{12}[)}]?$")
                },
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const FileSystemSetPropertiesExceptionHeaders = {
    serializedName: "FileSystem_setPropertiesExceptionHeaders",
    type: {
        name: "Composite",
        className: "FileSystemSetPropertiesExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const FileSystemGetPropertiesHeaders = {
    serializedName: "FileSystem_getPropertiesHeaders",
    type: {
        name: "Composite",
        className: "FileSystemGetPropertiesHeaders",
        modelProperties: {
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            requestId: {
                constraints: {
                    Pattern: new RegExp("^[{(]?[0-9a-f]{8}[-]?([0-9a-f]{4}[-]?){3}[0-9a-f]{12}[)}]?$")
                },
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            properties: {
                serializedName: "x-ms-properties",
                xmlName: "x-ms-properties",
                type: {
                    name: "String"
                }
            },
            namespaceEnabled: {
                serializedName: "x-ms-namespace-enabled",
                xmlName: "x-ms-namespace-enabled",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const FileSystemGetPropertiesExceptionHeaders = {
    serializedName: "FileSystem_getPropertiesExceptionHeaders",
    type: {
        name: "Composite",
        className: "FileSystemGetPropertiesExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const FileSystemDeleteHeaders = {
    serializedName: "FileSystem_deleteHeaders",
    type: {
        name: "Composite",
        className: "FileSystemDeleteHeaders",
        modelProperties: {
            requestId: {
                constraints: {
                    Pattern: new RegExp("^[{(]?[0-9a-f]{8}[-]?([0-9a-f]{4}[-]?){3}[0-9a-f]{12}[)}]?$")
                },
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            }
        }
    }
};
const FileSystemDeleteExceptionHeaders = {
    serializedName: "FileSystem_deleteExceptionHeaders",
    type: {
        name: "Composite",
        className: "FileSystemDeleteExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const FileSystemListPathsHeaders = {
    serializedName: "FileSystem_listPathsHeaders",
    type: {
        name: "Composite",
        className: "FileSystemListPathsHeaders",
        modelProperties: {
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            requestId: {
                constraints: {
                    Pattern: new RegExp("^[{(]?[0-9a-f]{8}[-]?([0-9a-f]{4}[-]?){3}[0-9a-f]{12}[)}]?$")
                },
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            continuation: {
                serializedName: "x-ms-continuation",
                xmlName: "x-ms-continuation",
                type: {
                    name: "String"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const FileSystemListPathsExceptionHeaders = {
    serializedName: "FileSystem_listPathsExceptionHeaders",
    type: {
        name: "Composite",
        className: "FileSystemListPathsExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const FileSystemListBlobHierarchySegmentHeaders = {
    serializedName: "FileSystem_listBlobHierarchySegmentHeaders",
    type: {
        name: "Composite",
        className: "FileSystemListBlobHierarchySegmentHeaders",
        modelProperties: {
            contentType: {
                serializedName: "content-type",
                xmlName: "content-type",
                type: {
                    name: "String"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const FileSystemListBlobHierarchySegmentExceptionHeaders = {
    serializedName: "FileSystem_listBlobHierarchySegmentExceptionHeaders",
    type: {
        name: "Composite",
        className: "FileSystemListBlobHierarchySegmentExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathCreateHeaders = {
    serializedName: "Path_createHeaders",
    type: {
        name: "Composite",
        className: "PathCreateHeaders",
        modelProperties: {
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            requestId: {
                constraints: {
                    Pattern: new RegExp("^[{(]?[0-9a-f]{8}[-]?([0-9a-f]{4}[-]?){3}[0-9a-f]{12}[)}]?$")
                },
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            continuation: {
                serializedName: "x-ms-continuation",
                xmlName: "x-ms-continuation",
                type: {
                    name: "String"
                }
            },
            contentLength: {
                serializedName: "content-length",
                xmlName: "content-length",
                type: {
                    name: "Number"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathCreateExceptionHeaders = {
    serializedName: "Path_createExceptionHeaders",
    type: {
        name: "Composite",
        className: "PathCreateExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathUpdateHeaders = {
    serializedName: "Path_updateHeaders",
    type: {
        name: "Composite",
        className: "PathUpdateHeaders",
        modelProperties: {
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            acceptRanges: {
                serializedName: "accept-ranges",
                xmlName: "accept-ranges",
                type: {
                    name: "String"
                }
            },
            cacheControl: {
                serializedName: "cache-control",
                xmlName: "cache-control",
                type: {
                    name: "String"
                }
            },
            contentDisposition: {
                serializedName: "content-disposition",
                xmlName: "content-disposition",
                type: {
                    name: "String"
                }
            },
            contentEncoding: {
                serializedName: "content-encoding",
                xmlName: "content-encoding",
                type: {
                    name: "String"
                }
            },
            contentLanguage: {
                serializedName: "content-language",
                xmlName: "content-language",
                type: {
                    name: "String"
                }
            },
            contentLength: {
                serializedName: "content-length",
                xmlName: "content-length",
                type: {
                    name: "Number"
                }
            },
            contentRange: {
                serializedName: "content-range",
                xmlName: "content-range",
                type: {
                    name: "String"
                }
            },
            contentType: {
                serializedName: "content-type",
                xmlName: "content-type",
                type: {
                    name: "String"
                }
            },
            contentMD5: {
                serializedName: "content-md5",
                xmlName: "content-md5",
                type: {
                    name: "String"
                }
            },
            properties: {
                serializedName: "x-ms-properties",
                xmlName: "x-ms-properties",
                type: {
                    name: "String"
                }
            },
            xMsContinuation: {
                serializedName: "x-ms-continuation",
                xmlName: "x-ms-continuation",
                type: {
                    name: "String"
                }
            },
            requestId: {
                constraints: {
                    Pattern: new RegExp("^[{(]?[0-9a-f]{8}[-]?([0-9a-f]{4}[-]?){3}[0-9a-f]{12}[)}]?$")
                },
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathUpdateExceptionHeaders = {
    serializedName: "Path_updateExceptionHeaders",
    type: {
        name: "Composite",
        className: "PathUpdateExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathLeaseHeaders = {
    serializedName: "Path_leaseHeaders",
    type: {
        name: "Composite",
        className: "PathLeaseHeaders",
        modelProperties: {
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            requestId: {
                constraints: {
                    Pattern: new RegExp("^[{(]?[0-9a-f]{8}[-]?([0-9a-f]{4}[-]?){3}[0-9a-f]{12}[)}]?$")
                },
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            leaseId: {
                constraints: {
                    Pattern: new RegExp("^[{(]?[0-9a-f]{8}[-]?([0-9a-f]{4}[-]?){3}[0-9a-f]{12}[)}]?$")
                },
                serializedName: "x-ms-lease-id",
                xmlName: "x-ms-lease-id",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathLeaseExceptionHeaders = {
    serializedName: "Path_leaseExceptionHeaders",
    type: {
        name: "Composite",
        className: "PathLeaseExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathReadHeaders = {
    serializedName: "Path_readHeaders",
    type: {
        name: "Composite",
        className: "PathReadHeaders",
        modelProperties: {
            acceptRanges: {
                serializedName: "accept-ranges",
                xmlName: "accept-ranges",
                type: {
                    name: "String"
                }
            },
            cacheControl: {
                serializedName: "cache-control",
                xmlName: "cache-control",
                type: {
                    name: "String"
                }
            },
            contentDisposition: {
                serializedName: "content-disposition",
                xmlName: "content-disposition",
                type: {
                    name: "String"
                }
            },
            contentEncoding: {
                serializedName: "content-encoding",
                xmlName: "content-encoding",
                type: {
                    name: "String"
                }
            },
            contentLanguage: {
                serializedName: "content-language",
                xmlName: "content-language",
                type: {
                    name: "String"
                }
            },
            contentLength: {
                serializedName: "content-length",
                xmlName: "content-length",
                type: {
                    name: "Number"
                }
            },
            contentRange: {
                serializedName: "content-range",
                xmlName: "content-range",
                type: {
                    name: "String"
                }
            },
            contentType: {
                serializedName: "content-type",
                xmlName: "content-type",
                type: {
                    name: "String"
                }
            },
            contentMD5: {
                serializedName: "content-md5",
                xmlName: "content-md5",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            requestId: {
                constraints: {
                    Pattern: new RegExp("^[{(]?[0-9a-f]{8}[-]?([0-9a-f]{4}[-]?){3}[0-9a-f]{12}[)}]?$")
                },
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            resourceType: {
                serializedName: "x-ms-resource-type",
                xmlName: "x-ms-resource-type",
                type: {
                    name: "String"
                }
            },
            properties: {
                serializedName: "x-ms-properties",
                xmlName: "x-ms-properties",
                type: {
                    name: "String"
                }
            },
            leaseDuration: {
                serializedName: "x-ms-lease-duration",
                xmlName: "x-ms-lease-duration",
                type: {
                    name: "String"
                }
            },
            leaseState: {
                serializedName: "x-ms-lease-state",
                xmlName: "x-ms-lease-state",
                type: {
                    name: "String"
                }
            },
            leaseStatus: {
                serializedName: "x-ms-lease-status",
                xmlName: "x-ms-lease-status",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathReadExceptionHeaders = {
    serializedName: "Path_readExceptionHeaders",
    type: {
        name: "Composite",
        className: "PathReadExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathGetPropertiesHeaders = {
    serializedName: "Path_getPropertiesHeaders",
    type: {
        name: "Composite",
        className: "PathGetPropertiesHeaders",
        modelProperties: {
            acceptRanges: {
                serializedName: "accept-ranges",
                xmlName: "accept-ranges",
                type: {
                    name: "String"
                }
            },
            cacheControl: {
                serializedName: "cache-control",
                xmlName: "cache-control",
                type: {
                    name: "String"
                }
            },
            contentDisposition: {
                serializedName: "content-disposition",
                xmlName: "content-disposition",
                type: {
                    name: "String"
                }
            },
            contentEncoding: {
                serializedName: "content-encoding",
                xmlName: "content-encoding",
                type: {
                    name: "String"
                }
            },
            contentLanguage: {
                serializedName: "content-language",
                xmlName: "content-language",
                type: {
                    name: "String"
                }
            },
            contentLength: {
                serializedName: "content-length",
                xmlName: "content-length",
                type: {
                    name: "Number"
                }
            },
            contentRange: {
                serializedName: "content-range",
                xmlName: "content-range",
                type: {
                    name: "String"
                }
            },
            contentType: {
                serializedName: "content-type",
                xmlName: "content-type",
                type: {
                    name: "String"
                }
            },
            contentMD5: {
                serializedName: "content-md5",
                xmlName: "content-md5",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            requestId: {
                constraints: {
                    Pattern: new RegExp("^[{(]?[0-9a-f]{8}[-]?([0-9a-f]{4}[-]?){3}[0-9a-f]{12}[)}]?$")
                },
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            resourceType: {
                serializedName: "x-ms-resource-type",
                xmlName: "x-ms-resource-type",
                type: {
                    name: "String"
                }
            },
            properties: {
                serializedName: "x-ms-properties",
                xmlName: "x-ms-properties",
                type: {
                    name: "String"
                }
            },
            owner: {
                serializedName: "x-ms-owner",
                xmlName: "x-ms-owner",
                type: {
                    name: "String"
                }
            },
            group: {
                serializedName: "x-ms-group",
                xmlName: "x-ms-group",
                type: {
                    name: "String"
                }
            },
            permissions: {
                serializedName: "x-ms-permissions",
                xmlName: "x-ms-permissions",
                type: {
                    name: "String"
                }
            },
            acl: {
                serializedName: "x-ms-acl",
                xmlName: "x-ms-acl",
                type: {
                    name: "String"
                }
            },
            leaseDuration: {
                serializedName: "x-ms-lease-duration",
                xmlName: "x-ms-lease-duration",
                type: {
                    name: "String"
                }
            },
            leaseState: {
                serializedName: "x-ms-lease-state",
                xmlName: "x-ms-lease-state",
                type: {
                    name: "String"
                }
            },
            leaseStatus: {
                serializedName: "x-ms-lease-status",
                xmlName: "x-ms-lease-status",
                type: {
                    name: "String"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathGetPropertiesExceptionHeaders = {
    serializedName: "Path_getPropertiesExceptionHeaders",
    type: {
        name: "Composite",
        className: "PathGetPropertiesExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathDeleteHeaders = {
    serializedName: "Path_deleteHeaders",
    type: {
        name: "Composite",
        className: "PathDeleteHeaders",
        modelProperties: {
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            requestId: {
                constraints: {
                    Pattern: new RegExp("^[{(]?[0-9a-f]{8}[-]?([0-9a-f]{4}[-]?){3}[0-9a-f]{12}[)}]?$")
                },
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            continuation: {
                serializedName: "x-ms-continuation",
                xmlName: "x-ms-continuation",
                type: {
                    name: "String"
                }
            },
            deletionId: {
                serializedName: "x-ms-deletion-id",
                xmlName: "x-ms-deletion-id",
                type: {
                    name: "String"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathDeleteExceptionHeaders = {
    serializedName: "Path_deleteExceptionHeaders",
    type: {
        name: "Composite",
        className: "PathDeleteExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathSetAccessControlHeaders = {
    serializedName: "Path_setAccessControlHeaders",
    type: {
        name: "Composite",
        className: "PathSetAccessControlHeaders",
        modelProperties: {
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathSetAccessControlExceptionHeaders = {
    serializedName: "Path_setAccessControlExceptionHeaders",
    type: {
        name: "Composite",
        className: "PathSetAccessControlExceptionHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathSetAccessControlRecursiveHeaders = {
    serializedName: "Path_setAccessControlRecursiveHeaders",
    type: {
        name: "Composite",
        className: "PathSetAccessControlRecursiveHeaders",
        modelProperties: {
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            continuation: {
                serializedName: "x-ms-continuation",
                xmlName: "x-ms-continuation",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathSetAccessControlRecursiveExceptionHeaders = {
    serializedName: "Path_setAccessControlRecursiveExceptionHeaders",
    type: {
        name: "Composite",
        className: "PathSetAccessControlRecursiveExceptionHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathFlushDataHeaders = {
    serializedName: "Path_flushDataHeaders",
    type: {
        name: "Composite",
        className: "PathFlushDataHeaders",
        modelProperties: {
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            contentLength: {
                serializedName: "content-length",
                xmlName: "content-length",
                type: {
                    name: "Number"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                constraints: {
                    Pattern: new RegExp("^[{(]?[0-9a-f]{8}[-]?([0-9a-f]{4}[-]?){3}[0-9a-f]{12}[)}]?$")
                },
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathFlushDataExceptionHeaders = {
    serializedName: "Path_flushDataExceptionHeaders",
    type: {
        name: "Composite",
        className: "PathFlushDataExceptionHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathAppendDataHeaders = {
    serializedName: "Path_appendDataHeaders",
    type: {
        name: "Composite",
        className: "PathAppendDataHeaders",
        modelProperties: {
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            contentMD5: {
                serializedName: "content-md5",
                xmlName: "content-md5",
                type: {
                    name: "ByteArray"
                }
            },
            xMsContentCrc64: {
                serializedName: "x-ms-content-crc64",
                xmlName: "x-ms-content-crc64",
                type: {
                    name: "ByteArray"
                }
            },
            isServerEncrypted: {
                serializedName: "x-ms-request-server-encrypted",
                xmlName: "x-ms-request-server-encrypted",
                type: {
                    name: "Boolean"
                }
            }
        }
    }
};
const PathAppendDataExceptionHeaders = {
    serializedName: "Path_appendDataExceptionHeaders",
    type: {
        name: "Composite",
        className: "PathAppendDataExceptionHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathSetExpiryHeaders = {
    serializedName: "Path_setExpiryHeaders",
    type: {
        name: "Composite",
        className: "PathSetExpiryHeaders",
        modelProperties: {
            etag: {
                serializedName: "etag",
                xmlName: "etag",
                type: {
                    name: "String"
                }
            },
            lastModified: {
                serializedName: "last-modified",
                xmlName: "last-modified",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            },
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathSetExpiryExceptionHeaders = {
    serializedName: "Path_setExpiryExceptionHeaders",
    type: {
        name: "Composite",
        className: "PathSetExpiryExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};
const PathUndeleteHeaders = {
    serializedName: "Path_undeleteHeaders",
    type: {
        name: "Composite",
        className: "PathUndeleteHeaders",
        modelProperties: {
            clientRequestId: {
                serializedName: "x-ms-client-request-id",
                xmlName: "x-ms-client-request-id",
                type: {
                    name: "String"
                }
            },
            requestId: {
                serializedName: "x-ms-request-id",
                xmlName: "x-ms-request-id",
                type: {
                    name: "String"
                }
            },
            resourceType: {
                serializedName: "x-ms-resource-type",
                xmlName: "x-ms-resource-type",
                type: {
                    name: "String"
                }
            },
            version: {
                serializedName: "x-ms-version",
                xmlName: "x-ms-version",
                type: {
                    name: "String"
                }
            },
            date: {
                serializedName: "date",
                xmlName: "date",
                type: {
                    name: "DateTimeRfc1123"
                }
            }
        }
    }
};
const PathUndeleteExceptionHeaders = {
    serializedName: "Path_undeleteExceptionHeaders",
    type: {
        name: "Composite",
        className: "PathUndeleteExceptionHeaders",
        modelProperties: {
            errorCode: {
                serializedName: "x-ms-error-code",
                xmlName: "x-ms-error-code",
                type: {
                    name: "String"
                }
            }
        }
    }
};

var Mappers = /*#__PURE__*/Object.freeze({
    __proto__: null,
    FileSystemList: FileSystemList,
    FileSystem: FileSystem,
    StorageError: StorageError,
    StorageErrorError: StorageErrorError,
    PathList: PathList,
    Path: Path,
    ListBlobsHierarchySegmentResponse: ListBlobsHierarchySegmentResponse,
    BlobHierarchyListSegment: BlobHierarchyListSegment,
    BlobPrefix: BlobPrefix,
    BlobItemModel: BlobItemModel,
    BlobPropertiesModel: BlobPropertiesModel,
    SetAccessControlRecursiveResponse: SetAccessControlRecursiveResponse,
    AclFailedEntry: AclFailedEntry,
    ServiceListFileSystemsHeaders: ServiceListFileSystemsHeaders,
    ServiceListFileSystemsExceptionHeaders: ServiceListFileSystemsExceptionHeaders,
    FileSystemCreateHeaders: FileSystemCreateHeaders,
    FileSystemCreateExceptionHeaders: FileSystemCreateExceptionHeaders,
    FileSystemSetPropertiesHeaders: FileSystemSetPropertiesHeaders,
    FileSystemSetPropertiesExceptionHeaders: FileSystemSetPropertiesExceptionHeaders,
    FileSystemGetPropertiesHeaders: FileSystemGetPropertiesHeaders,
    FileSystemGetPropertiesExceptionHeaders: FileSystemGetPropertiesExceptionHeaders,
    FileSystemDeleteHeaders: FileSystemDeleteHeaders,
    FileSystemDeleteExceptionHeaders: FileSystemDeleteExceptionHeaders,
    FileSystemListPathsHeaders: FileSystemListPathsHeaders,
    FileSystemListPathsExceptionHeaders: FileSystemListPathsExceptionHeaders,
    FileSystemListBlobHierarchySegmentHeaders: FileSystemListBlobHierarchySegmentHeaders,
    FileSystemListBlobHierarchySegmentExceptionHeaders: FileSystemListBlobHierarchySegmentExceptionHeaders,
    PathCreateHeaders: PathCreateHeaders,
    PathCreateExceptionHeaders: PathCreateExceptionHeaders,
    PathUpdateHeaders: PathUpdateHeaders,
    PathUpdateExceptionHeaders: PathUpdateExceptionHeaders,
    PathLeaseHeaders: PathLeaseHeaders,
    PathLeaseExceptionHeaders: PathLeaseExceptionHeaders,
    PathReadHeaders: PathReadHeaders,
    PathReadExceptionHeaders: PathReadExceptionHeaders,
    PathGetPropertiesHeaders: PathGetPropertiesHeaders,
    PathGetPropertiesExceptionHeaders: PathGetPropertiesExceptionHeaders,
    PathDeleteHeaders: PathDeleteHeaders,
    PathDeleteExceptionHeaders: PathDeleteExceptionHeaders,
    PathSetAccessControlHeaders: PathSetAccessControlHeaders,
    PathSetAccessControlExceptionHeaders: PathSetAccessControlExceptionHeaders,
    PathSetAccessControlRecursiveHeaders: PathSetAccessControlRecursiveHeaders,
    PathSetAccessControlRecursiveExceptionHeaders: PathSetAccessControlRecursiveExceptionHeaders,
    PathFlushDataHeaders: PathFlushDataHeaders,
    PathFlushDataExceptionHeaders: PathFlushDataExceptionHeaders,
    PathAppendDataHeaders: PathAppendDataHeaders,
    PathAppendDataExceptionHeaders: PathAppendDataExceptionHeaders,
    PathSetExpiryHeaders: PathSetExpiryHeaders,
    PathSetExpiryExceptionHeaders: PathSetExpiryExceptionHeaders,
    PathUndeleteHeaders: PathUndeleteHeaders,
    PathUndeleteExceptionHeaders: PathUndeleteExceptionHeaders
});

/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */
const accept = {
    parameterPath: "accept",
    mapper: {
        defaultValue: "application/json",
        isConstant: true,
        serializedName: "Accept",
        type: {
            name: "String"
        }
    }
};
const url = {
    parameterPath: "url",
    mapper: {
        serializedName: "url",
        required: true,
        xmlName: "url",
        type: {
            name: "String"
        }
    },
    skipEncoding: true
};
const prefix = {
    parameterPath: ["options", "prefix"],
    mapper: {
        serializedName: "prefix",
        xmlName: "prefix",
        type: {
            name: "String"
        }
    }
};
const continuation = {
    parameterPath: ["options", "continuation"],
    mapper: {
        serializedName: "continuation",
        xmlName: "continuation",
        type: {
            name: "String"
        }
    }
};
const maxResults = {
    parameterPath: ["options", "maxResults"],
    mapper: {
        constraints: {
            InclusiveMinimum: 1
        },
        serializedName: "maxResults",
        xmlName: "maxResults",
        type: {
            name: "Number"
        }
    }
};
const requestId = {
    parameterPath: ["options", "requestId"],
    mapper: {
        serializedName: "x-ms-client-request-id",
        xmlName: "x-ms-client-request-id",
        type: {
            name: "String"
        }
    }
};
const timeout = {
    parameterPath: ["options", "timeout"],
    mapper: {
        constraints: {
            InclusiveMinimum: 0
        },
        serializedName: "timeout",
        xmlName: "timeout",
        type: {
            name: "Number"
        }
    }
};
const version = {
    parameterPath: "version",
    mapper: {
        defaultValue: "2020-10-02",
        isConstant: true,
        serializedName: "x-ms-version",
        type: {
            name: "String"
        }
    }
};
const resource1 = {
    parameterPath: "resource",
    mapper: {
        defaultValue: "filesystem",
        isConstant: true,
        serializedName: "resource",
        type: {
            name: "String"
        }
    }
};
const properties = {
    parameterPath: ["options", "properties"],
    mapper: {
        serializedName: "x-ms-properties",
        xmlName: "x-ms-properties",
        type: {
            name: "String"
        }
    }
};
const ifModifiedSince = {
    parameterPath: ["options", "modifiedAccessConditions", "ifModifiedSince"],
    mapper: {
        serializedName: "If-Modified-Since",
        xmlName: "If-Modified-Since",
        type: {
            name: "DateTimeRfc1123"
        }
    }
};
const ifUnmodifiedSince = {
    parameterPath: ["options", "modifiedAccessConditions", "ifUnmodifiedSince"],
    mapper: {
        serializedName: "If-Unmodified-Since",
        xmlName: "If-Unmodified-Since",
        type: {
            name: "DateTimeRfc1123"
        }
    }
};
const path = {
    parameterPath: ["options", "path"],
    mapper: {
        serializedName: "directory",
        xmlName: "directory",
        type: {
            name: "String"
        }
    }
};
const recursive = {
    parameterPath: "recursive",
    mapper: {
        serializedName: "recursive",
        required: true,
        xmlName: "recursive",
        type: {
            name: "Boolean"
        }
    }
};
const upn = {
    parameterPath: ["options", "upn"],
    mapper: {
        serializedName: "upn",
        xmlName: "upn",
        type: {
            name: "Boolean"
        }
    }
};
const accept1 = {
    parameterPath: "accept",
    mapper: {
        defaultValue: "application/xml",
        isConstant: true,
        serializedName: "Accept",
        type: {
            name: "String"
        }
    }
};
const restype = {
    parameterPath: "restype",
    mapper: {
        defaultValue: "container",
        isConstant: true,
        serializedName: "restype",
        type: {
            name: "String"
        }
    }
};
const comp = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "list",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const delimiter = {
    parameterPath: ["options", "delimiter"],
    mapper: {
        serializedName: "delimiter",
        xmlName: "delimiter",
        type: {
            name: "String"
        }
    }
};
const marker = {
    parameterPath: ["options", "marker"],
    mapper: {
        serializedName: "marker",
        xmlName: "marker",
        type: {
            name: "String"
        }
    }
};
const include = {
    parameterPath: ["options", "include"],
    mapper: {
        serializedName: "include",
        xmlName: "include",
        xmlElementName: "ListBlobsIncludeItem",
        type: {
            name: "Sequence",
            element: {
                type: {
                    name: "Enum",
                    allowedValues: [
                        "copy",
                        "deleted",
                        "metadata",
                        "snapshots",
                        "uncommittedblobs",
                        "versions",
                        "tags"
                    ]
                }
            }
        }
    },
    collectionFormat: coreHttp.QueryCollectionFormat.Csv
};
const showonly = {
    parameterPath: ["options", "showonly"],
    mapper: {
        defaultValue: "deleted",
        isConstant: true,
        serializedName: "showonly",
        type: {
            name: "String"
        }
    }
};
const resource2 = {
    parameterPath: ["options", "resource"],
    mapper: {
        serializedName: "resource",
        xmlName: "resource",
        type: {
            name: "Enum",
            allowedValues: ["directory", "file"]
        }
    }
};
const mode = {
    parameterPath: ["options", "mode"],
    mapper: {
        serializedName: "mode",
        xmlName: "mode",
        type: {
            name: "Enum",
            allowedValues: ["legacy", "posix"]
        }
    }
};
const cacheControl = {
    parameterPath: ["options", "pathHttpHeaders", "cacheControl"],
    mapper: {
        serializedName: "x-ms-cache-control",
        xmlName: "x-ms-cache-control",
        type: {
            name: "String"
        }
    }
};
const contentEncoding = {
    parameterPath: ["options", "pathHttpHeaders", "contentEncoding"],
    mapper: {
        serializedName: "x-ms-content-encoding",
        xmlName: "x-ms-content-encoding",
        type: {
            name: "String"
        }
    }
};
const contentLanguage = {
    parameterPath: ["options", "pathHttpHeaders", "contentLanguage"],
    mapper: {
        serializedName: "x-ms-content-language",
        xmlName: "x-ms-content-language",
        type: {
            name: "String"
        }
    }
};
const contentDisposition = {
    parameterPath: ["options", "pathHttpHeaders", "contentDisposition"],
    mapper: {
        serializedName: "x-ms-content-disposition",
        xmlName: "x-ms-content-disposition",
        type: {
            name: "String"
        }
    }
};
const contentType = {
    parameterPath: ["options", "pathHttpHeaders", "contentType"],
    mapper: {
        serializedName: "x-ms-content-type",
        xmlName: "x-ms-content-type",
        type: {
            name: "String"
        }
    }
};
const renameSource = {
    parameterPath: ["options", "renameSource"],
    mapper: {
        serializedName: "x-ms-rename-source",
        xmlName: "x-ms-rename-source",
        type: {
            name: "String"
        }
    }
};
const leaseId = {
    parameterPath: ["options", "leaseAccessConditions", "leaseId"],
    mapper: {
        serializedName: "x-ms-lease-id",
        xmlName: "x-ms-lease-id",
        type: {
            name: "String"
        }
    }
};
const sourceLeaseId = {
    parameterPath: ["options", "sourceLeaseId"],
    mapper: {
        serializedName: "x-ms-source-lease-id",
        xmlName: "x-ms-source-lease-id",
        type: {
            name: "String"
        }
    }
};
const permissions = {
    parameterPath: ["options", "permissions"],
    mapper: {
        serializedName: "x-ms-permissions",
        xmlName: "x-ms-permissions",
        type: {
            name: "String"
        }
    }
};
const umask = {
    parameterPath: ["options", "umask"],
    mapper: {
        serializedName: "x-ms-umask",
        xmlName: "x-ms-umask",
        type: {
            name: "String"
        }
    }
};
const ifMatch = {
    parameterPath: ["options", "modifiedAccessConditions", "ifMatch"],
    mapper: {
        serializedName: "If-Match",
        xmlName: "If-Match",
        type: {
            name: "String"
        }
    }
};
const ifNoneMatch = {
    parameterPath: ["options", "modifiedAccessConditions", "ifNoneMatch"],
    mapper: {
        serializedName: "If-None-Match",
        xmlName: "If-None-Match",
        type: {
            name: "String"
        }
    }
};
const sourceIfMatch = {
    parameterPath: ["options", "sourceModifiedAccessConditions", "sourceIfMatch"],
    mapper: {
        serializedName: "x-ms-source-if-match",
        xmlName: "x-ms-source-if-match",
        type: {
            name: "String"
        }
    }
};
const sourceIfNoneMatch = {
    parameterPath: [
        "options",
        "sourceModifiedAccessConditions",
        "sourceIfNoneMatch"
    ],
    mapper: {
        serializedName: "x-ms-source-if-none-match",
        xmlName: "x-ms-source-if-none-match",
        type: {
            name: "String"
        }
    }
};
const sourceIfModifiedSince = {
    parameterPath: [
        "options",
        "sourceModifiedAccessConditions",
        "sourceIfModifiedSince"
    ],
    mapper: {
        serializedName: "x-ms-source-if-modified-since",
        xmlName: "x-ms-source-if-modified-since",
        type: {
            name: "DateTimeRfc1123"
        }
    }
};
const sourceIfUnmodifiedSince = {
    parameterPath: [
        "options",
        "sourceModifiedAccessConditions",
        "sourceIfUnmodifiedSince"
    ],
    mapper: {
        serializedName: "x-ms-source-if-unmodified-since",
        xmlName: "x-ms-source-if-unmodified-since",
        type: {
            name: "DateTimeRfc1123"
        }
    }
};
const contentType1 = {
    parameterPath: ["options", "contentType"],
    mapper: {
        defaultValue: "application/octet-stream",
        isConstant: true,
        serializedName: "Content-Type",
        type: {
            name: "String"
        }
    }
};
const body = {
    parameterPath: "body",
    mapper: {
        serializedName: "body",
        required: true,
        xmlName: "body",
        type: {
            name: "Stream"
        }
    }
};
const accept2 = {
    parameterPath: "accept",
    mapper: {
        defaultValue: "application/json",
        isConstant: true,
        serializedName: "Accept",
        type: {
            name: "String"
        }
    }
};
const action = {
    parameterPath: "action",
    mapper: {
        serializedName: "action",
        required: true,
        xmlName: "action",
        type: {
            name: "Enum",
            allowedValues: [
                "append",
                "flush",
                "setProperties",
                "setAccessControl",
                "setAccessControlRecursive"
            ]
        }
    }
};
const maxRecords = {
    parameterPath: ["options", "maxRecords"],
    mapper: {
        constraints: {
            InclusiveMinimum: 1
        },
        serializedName: "maxRecords",
        xmlName: "maxRecords",
        type: {
            name: "Number"
        }
    }
};
const mode1 = {
    parameterPath: "mode",
    mapper: {
        serializedName: "mode",
        required: true,
        xmlName: "mode",
        type: {
            name: "Enum",
            allowedValues: ["set", "modify", "remove"]
        }
    }
};
const forceFlag = {
    parameterPath: ["options", "forceFlag"],
    mapper: {
        serializedName: "forceFlag",
        xmlName: "forceFlag",
        type: {
            name: "Boolean"
        }
    }
};
const position = {
    parameterPath: ["options", "position"],
    mapper: {
        serializedName: "position",
        xmlName: "position",
        type: {
            name: "Number"
        }
    }
};
const retainUncommittedData = {
    parameterPath: ["options", "retainUncommittedData"],
    mapper: {
        serializedName: "retainUncommittedData",
        xmlName: "retainUncommittedData",
        type: {
            name: "Boolean"
        }
    }
};
const close = {
    parameterPath: ["options", "close"],
    mapper: {
        serializedName: "close",
        xmlName: "close",
        type: {
            name: "Boolean"
        }
    }
};
const contentLength = {
    parameterPath: ["options", "contentLength"],
    mapper: {
        constraints: {
            InclusiveMinimum: 0
        },
        serializedName: "Content-Length",
        xmlName: "Content-Length",
        type: {
            name: "Number"
        }
    }
};
const contentMD5 = {
    parameterPath: ["options", "pathHttpHeaders", "contentMD5"],
    mapper: {
        serializedName: "x-ms-content-md5",
        xmlName: "x-ms-content-md5",
        type: {
            name: "ByteArray"
        }
    }
};
const owner = {
    parameterPath: ["options", "owner"],
    mapper: {
        serializedName: "x-ms-owner",
        xmlName: "x-ms-owner",
        type: {
            name: "String"
        }
    }
};
const group = {
    parameterPath: ["options", "group"],
    mapper: {
        serializedName: "x-ms-group",
        xmlName: "x-ms-group",
        type: {
            name: "String"
        }
    }
};
const acl = {
    parameterPath: ["options", "acl"],
    mapper: {
        serializedName: "x-ms-acl",
        xmlName: "x-ms-acl",
        type: {
            name: "String"
        }
    }
};
const xMsLeaseAction = {
    parameterPath: "xMsLeaseAction",
    mapper: {
        serializedName: "x-ms-lease-action",
        required: true,
        xmlName: "x-ms-lease-action",
        type: {
            name: "Enum",
            allowedValues: ["acquire", "break", "change", "renew", "release"]
        }
    }
};
const xMsLeaseDuration = {
    parameterPath: ["options", "xMsLeaseDuration"],
    mapper: {
        serializedName: "x-ms-lease-duration",
        xmlName: "x-ms-lease-duration",
        type: {
            name: "Number"
        }
    }
};
const xMsLeaseBreakPeriod = {
    parameterPath: ["options", "xMsLeaseBreakPeriod"],
    mapper: {
        serializedName: "x-ms-lease-break-period",
        xmlName: "x-ms-lease-break-period",
        type: {
            name: "Number"
        }
    }
};
const proposedLeaseId = {
    parameterPath: ["options", "proposedLeaseId"],
    mapper: {
        serializedName: "x-ms-proposed-lease-id",
        xmlName: "x-ms-proposed-lease-id",
        type: {
            name: "String"
        }
    }
};
const range = {
    parameterPath: ["options", "range"],
    mapper: {
        serializedName: "Range",
        xmlName: "Range",
        type: {
            name: "String"
        }
    }
};
const xMsRangeGetContentMd5 = {
    parameterPath: ["options", "xMsRangeGetContentMd5"],
    mapper: {
        serializedName: "x-ms-range-get-content-md5",
        xmlName: "x-ms-range-get-content-md5",
        type: {
            name: "Boolean"
        }
    }
};
const action1 = {
    parameterPath: ["options", "action"],
    mapper: {
        serializedName: "action",
        xmlName: "action",
        type: {
            name: "Enum",
            allowedValues: ["getAccessControl", "getStatus"]
        }
    }
};
const recursive1 = {
    parameterPath: ["options", "recursive"],
    mapper: {
        serializedName: "recursive",
        xmlName: "recursive",
        type: {
            name: "Boolean"
        }
    }
};
const action2 = {
    parameterPath: "action",
    mapper: {
        defaultValue: "setAccessControl",
        isConstant: true,
        serializedName: "action",
        type: {
            name: "String"
        }
    }
};
const action3 = {
    parameterPath: "action",
    mapper: {
        defaultValue: "setAccessControlRecursive",
        isConstant: true,
        serializedName: "action",
        type: {
            name: "String"
        }
    }
};
const action4 = {
    parameterPath: "action",
    mapper: {
        defaultValue: "flush",
        isConstant: true,
        serializedName: "action",
        type: {
            name: "String"
        }
    }
};
const contentType2 = {
    parameterPath: ["options", "contentType"],
    mapper: {
        defaultValue: "application/json",
        isConstant: true,
        serializedName: "Content-Type",
        type: {
            name: "String"
        }
    }
};
const action5 = {
    parameterPath: "action",
    mapper: {
        defaultValue: "append",
        isConstant: true,
        serializedName: "action",
        type: {
            name: "String"
        }
    }
};
const transactionalContentHash = {
    parameterPath: ["options", "pathHttpHeaders", "transactionalContentHash"],
    mapper: {
        serializedName: "Content-MD5",
        xmlName: "Content-MD5",
        type: {
            name: "ByteArray"
        }
    }
};
const transactionalContentCrc64 = {
    parameterPath: ["options", "transactionalContentCrc64"],
    mapper: {
        serializedName: "x-ms-content-crc64",
        xmlName: "x-ms-content-crc64",
        type: {
            name: "ByteArray"
        }
    }
};
const comp1 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "expiry",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const expiryOptions = {
    parameterPath: "expiryOptions",
    mapper: {
        serializedName: "x-ms-expiry-option",
        required: true,
        xmlName: "x-ms-expiry-option",
        type: {
            name: "Enum",
            allowedValues: [
                "NeverExpire",
                "RelativeToCreation",
                "RelativeToNow",
                "Absolute"
            ]
        }
    }
};
const expiresOn = {
    parameterPath: ["options", "expiresOn"],
    mapper: {
        serializedName: "x-ms-expiry-time",
        xmlName: "x-ms-expiry-time",
        type: {
            name: "String"
        }
    }
};
const comp2 = {
    parameterPath: "comp",
    mapper: {
        defaultValue: "undelete",
        isConstant: true,
        serializedName: "comp",
        type: {
            name: "String"
        }
    }
};
const undeleteSource = {
    parameterPath: ["options", "undeleteSource"],
    mapper: {
        serializedName: "x-ms-undelete-source",
        xmlName: "x-ms-undelete-source",
        type: {
            name: "String"
        }
    }
};

/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */
/** Class representing a FileSystem. */
class FileSystem$1 {
    /**
     * Initialize a new instance of the class FileSystem class.
     * @param client Reference to the service client
     */
    constructor(client) {
        this.client = client;
    }
    /**
     * Create a FileSystem rooted at the specified location. If the FileSystem already exists, the
     * operation fails.  This operation does not support conditional HTTP requests.
     * @param options The options parameters.
     */
    create(options) {
        const operationArguments = {
            options: coreHttp.operationOptionsToRequestOptionsBase(options || {})
        };
        return this.client.sendOperationRequest(operationArguments, createOperationSpec);
    }
    /**
     * Set properties for the FileSystem.  This operation supports conditional HTTP requests.  For more
     * information, see [Specifying Conditional Headers for Blob Service
     * Operations](https://docs.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations).
     * @param options The options parameters.
     */
    setProperties(options) {
        const operationArguments = {
            options: coreHttp.operationOptionsToRequestOptionsBase(options || {})
        };
        return this.client.sendOperationRequest(operationArguments, setPropertiesOperationSpec);
    }
    /**
     * All system and user-defined filesystem properties are specified in the response headers.
     * @param options The options parameters.
     */
    getProperties(options) {
        const operationArguments = {
            options: coreHttp.operationOptionsToRequestOptionsBase(options || {})
        };
        return this.client.sendOperationRequest(operationArguments, getPropertiesOperationSpec);
    }
    /**
     * Marks the FileSystem for deletion.  When a FileSystem is deleted, a FileSystem with the same
     * identifier cannot be created for at least 30 seconds. While the filesystem is being deleted,
     * attempts to create a filesystem with the same identifier will fail with status code 409 (Conflict),
     * with the service returning additional error information indicating that the filesystem is being
     * deleted. All other operations, including operations on any files or directories within the
     * filesystem, will fail with status code 404 (Not Found) while the filesystem is being deleted. This
     * operation supports conditional HTTP requests.  For more information, see [Specifying Conditional
     * Headers for Blob Service
     * Operations](https://docs.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations).
     * @param options The options parameters.
     */
    delete(options) {
        const operationArguments = {
            options: coreHttp.operationOptionsToRequestOptionsBase(options || {})
        };
        return this.client.sendOperationRequest(operationArguments, deleteOperationSpec);
    }
    /**
     * List FileSystem paths and their properties.
     * @param recursive Required
     * @param options The options parameters.
     */
    listPaths(recursive, options) {
        const operationArguments = {
            recursive,
            options: coreHttp.operationOptionsToRequestOptionsBase(options || {})
        };
        return this.client.sendOperationRequest(operationArguments, listPathsOperationSpec);
    }
    /**
     * The List Blobs operation returns a list of the blobs under the specified container
     * @param options The options parameters.
     */
    listBlobHierarchySegment(options) {
        const operationArguments = {
            options: coreHttp.operationOptionsToRequestOptionsBase(options || {})
        };
        return this.client.sendOperationRequest(operationArguments, listBlobHierarchySegmentOperationSpec);
    }
}
// Operation Specifications
const xmlSerializer = new coreHttp.Serializer(Mappers, /* isXml */ true);
const serializer = new coreHttp.Serializer(Mappers, /* isXml */ false);
const createOperationSpec = {
    path: "/{filesystem}",
    httpMethod: "PUT",
    responses: {
        201: {
            headersMapper: FileSystemCreateHeaders
        },
        default: {
            bodyMapper: StorageError,
            headersMapper: FileSystemCreateExceptionHeaders
        }
    },
    queryParameters: [timeout, resource1],
    urlParameters: [url],
    headerParameters: [
        accept,
        requestId,
        version,
        properties
    ],
    serializer
};
const setPropertiesOperationSpec = {
    path: "/{filesystem}",
    httpMethod: "PATCH",
    responses: {
        200: {
            headersMapper: FileSystemSetPropertiesHeaders
        },
        default: {
            bodyMapper: StorageError,
            headersMapper: FileSystemSetPropertiesExceptionHeaders
        }
    },
    queryParameters: [timeout, resource1],
    urlParameters: [url],
    headerParameters: [
        accept,
        requestId,
        version,
        properties,
        ifModifiedSince,
        ifUnmodifiedSince
    ],
    serializer
};
const getPropertiesOperationSpec = {
    path: "/{filesystem}",
    httpMethod: "HEAD",
    responses: {
        200: {
            headersMapper: FileSystemGetPropertiesHeaders
        },
        default: {
            bodyMapper: StorageError,
            headersMapper: FileSystemGetPropertiesExceptionHeaders
        }
    },
    queryParameters: [timeout, resource1],
    urlParameters: [url],
    headerParameters: [
        accept,
        requestId,
        version
    ],
    serializer
};
const deleteOperationSpec = {
    path: "/{filesystem}",
    httpMethod: "DELETE",
    responses: {
        202: {
            headersMapper: FileSystemDeleteHeaders
        },
        default: {
            bodyMapper: StorageError,
            headersMapper: FileSystemDeleteExceptionHeaders
        }
    },
    queryParameters: [timeout, resource1],
    urlParameters: [url],
    headerParameters: [
        accept,
        requestId,
        version,
        ifModifiedSince,
        ifUnmodifiedSince
    ],
    serializer
};
const listPathsOperationSpec = {
    path: "/{filesystem}",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: PathList,
            headersMapper: FileSystemListPathsHeaders
        },
        default: {
            bodyMapper: StorageError,
            headersMapper: FileSystemListPathsExceptionHeaders
        }
    },
    queryParameters: [
        continuation,
        maxResults,
        timeout,
        resource1,
        path,
        recursive,
        upn
    ],
    urlParameters: [url],
    headerParameters: [
        accept,
        requestId,
        version
    ],
    serializer
};
const listBlobHierarchySegmentOperationSpec = {
    path: "/{filesystem}",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: ListBlobsHierarchySegmentResponse,
            headersMapper: FileSystemListBlobHierarchySegmentHeaders
        },
        default: {
            bodyMapper: StorageError,
            headersMapper: FileSystemListBlobHierarchySegmentExceptionHeaders
        }
    },
    queryParameters: [
        prefix,
        maxResults,
        timeout,
        restype,
        comp,
        delimiter,
        marker,
        include,
        showonly
    ],
    urlParameters: [url],
    headerParameters: [
        requestId,
        version,
        accept1
    ],
    isXML: true,
    serializer: xmlSerializer
};

/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */
/** Class representing a Path. */
class Path$1 {
    /**
     * Initialize a new instance of the class Path class.
     * @param client Reference to the service client
     */
    constructor(client) {
        this.client = client;
    }
    /**
     * Create or rename a file or directory.    By default, the destination is overwritten and if the
     * destination already exists and has a lease the lease is broken.  This operation supports conditional
     * HTTP requests.  For more information, see [Specifying Conditional Headers for Blob Service
     * Operations](https://docs.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations).
     *  To fail if the destination already exists, use a conditional request with If-None-Match: "*".
     * @param options The options parameters.
     */
    create(options) {
        const operationArguments = {
            options: coreHttp.operationOptionsToRequestOptionsBase(options || {})
        };
        return this.client.sendOperationRequest(operationArguments, createOperationSpec$1);
    }
    /**
     * Uploads data to be appended to a file, flushes (writes) previously uploaded data to a file, sets
     * properties for a file or directory, or sets access control for a file or directory. Data can only be
     * appended to a file. Concurrent writes to the same file using multiple clients are not supported.
     * This operation supports conditional HTTP requests. For more information, see [Specifying Conditional
     * Headers for Blob Service
     * Operations](https://docs.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations).
     * @param action The action must be "append" to upload data to be appended to a file, "flush" to flush
     *               previously uploaded data to a file, "setProperties" to set the properties of a file or directory,
     *               "setAccessControl" to set the owner, group, permissions, or access control list for a file or
     *               directory, or  "setAccessControlRecursive" to set the access control list for a directory
     *               recursively. Note that Hierarchical Namespace must be enabled for the account in order to use access
     *               control.  Also note that the Access Control List (ACL) includes permissions for the owner, owning
     *               group, and others, so the x-ms-permissions and x-ms-acl request headers are mutually exclusive.
     * @param mode Mode "set" sets POSIX access control rights on files and directories, "modify" modifies
     *             one or more POSIX access control rights  that pre-exist on files and directories, "remove" removes
     *             one or more POSIX access control rights  that were present earlier on files and directories
     * @param body Initial data
     * @param options The options parameters.
     */
    update(action, mode, body, options) {
        const operationArguments = {
            action,
            mode,
            body,
            options: coreHttp.operationOptionsToRequestOptionsBase(options || {})
        };
        return this.client.sendOperationRequest(operationArguments, updateOperationSpec);
    }
    /**
     * Create and manage a lease to restrict write and delete access to the path. This operation supports
     * conditional HTTP requests.  For more information, see [Specifying Conditional Headers for Blob
     * Service
     * Operations](https://docs.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations).
     * @param xMsLeaseAction There are five lease actions: "acquire", "break", "change", "renew", and
     *                       "release". Use "acquire" and specify the "x-ms-proposed-lease-id" and "x-ms-lease-duration" to
     *                       acquire a new lease. Use "break" to break an existing lease. When a lease is broken, the lease break
     *                       period is allowed to elapse, during which time no lease operation except break and release can be
     *                       performed on the file. When a lease is successfully broken, the response indicates the interval in
     *                       seconds until a new lease can be acquired. Use "change" and specify the current lease ID in
     *                       "x-ms-lease-id" and the new lease ID in "x-ms-proposed-lease-id" to change the lease ID of an active
     *                       lease. Use "renew" and specify the "x-ms-lease-id" to renew an existing lease. Use "release" and
     *                       specify the "x-ms-lease-id" to release a lease.
     * @param options The options parameters.
     */
    lease(xMsLeaseAction, options) {
        const operationArguments = {
            xMsLeaseAction,
            options: coreHttp.operationOptionsToRequestOptionsBase(options || {})
        };
        return this.client.sendOperationRequest(operationArguments, leaseOperationSpec);
    }
    /**
     * Read the contents of a file.  For read operations, range requests are supported. This operation
     * supports conditional HTTP requests.  For more information, see [Specifying Conditional Headers for
     * Blob Service
     * Operations](https://docs.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations).
     * @param options The options parameters.
     */
    read(options) {
        const operationArguments = {
            options: coreHttp.operationOptionsToRequestOptionsBase(options || {})
        };
        return this.client.sendOperationRequest(operationArguments, readOperationSpec);
    }
    /**
     * Get Properties returns all system and user defined properties for a path. Get Status returns all
     * system defined properties for a path. Get Access Control List returns the access control list for a
     * path. This operation supports conditional HTTP requests.  For more information, see [Specifying
     * Conditional Headers for Blob Service
     * Operations](https://docs.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations).
     * @param options The options parameters.
     */
    getProperties(options) {
        const operationArguments = {
            options: coreHttp.operationOptionsToRequestOptionsBase(options || {})
        };
        return this.client.sendOperationRequest(operationArguments, getPropertiesOperationSpec$1);
    }
    /**
     * Delete the file or directory. This operation supports conditional HTTP requests.  For more
     * information, see [Specifying Conditional Headers for Blob Service
     * Operations](https://docs.microsoft.com/en-us/rest/api/storageservices/specifying-conditional-headers-for-blob-service-operations).
     * @param options The options parameters.
     */
    delete(options) {
        const operationArguments = {
            options: coreHttp.operationOptionsToRequestOptionsBase(options || {})
        };
        return this.client.sendOperationRequest(operationArguments, deleteOperationSpec$1);
    }
    /**
     * Set the owner, group, permissions, or access control list for a path.
     * @param options The options parameters.
     */
    setAccessControl(options) {
        const operationArguments = {
            options: coreHttp.operationOptionsToRequestOptionsBase(options || {})
        };
        return this.client.sendOperationRequest(operationArguments, setAccessControlOperationSpec);
    }
    /**
     * Set the access control list for a path and sub-paths.
     * @param mode Mode "set" sets POSIX access control rights on files and directories, "modify" modifies
     *             one or more POSIX access control rights  that pre-exist on files and directories, "remove" removes
     *             one or more POSIX access control rights  that were present earlier on files and directories
     * @param options The options parameters.
     */
    setAccessControlRecursive(mode, options) {
        const operationArguments = {
            mode,
            options: coreHttp.operationOptionsToRequestOptionsBase(options || {})
        };
        return this.client.sendOperationRequest(operationArguments, setAccessControlRecursiveOperationSpec);
    }
    /**
     * Set the owner, group, permissions, or access control list for a path.
     * @param options The options parameters.
     */
    flushData(options) {
        const operationArguments = {
            options: coreHttp.operationOptionsToRequestOptionsBase(options || {})
        };
        return this.client.sendOperationRequest(operationArguments, flushDataOperationSpec);
    }
    /**
     * Append data to the file.
     * @param body Initial data
     * @param options The options parameters.
     */
    appendData(body, options) {
        const operationArguments = {
            body,
            options: coreHttp.operationOptionsToRequestOptionsBase(options || {})
        };
        return this.client.sendOperationRequest(operationArguments, appendDataOperationSpec);
    }
    /**
     * Sets the time a blob will expire and be deleted.
     * @param expiryOptions Required. Indicates mode of the expiry time
     * @param options The options parameters.
     */
    setExpiry(expiryOptions, options) {
        const operationArguments = {
            expiryOptions,
            options: coreHttp.operationOptionsToRequestOptionsBase(options || {})
        };
        return this.client.sendOperationRequest(operationArguments, setExpiryOperationSpec);
    }
    /**
     * Undelete a path that was previously soft deleted
     * @param options The options parameters.
     */
    undelete(options) {
        const operationArguments = {
            options: coreHttp.operationOptionsToRequestOptionsBase(options || {})
        };
        return this.client.sendOperationRequest(operationArguments, undeleteOperationSpec);
    }
}
// Operation Specifications
const serializer$1 = new coreHttp.Serializer(Mappers, /* isXml */ false);
const createOperationSpec$1 = {
    path: "/{filesystem}/{path}",
    httpMethod: "PUT",
    responses: {
        201: {
            headersMapper: PathCreateHeaders
        },
        default: {
            bodyMapper: StorageError,
            headersMapper: PathCreateExceptionHeaders
        }
    },
    queryParameters: [
        continuation,
        timeout,
        resource2,
        mode
    ],
    urlParameters: [url],
    headerParameters: [
        accept,
        requestId,
        version,
        properties,
        ifModifiedSince,
        ifUnmodifiedSince,
        cacheControl,
        contentEncoding,
        contentLanguage,
        contentDisposition,
        contentType,
        renameSource,
        leaseId,
        sourceLeaseId,
        permissions,
        umask,
        ifMatch,
        ifNoneMatch,
        sourceIfMatch,
        sourceIfNoneMatch,
        sourceIfModifiedSince,
        sourceIfUnmodifiedSince
    ],
    serializer: serializer$1
};
const updateOperationSpec = {
    path: "/{filesystem}/{path}",
    httpMethod: "PATCH",
    responses: {
        200: {
            bodyMapper: SetAccessControlRecursiveResponse,
            headersMapper: PathUpdateHeaders
        },
        202: {
            headersMapper: PathUpdateHeaders
        },
        default: {
            bodyMapper: StorageError,
            headersMapper: PathUpdateExceptionHeaders
        }
    },
    requestBody: body,
    queryParameters: [
        continuation,
        timeout,
        action,
        maxRecords,
        mode1,
        forceFlag,
        position,
        retainUncommittedData,
        close
    ],
    urlParameters: [url],
    headerParameters: [
        requestId,
        version,
        properties,
        ifModifiedSince,
        ifUnmodifiedSince,
        cacheControl,
        contentEncoding,
        contentLanguage,
        contentDisposition,
        contentType,
        leaseId,
        permissions,
        ifMatch,
        ifNoneMatch,
        contentType1,
        accept2,
        contentLength,
        contentMD5,
        owner,
        group,
        acl
    ],
    mediaType: "binary",
    serializer: serializer$1
};
const leaseOperationSpec = {
    path: "/{filesystem}/{path}",
    httpMethod: "POST",
    responses: {
        200: {
            headersMapper: PathLeaseHeaders
        },
        201: {
            headersMapper: PathLeaseHeaders
        },
        202: {
            headersMapper: PathLeaseHeaders
        },
        default: {
            bodyMapper: StorageError,
            headersMapper: PathLeaseExceptionHeaders
        }
    },
    queryParameters: [timeout],
    urlParameters: [url],
    headerParameters: [
        accept,
        requestId,
        version,
        ifModifiedSince,
        ifUnmodifiedSince,
        leaseId,
        ifMatch,
        ifNoneMatch,
        xMsLeaseAction,
        xMsLeaseDuration,
        xMsLeaseBreakPeriod,
        proposedLeaseId
    ],
    serializer: serializer$1
};
const readOperationSpec = {
    path: "/{filesystem}/{path}",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: {
                type: { name: "Stream" },
                serializedName: "parsedResponse"
            },
            headersMapper: PathReadHeaders
        },
        206: {
            bodyMapper: {
                type: { name: "Stream" },
                serializedName: "parsedResponse"
            },
            headersMapper: PathReadHeaders
        },
        default: {
            bodyMapper: StorageError,
            headersMapper: PathReadExceptionHeaders
        }
    },
    queryParameters: [timeout],
    urlParameters: [url],
    headerParameters: [
        accept,
        requestId,
        version,
        ifModifiedSince,
        ifUnmodifiedSince,
        leaseId,
        ifMatch,
        ifNoneMatch,
        range,
        xMsRangeGetContentMd5
    ],
    serializer: serializer$1
};
const getPropertiesOperationSpec$1 = {
    path: "/{filesystem}/{path}",
    httpMethod: "HEAD",
    responses: {
        200: {
            headersMapper: PathGetPropertiesHeaders
        },
        default: {
            bodyMapper: StorageError,
            headersMapper: PathGetPropertiesExceptionHeaders
        }
    },
    queryParameters: [timeout, upn, action1],
    urlParameters: [url],
    headerParameters: [
        accept,
        requestId,
        version,
        ifModifiedSince,
        ifUnmodifiedSince,
        leaseId,
        ifMatch,
        ifNoneMatch
    ],
    serializer: serializer$1
};
const deleteOperationSpec$1 = {
    path: "/{filesystem}/{path}",
    httpMethod: "DELETE",
    responses: {
        200: {
            headersMapper: PathDeleteHeaders
        },
        default: {
            bodyMapper: StorageError,
            headersMapper: PathDeleteExceptionHeaders
        }
    },
    queryParameters: [
        continuation,
        timeout,
        recursive1
    ],
    urlParameters: [url],
    headerParameters: [
        accept,
        requestId,
        version,
        ifModifiedSince,
        ifUnmodifiedSince,
        leaseId,
        ifMatch,
        ifNoneMatch
    ],
    serializer: serializer$1
};
const setAccessControlOperationSpec = {
    path: "/{filesystem}/{path}",
    httpMethod: "PATCH",
    responses: {
        200: {
            headersMapper: PathSetAccessControlHeaders
        },
        default: {
            bodyMapper: StorageError,
            headersMapper: PathSetAccessControlExceptionHeaders
        }
    },
    queryParameters: [timeout, action2],
    urlParameters: [url],
    headerParameters: [
        accept,
        requestId,
        version,
        ifModifiedSince,
        ifUnmodifiedSince,
        leaseId,
        permissions,
        ifMatch,
        ifNoneMatch,
        owner,
        group,
        acl
    ],
    serializer: serializer$1
};
const setAccessControlRecursiveOperationSpec = {
    path: "/{filesystem}/{path}",
    httpMethod: "PATCH",
    responses: {
        200: {
            bodyMapper: SetAccessControlRecursiveResponse,
            headersMapper: PathSetAccessControlRecursiveHeaders
        },
        default: {
            bodyMapper: StorageError,
            headersMapper: PathSetAccessControlRecursiveExceptionHeaders
        }
    },
    queryParameters: [
        continuation,
        timeout,
        maxRecords,
        mode1,
        forceFlag,
        action3
    ],
    urlParameters: [url],
    headerParameters: [
        accept,
        requestId,
        version,
        acl
    ],
    serializer: serializer$1
};
const flushDataOperationSpec = {
    path: "/{filesystem}/{path}",
    httpMethod: "PATCH",
    responses: {
        200: {
            headersMapper: PathFlushDataHeaders
        },
        default: {
            bodyMapper: StorageError,
            headersMapper: PathFlushDataExceptionHeaders
        }
    },
    queryParameters: [
        timeout,
        position,
        retainUncommittedData,
        close,
        action4
    ],
    urlParameters: [url],
    headerParameters: [
        accept,
        requestId,
        version,
        ifModifiedSince,
        ifUnmodifiedSince,
        cacheControl,
        contentEncoding,
        contentLanguage,
        contentDisposition,
        contentType,
        leaseId,
        ifMatch,
        ifNoneMatch,
        contentLength,
        contentMD5
    ],
    serializer: serializer$1
};
const appendDataOperationSpec = {
    path: "/{filesystem}/{path}",
    httpMethod: "PATCH",
    responses: {
        202: {
            headersMapper: PathAppendDataHeaders
        },
        default: {
            bodyMapper: StorageError,
            headersMapper: PathAppendDataExceptionHeaders
        }
    },
    requestBody: body,
    queryParameters: [
        timeout,
        position,
        action5
    ],
    urlParameters: [url],
    headerParameters: [
        requestId,
        version,
        leaseId,
        accept2,
        contentLength,
        contentType2,
        transactionalContentHash,
        transactionalContentCrc64
    ],
    mediaType: "binary",
    serializer: serializer$1
};
const setExpiryOperationSpec = {
    path: "/{filesystem}/{path}",
    httpMethod: "PUT",
    responses: {
        200: {
            headersMapper: PathSetExpiryHeaders
        },
        default: {
            bodyMapper: StorageError,
            headersMapper: PathSetExpiryExceptionHeaders
        }
    },
    queryParameters: [timeout, comp1],
    urlParameters: [url],
    headerParameters: [
        accept,
        requestId,
        version,
        expiryOptions,
        expiresOn
    ],
    serializer: serializer$1
};
const undeleteOperationSpec = {
    path: "/{filesystem}/{path}",
    httpMethod: "PUT",
    responses: {
        200: {
            headersMapper: PathUndeleteHeaders
        },
        default: {
            bodyMapper: StorageError,
            headersMapper: PathUndeleteExceptionHeaders
        }
    },
    queryParameters: [timeout, comp2],
    urlParameters: [url],
    headerParameters: [
        accept,
        requestId,
        version,
        undeleteSource
    ],
    serializer: serializer$1
};

// Copyright (c) Microsoft Corporation.
/**
 * The `@azure/logger` configuration for this package.
 */
const logger = logger$1.createClientLogger("storage-file-datalake");

// Copyright (c) Microsoft Corporation.
/**
 * StorageBrowserPolicy will handle differences between Node.js and browser runtime, including:
 *
 * 1. Browsers cache GET/HEAD requests by adding conditional headers such as 'IF_MODIFIED_SINCE'.
 * StorageBrowserPolicy is a policy used to add a timestamp query to GET/HEAD request URL
 * thus avoid the browser cache.
 *
 * 2. Remove cookie header for security
 *
 * 3. Remove content-length header to avoid browsers warning
 */
class StorageBrowserPolicy extends coreHttp.BaseRequestPolicy {
    /**
     * Creates an instance of StorageBrowserPolicy.
     * @param nextPolicy -
     * @param options -
     */
    // The base class has a protected constructor. Adding a public one to enable constructing of this class.
    /* eslint-disable-next-line @typescript-eslint/no-useless-constructor*/
    constructor(nextPolicy, options) {
        super(nextPolicy, options);
    }
    /**
     * Sends out request.
     *
     * @param request -
     */
    async sendRequest(request) {
        {
            return this._nextPolicy.sendRequest(request);
        }
    }
}

// Copyright (c) Microsoft Corporation.
/**
 * StorageBrowserPolicyFactory is a factory class helping generating StorageBrowserPolicy objects.
 */
class StorageBrowserPolicyFactory {
    /**
     * Creates a StorageBrowserPolicyFactory object.
     *
     * @param nextPolicy -
     * @param options -
     */
    create(nextPolicy, options) {
        return new StorageBrowserPolicy(nextPolicy, options);
    }
}

// Copyright (c) Microsoft Corporation.
(function (StorageRetryPolicyType) {
    /**
     * Exponential retry. Retry time delay grows exponentially.
     */
    StorageRetryPolicyType[StorageRetryPolicyType["EXPONENTIAL"] = 0] = "EXPONENTIAL";
    /**
     * Linear retry. Retry time delay grows linearly.
     */
    StorageRetryPolicyType[StorageRetryPolicyType["FIXED"] = 1] = "FIXED";
})(exports.StorageRetryPolicyType || (exports.StorageRetryPolicyType = {}));
// Default values of StorageRetryOptions
const DEFAULT_RETRY_OPTIONS = {
    maxRetryDelayInMs: 120 * 1000,
    maxTries: 4,
    retryDelayInMs: 4 * 1000,
    retryPolicyType: exports.StorageRetryPolicyType.EXPONENTIAL,
    secondaryHost: "",
    tryTimeoutInMs: undefined // Use server side default timeout strategy
};
const RETRY_ABORT_ERROR = new abortController.AbortError("The operation was aborted.");
/**
 * Retry policy with exponential retry and linear retry implemented.
 */
class StorageRetryPolicy extends coreHttp.BaseRequestPolicy {
    /**
     * Creates an instance of RetryPolicy.
     *
     * @param nextPolicy -
     * @param options -
     * @param retryOptions -
     */
    constructor(nextPolicy, options, retryOptions = DEFAULT_RETRY_OPTIONS) {
        super(nextPolicy, options);
        // Initialize retry options
        this.retryOptions = {
            retryPolicyType: retryOptions.retryPolicyType
                ? retryOptions.retryPolicyType
                : DEFAULT_RETRY_OPTIONS.retryPolicyType,
            maxTries: retryOptions.maxTries && retryOptions.maxTries >= 1
                ? Math.floor(retryOptions.maxTries)
                : DEFAULT_RETRY_OPTIONS.maxTries,
            tryTimeoutInMs: retryOptions.tryTimeoutInMs && retryOptions.tryTimeoutInMs >= 0
                ? retryOptions.tryTimeoutInMs
                : DEFAULT_RETRY_OPTIONS.tryTimeoutInMs,
            retryDelayInMs: retryOptions.retryDelayInMs && retryOptions.retryDelayInMs >= 0
                ? Math.min(retryOptions.retryDelayInMs, retryOptions.maxRetryDelayInMs
                    ? retryOptions.maxRetryDelayInMs
                    : DEFAULT_RETRY_OPTIONS.maxRetryDelayInMs)
                : DEFAULT_RETRY_OPTIONS.retryDelayInMs,
            maxRetryDelayInMs: retryOptions.maxRetryDelayInMs && retryOptions.maxRetryDelayInMs >= 0
                ? retryOptions.maxRetryDelayInMs
                : DEFAULT_RETRY_OPTIONS.maxRetryDelayInMs,
            secondaryHost: retryOptions.secondaryHost
                ? retryOptions.secondaryHost
                : DEFAULT_RETRY_OPTIONS.secondaryHost
        };
    }
    /**
     * Sends request.
     *
     * @param request -
     */
    async sendRequest(request) {
        return this.attemptSendRequest(request, false, 1);
    }
    /**
     * Decide and perform next retry. Won't mutate request parameter.
     *
     * @param request -
     * @param secondaryHas404 -  If attempt was against the secondary & it returned a StatusNotFound (404), then
     *                                   the resource was not found. This may be due to replication delay. So, in this
     *                                   case, we'll never try the secondary again for this operation.
     * @param attempt -           How many retries has been attempted to performed, starting from 1, which includes
     *                                   the attempt will be performed by this method call.
     */
    async attemptSendRequest(request, secondaryHas404, attempt) {
        const newRequest = request.clone();
        const isPrimaryRetry = secondaryHas404 ||
            !this.retryOptions.secondaryHost ||
            !(request.method === "GET" || request.method === "HEAD" || request.method === "OPTIONS") ||
            attempt % 2 === 1;
        if (!isPrimaryRetry) {
            newRequest.url = setURLHost(newRequest.url, this.retryOptions.secondaryHost);
        }
        // Set the server-side timeout query parameter "timeout=[seconds]"
        if (this.retryOptions.tryTimeoutInMs) {
            newRequest.url = setURLParameter(newRequest.url, UrlConstants.Parameters.TIMEOUT, Math.floor(this.retryOptions.tryTimeoutInMs / 1000).toString());
        }
        let response;
        try {
            logger.info(`RetryPolicy: =====> Try=${attempt} ${isPrimaryRetry ? "Primary" : "Secondary"}`);
            response = await this._nextPolicy.sendRequest(newRequest);
            if (!this.shouldRetry(isPrimaryRetry, attempt, response)) {
                return response;
            }
            secondaryHas404 = secondaryHas404 || (!isPrimaryRetry && response.status === 404);
        }
        catch (err) {
            logger.error(`RetryPolicy: Caught error, message: ${err.message}, code: ${err.code}`);
            if (!this.shouldRetry(isPrimaryRetry, attempt, response, err)) {
                throw err;
            }
        }
        await this.delay(isPrimaryRetry, attempt, request.abortSignal);
        return this.attemptSendRequest(request, secondaryHas404, ++attempt);
    }
    /**
     * Decide whether to retry according to last HTTP response and retry counters.
     *
     * @param isPrimaryRetry -
     * @param attempt -
     * @param response -
     * @param err -
     */
    shouldRetry(isPrimaryRetry, attempt, response, err) {
        if (attempt >= this.retryOptions.maxTries) {
            logger.info(`RetryPolicy: Attempt(s) ${attempt} >= maxTries ${this.retryOptions
                .maxTries}, no further try.`);
            return false;
        }
        // Handle network failures, you may need to customize the list when you implement
        // your own http client
        const retriableErrors = [
            "ETIMEDOUT",
            "ESOCKETTIMEDOUT",
            "ECONNREFUSED",
            "ECONNRESET",
            "ENOENT",
            "ENOTFOUND",
            "TIMEOUT",
            "EPIPE",
            "REQUEST_SEND_ERROR" // For default xhr based http client provided in ms-rest-js
        ];
        if (err) {
            for (const retriableError of retriableErrors) {
                if (err.name.toUpperCase().includes(retriableError) ||
                    err.message.toUpperCase().includes(retriableError) ||
                    (err.code && err.code.toString().toUpperCase() === retriableError)) {
                    logger.info(`RetryPolicy: Network error ${retriableError} found, will retry.`);
                    return true;
                }
            }
        }
        // If attempt was against the secondary & it returned a StatusNotFound (404), then
        // the resource was not found. This may be due to replication delay. So, in this
        // case, we'll never try the secondary again for this operation.
        if (response || err) {
            const statusCode = response ? response.status : err ? err.statusCode : 0;
            if (!isPrimaryRetry && statusCode === 404) {
                logger.info(`RetryPolicy: Secondary access with 404, will retry.`);
                return true;
            }
            // Server internal error or server timeout
            if (statusCode === 503 || statusCode === 500) {
                logger.info(`RetryPolicy: Will retry for status code ${statusCode}.`);
                return true;
            }
        }
        if ((err === null || err === void 0 ? void 0 : err.code) === "PARSE_ERROR" && (err === null || err === void 0 ? void 0 : err.message.startsWith(`Error "Error: Unclosed root tag`))) {
            logger.info("RetryPolicy: Incomplete XML response likely due to service timeout, will retry.");
            return true;
        }
        return false;
    }
    /**
     * Delay a calculated time between retries.
     *
     * @param isPrimaryRetry -
     * @param attempt -
     * @param abortSignal -
     */
    async delay(isPrimaryRetry, attempt, abortSignal) {
        let delayTimeInMs = 0;
        if (isPrimaryRetry) {
            switch (this.retryOptions.retryPolicyType) {
                case exports.StorageRetryPolicyType.EXPONENTIAL:
                    delayTimeInMs = Math.min((Math.pow(2, attempt - 1) - 1) * this.retryOptions.retryDelayInMs, this.retryOptions.maxRetryDelayInMs);
                    break;
                case exports.StorageRetryPolicyType.FIXED:
                    delayTimeInMs = this.retryOptions.retryDelayInMs;
                    break;
            }
        }
        else {
            delayTimeInMs = Math.random() * 1000;
        }
        logger.info(`RetryPolicy: Delay for ${delayTimeInMs}ms`);
        return delay(delayTimeInMs, abortSignal, RETRY_ABORT_ERROR);
    }
}

// Copyright (c) Microsoft Corporation.
/**
 * StorageRetryPolicyFactory is a factory class helping generating {@link StorageRetryPolicy} objects.
 */
class StorageRetryPolicyFactory {
    /**
     * Creates an instance of StorageRetryPolicyFactory.
     * @param retryOptions -
     */
    constructor(retryOptions) {
        this.retryOptions = retryOptions;
    }
    /**
     * Creates a StorageRetryPolicy object.
     *
     * @param nextPolicy -
     * @param options -
     */
    create(nextPolicy, options) {
        return new StorageRetryPolicy(nextPolicy, options, this.retryOptions);
    }
}

// Copyright (c) Microsoft Corporation.
/**
 * TelemetryPolicy is a policy used to tag user-agent header for every requests.
 */
class TelemetryPolicy extends coreHttp.BaseRequestPolicy {
    /**
     * Creates an instance of TelemetryPolicy.
     * @param nextPolicy -
     * @param options -
     * @param telemetry -
     */
    constructor(nextPolicy, options, telemetry) {
        super(nextPolicy, options);
        this.telemetry = telemetry;
    }
    /**
     * Sends out request.
     *
     * @param request -
     */
    async sendRequest(request) {
        {
            if (!request.headers) {
                request.headers = new coreHttp.HttpHeaders();
            }
            if (!request.headers.get(HeaderConstants.USER_AGENT)) {
                request.headers.set(HeaderConstants.USER_AGENT, this.telemetry);
            }
        }
        return this._nextPolicy.sendRequest(request);
    }
}

// Copyright (c) Microsoft Corporation.
/**
 * TelemetryPolicyFactory is a factory class helping generating {@link TelemetryPolicy} objects.
 */
class TelemetryPolicyFactory {
    /**
     * Creates an instance of TelemetryPolicyFactory.
     * @param telemetry -
     */
    constructor(telemetry) {
        const userAgentInfo = [];
        {
            if (telemetry) {
                const telemetryString = telemetry.userAgentPrefix || "";
                if (telemetryString.length > 0 && userAgentInfo.indexOf(telemetryString) === -1) {
                    userAgentInfo.push(telemetryString);
                }
            }
            // e.g. azsdk-js-storagedatalake/10.0.0
            const libInfo = `azsdk-js-storagedatalake/${SDK_VERSION}`;
            if (userAgentInfo.indexOf(libInfo) === -1) {
                userAgentInfo.push(libInfo);
            }
            // e.g. (NODE-VERSION 4.9.1; Windows_NT 10.0.16299)
            const runtimeInfo = `(NODE-VERSION ${process.version}; ${os.type()} ${os.release()})`;
            if (userAgentInfo.indexOf(runtimeInfo) === -1) {
                userAgentInfo.push(runtimeInfo);
            }
        }
        this.telemetryString = userAgentInfo.join(" ");
    }
    /**
     * Creates a TelemetryPolicy object.
     *
     * @param nextPolicy -
     * @param options -
     */
    create(nextPolicy, options) {
        return new TelemetryPolicy(nextPolicy, options, this.telemetryString);
    }
}

// Copyright (c) Microsoft Corporation.
const _defaultHttpClient = new coreHttp.DefaultHttpClient();
function getCachedDefaultHttpClient() {
    return _defaultHttpClient;
}

// Copyright (c) Microsoft Corporation.
/**
 * A Pipeline class containing HTTP request policies.
 * You can create a default Pipeline by calling {@link newPipeline}.
 * Or you can create a Pipeline with your own policies by the constructor of Pipeline.
 *
 * Refer to {@link newPipeline} and provided policies before implementing your
 * customized Pipeline.
 */
class Pipeline {
    /**
     * Creates an instance of Pipeline. Customize HTTPClient by implementing IHttpClient interface.
     *
     * @param factories -
     * @param options -
     */
    constructor(factories, options = {}) {
        this.factories = factories;
        // when options.httpClient is not specified, passing in a DefaultHttpClient instance to
        // avoid each client creating its own http client.
        this.options = Object.assign(Object.assign({}, options), { httpClient: options.httpClient || getCachedDefaultHttpClient() });
    }
    /**
     * Transfer Pipeline object to ServiceClientOptions object which is required by
     * ServiceClient constructor.
     *
     * @returns The ServiceClientOptions object from this Pipeline.
     */
    toServiceClientOptions() {
        return {
            httpClient: this.options.httpClient,
            requestPolicyFactories: this.factories
        };
    }
}
/**
 * Creates a new Pipeline object with Credential provided.
 *
 * @param credential -  Such as AnonymousCredential, StorageSharedKeyCredential or any credential from the `@azure/identity` package to authenticate requests to the service. You can also provide an object that implements the TokenCredential interface. If not specified, AnonymousCredential is used.
 * @param pipelineOptions - Optional. Options.
 * @returns A new Pipeline object.
 */
function newPipeline(credential, pipelineOptions = {}) {
    if (credential === undefined) {
        credential = new AnonymousCredential();
    }
    // Order is important. Closer to the API at the top & closer to the network at the bottom.
    // The credential's policy factory must appear close to the wire so it can sign any
    // changes made by other factories (like UniqueRequestIDPolicyFactory)
    const telemetryPolicy = new TelemetryPolicyFactory(pipelineOptions.userAgentOptions);
    const factories = [
        coreHttp.tracingPolicy({ userAgent: telemetryPolicy.telemetryString }),
        coreHttp.keepAlivePolicy(pipelineOptions.keepAliveOptions),
        telemetryPolicy,
        coreHttp.generateClientRequestIdPolicy(),
        new StorageBrowserPolicyFactory(),
        new StorageRetryPolicyFactory(pipelineOptions.retryOptions),
        coreHttp.deserializationPolicy(),
        coreHttp.logPolicy({
            logger: logger.info,
            allowedHeaderNames: StorageDataLakeLoggingAllowedHeaderNames,
            allowedQueryParameters: StorageDataLakeLoggingAllowedQueryParameters
        })
    ];
    {
        // policies only available in Node.js runtime, not in browsers
        factories.push(coreHttp.proxyPolicy(pipelineOptions.proxyOptions));
        factories.push(coreHttp.disableResponseDecompressionPolicy());
    }
    factories.push(coreHttp.isTokenCredential(credential)
        ? attachCredential(coreHttp.bearerTokenAuthenticationPolicy(credential, StorageOAuthScopes), credential)
        : credential);
    return new Pipeline(factories, pipelineOptions);
}
/**
 * Attach a TokenCredential to an object.
 *
 * @param thing -
 * @param credential -
 */
function attachCredential(thing, credential) {
    thing.credential = credential;
    return thing;
}

/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */
const packageName = "azure-storage-datalake";
const packageVersion = "12.7.0";
class StorageClientContext extends coreHttp.ServiceClient {
    /**
     * Initializes a new instance of the StorageClientContext class.
     * @param url The URL of the service account, container, or blob that is the target of the desired
     *            operation.
     * @param options The parameter options
     */
    constructor(url, options) {
        if (url === undefined) {
            throw new Error("'url' cannot be null");
        }
        // Initializing default values for options
        if (!options) {
            options = {};
        }
        if (!options.userAgent) {
            const defaultUserAgent = coreHttp.getDefaultUserAgentValue();
            options.userAgent = `${packageName}/${packageVersion} ${defaultUserAgent}`;
        }
        super(undefined, options);
        this.requestContentType = "application/json; charset=utf-8";
        this.baseUri = options.endpoint || "{url}";
        // Parameter assignments
        this.url = url;
        // Assigning values to Constant parameters
        this.version = options.version || "2020-10-02";
        this.resource = options.resource || "filesystem";
    }
}

// Copyright (c) Microsoft Corporation.
/**
 * Get a blob endpoint URL from incoming blob or dfs endpoint URLs.
 * Only handle known host name pair patterns, add more patterns into ToBlobEndpointHostMappings in constants.ts.
 *
 * Expected input and outputs:
 * http://account.blob.core.windows.net     - http://account.blob.core.windows.net
 * http://account.dfs.core.windows.net      - http://account.blob.core.windows.net
 * http://127.0.0.1:10000                   - http://127.0.0.1:10000
 * http://account.blob.core.windows.net/abc - http://account.blob.core.windows.net/abc
 * http://account.dfs.core.windows.net/abc  - http://account.blob.core.windows.net/abc
 * http://127.0.0.1:10000/abc               - http://127.0.0.1:10000/abc
 *
 * @param url -
 */
function toBlobEndpointUrl(url) {
    const urlParsed = coreHttp.URLBuilder.parse(url);
    let host = urlParsed.getHost();
    if (host === undefined) {
        throw RangeError(`toBlobEndpointUrl() parameter url ${url} doesn't include valid host.`);
    }
    for (const mapping of ToBlobEndpointHostMappings) {
        if (host.includes(mapping[0])) {
            host = host.replace(mapping[0], mapping[1]);
            break;
        }
    }
    urlParsed.setHost(host);
    return urlParsed.toString();
}
/**
 * Get a dfs endpoint URL from incoming blob or dfs endpoint URLs.
 * Only handle known host name pair patterns, add more patterns into ToDfsEndpointHostMappings in constants.ts.
 *
 * Expected input and outputs:
 * http://account.blob.core.windows.net     - http://account.dfs.core.windows.net
 * http://account.dfs.core.windows.net      - http://account.dfs.core.windows.net
 * http://127.0.0.1:10000                   - http://127.0.0.1:10000
 * http://account.blob.core.windows.net/abc - http://account.dfs.core.windows.net/abc
 * http://account.dfs.core.windows.net/abc  - http://account.dfs.core.windows.net/abc
 * http://127.0.0.1:10000/abc               - http://127.0.0.1:10000/abc
 *
 * @param url -
 */
function toDfsEndpointUrl(url) {
    const urlParsed = coreHttp.URLBuilder.parse(url);
    let host = urlParsed.getHost();
    if (host === undefined) {
        throw RangeError(`toDfsEndpointUrl() parameter url ${url} doesn't include valid host.`);
    }
    for (const mapping of ToDfsEndpointHostMappings) {
        if (host.includes(mapping[0])) {
            host = host.replace(mapping[0], mapping[1]);
            break;
        }
    }
    urlParsed.setHost(host);
    return urlParsed.toString();
}
function toFileSystemAsyncIterableIterator(iter) {
    return {
        async next() {
            const rawResult = await iter.next();
            if (rawResult.value) {
                rawResult.value.fileSystemItems = rawResult.value.containerItems.map((val) => {
                    return Object.assign(Object.assign({}, val), { versionId: val.version, properties: Object.assign(Object.assign({}, val.properties), { publicAccess: toPublicAccessType(val.properties.publicAccess) }) });
                });
            }
            return rawResult;
        },
        [Symbol.asyncIterator]() {
            return this;
        }
    };
}
function toFileSystemPagedAsyncIterableIterator(iter) {
    return {
        async next() {
            const rawResult = await iter.next();
            const result = rawResult;
            if (result.value) {
                result.value.properties.publicAccess = toPublicAccessType(rawResult.value.properties.publicAccess);
                result.value.versionId = rawResult.value.version;
            }
            return result;
        },
        [Symbol.asyncIterator]() {
            return this;
        },
        byPage(settings = {}) {
            return toFileSystemAsyncIterableIterator(iter.byPage(settings));
        }
    };
}
function toContainerPublicAccessType(publicAccessType) {
    if (!publicAccessType) {
        return undefined;
    }
    switch (publicAccessType) {
        case "filesystem":
            return "container";
        case "file":
            return "blob";
        default:
            throw TypeError(`toContainerPublicAccessType() parameter ${publicAccessType} is not recognized.`);
    }
}
function toPublicAccessType(containerPublicAccessType) {
    if (!containerPublicAccessType) {
        return undefined;
    }
    switch (containerPublicAccessType) {
        case "container":
            return "filesystem";
        case "blob":
            return "file";
        default:
            throw TypeError(`toPublicAccessType() parameter ${containerPublicAccessType} is not recognized.`);
    }
}
function toProperties(metadata) {
    if (metadata === undefined) {
        return undefined;
    }
    const properties = [];
    for (const key in metadata) {
        if (Object.prototype.hasOwnProperty.call(metadata, key)) {
            const value = metadata[key];
            properties.push(`${key}=${base64encode(value)}`);
        }
    }
    return properties.join(",");
}
function toPathGetAccessControlResponse(response) {
    return Object.assign(Object.assign({}, response), { _response: response._response, permissions: toPermissions(response.permissions), acl: toAcl(response.acl) });
}
function toRolePermissions(permissionsString, allowStickyBit = false) {
    const error = new RangeError(`toRolePermissions() Invalid role permissions string ${permissionsString}`);
    if (permissionsString.length !== 3) {
        throw error;
    }
    permissionsString = permissionsString.toLowerCase();
    let read = false;
    if (permissionsString[0] === "r") {
        read = true;
    }
    else if (permissionsString[0] !== "-") {
        throw error;
    }
    let write = false;
    if (permissionsString[1] === "w") {
        write = true;
    }
    else if (permissionsString[1] !== "-") {
        throw error;
    }
    let execute = false;
    if (permissionsString[2] === "x") {
        execute = true;
    }
    else if (allowStickyBit) {
        if (permissionsString[2] === "t") {
            execute = true;
        }
        else if (permissionsString[2] !== "-") {
            throw error;
        }
    }
    else if (permissionsString[2] !== "-") {
        throw error;
    }
    return { read, write, execute };
}
function toPermissions(permissionsString) {
    if (permissionsString === undefined || permissionsString === "" || permissionsString === null) {
        return undefined;
    }
    if (permissionsString.length !== 9 && permissionsString.length !== 10) {
        throw RangeError(`toPermissions() Invalid permissions string ${permissionsString}`);
    }
    // Case insensitive
    permissionsString = permissionsString.toLowerCase();
    let stickyBit = false;
    if (permissionsString[8] === "t") {
        stickyBit = true;
    }
    let extendedAcls = false;
    if (permissionsString.length === 10) {
        if (permissionsString[9] === "+") {
            extendedAcls = true;
        }
        else {
            throw RangeError(`toPermissions() Invalid extendedAcls bit ${permissionsString[9]} in permissions string ${permissionsString}`);
        }
    }
    const owner = toRolePermissions(permissionsString.substr(0, 3), false);
    const group = toRolePermissions(permissionsString.substr(3, 3), false);
    const other = toRolePermissions(permissionsString.substr(6, 3), true);
    return {
        owner,
        group,
        other,
        stickyBit,
        extendedAcls
    };
}
function toAccessControlItem(aclItemString) {
    const error = new RangeError(`toAccessControlItem() Parameter access control item string ${aclItemString} is not valid.`);
    if (aclItemString === "") {
        throw error;
    }
    aclItemString = aclItemString.toLowerCase();
    const parts = aclItemString.split(":");
    if (parts.length < 3 || parts.length > 4) {
        throw error;
    }
    let defaultScope = false;
    let index = 0;
    if (parts.length === 4) {
        if (parts[index] !== "default") {
            throw error;
        }
        defaultScope = true;
        index++;
    }
    const accessControlType = parts[index++];
    if (accessControlType !== "user" &&
        accessControlType !== "group" &&
        accessControlType !== "mask" &&
        accessControlType !== "other") {
        throw error;
    }
    const entityId = parts[index++];
    const permissions = toRolePermissions(parts[index++]);
    return {
        defaultScope,
        accessControlType,
        entityId,
        permissions
    };
}
function toAcl(aclString) {
    if (aclString === undefined || aclString === "" || aclString === null) {
        return [];
    }
    const acls = [];
    const aclParts = aclString.split(",");
    for (const aclPart of aclParts) {
        acls.push(toAccessControlItem(aclPart));
    }
    return acls;
}
function toAccessControlItemString(item) {
    const entityIdString = item.entityId !== undefined ? `:${item.entityId}` : "";
    const permissionsString = item.permissions !== undefined ? `:${toRolePermissionsString(item.permissions)}` : "";
    return `${item.defaultScope ? "default:" : ""}${item.accessControlType}${entityIdString}${permissionsString}`;
}
function toAclString(acl) {
    return acl.map(toAccessControlItemString).join(",");
}
function toRolePermissionsString(p, stickyBit = false) {
    return `${p.read ? "r" : "-"}${p.write ? "w" : "-"}${stickyBit ? "t" : p.execute ? "x" : "-"}`;
}
function toPermissionsString(permissions) {
    return `${toRolePermissionsString(permissions.owner)}${toRolePermissionsString(permissions.group)}${toRolePermissionsString(permissions.other, permissions.stickyBit)}${permissions.extendedAcls ? "+" : ""}`;
}
function toAccessControlChangeFailureArray(aclFailedEntries = []) {
    return aclFailedEntries.map((aclFailedEntry) => {
        return {
            name: aclFailedEntry.name || "",
            isDirectory: (aclFailedEntry.type || "").toLowerCase() === "directory",
            message: aclFailedEntry.errorMessage || ""
        };
    });
}

// Copyright (c) Microsoft Corporation.
/**
 * A StorageClient represents a based URL class for {@link BlobServiceClient}, {@link ContainerClient}
 * and etc.
 */
class StorageClient {
    /**
     * Creates an instance of StorageClient.
     * @param url - url to resource
     * @param pipeline - request policy pipeline.
     */
    constructor(url, pipeline) {
        // URL should be encoded and only once, protocol layer shouldn't encode URL again
        this.url = escapeURLPath(url);
        this.blobEndpointUrl = toBlobEndpointUrl(this.url);
        this.dfsEndpointUrl = toDfsEndpointUrl(this.url);
        this.accountName = getAccountNameFromUrl(this.blobEndpointUrl);
        this.pipeline = pipeline;
        this.storageClientContext = new StorageClientContext(this.dfsEndpointUrl, pipeline.toServiceClientOptions());
        this.storageClientContextToBlobEndpoint = new StorageClientContext(this.blobEndpointUrl, pipeline.toServiceClientOptions());
        this.isHttps = iEqual(getURLScheme(this.url) || "", "https");
        this.credential = new AnonymousCredential();
        for (const factory of this.pipeline.factories) {
            if ((coreHttp.isNode && factory instanceof StorageSharedKeyCredential) ||
                factory instanceof AnonymousCredential) {
                this.credential = factory;
            }
            else if (coreHttp.isTokenCredential(factory.credential)) {
                // Only works if the factory has been attached a "credential" property.
                // We do that in newPipeline() when using TokenCredential.
                this.credential = factory.credential;
            }
        }
        // Override protocol layer's default content-type
        const storageClientContext = this.storageClientContext;
        storageClientContext.requestContentType = undefined;
        const storageClientContextWithBlobEndpoint = this.storageClientContextToBlobEndpoint;
        storageClientContextWithBlobEndpoint.requestContentType = undefined;
    }
}

// Copyright (c) Microsoft Corporation.
/**
 * This class generates a readable stream from the data in an array of buffers.
 */
class BuffersStream extends stream.Readable {
    /**
     * Creates an instance of BuffersStream that will emit the data
     * contained in the array of buffers.
     *
     * @param buffers - Array of buffers containing the data
     * @param byteLength - The total length of data contained in the buffers
     */
    constructor(buffers, byteLength, options) {
        super(options);
        this.buffers = buffers;
        this.byteLength = byteLength;
        this.byteOffsetInCurrentBuffer = 0;
        this.bufferIndex = 0;
        this.pushedBytesLength = 0;
        // check byteLength is no larger than buffers[] total length
        let buffersLength = 0;
        for (const buf of this.buffers) {
            buffersLength += buf.byteLength;
        }
        if (buffersLength < this.byteLength) {
            throw new Error("Data size shouldn't be larger than the total length of buffers.");
        }
    }
    /**
     * Internal _read() that will be called when the stream wants to pull more data in.
     *
     * @param size - Optional. The size of data to be read
     */
    _read(size) {
        if (this.pushedBytesLength >= this.byteLength) {
            this.push(null);
        }
        if (!size) {
            size = this.readableHighWaterMark;
        }
        const outBuffers = [];
        let i = 0;
        while (i < size && this.pushedBytesLength < this.byteLength) {
            // The last buffer may be longer than the data it contains.
            const remainingDataInAllBuffers = this.byteLength - this.pushedBytesLength;
            const remainingCapacityInThisBuffer = this.buffers[this.bufferIndex].byteLength - this.byteOffsetInCurrentBuffer;
            const remaining = Math.min(remainingCapacityInThisBuffer, remainingDataInAllBuffers);
            if (remaining > size - i) {
                // chunkSize = size - i
                const end = this.byteOffsetInCurrentBuffer + size - i;
                outBuffers.push(this.buffers[this.bufferIndex].slice(this.byteOffsetInCurrentBuffer, end));
                this.pushedBytesLength += size - i;
                this.byteOffsetInCurrentBuffer = end;
                i = size;
                break;
            }
            else {
                // chunkSize = remaining
                const end = this.byteOffsetInCurrentBuffer + remaining;
                outBuffers.push(this.buffers[this.bufferIndex].slice(this.byteOffsetInCurrentBuffer, end));
                if (remaining === remainingCapacityInThisBuffer) {
                    // this.buffers[this.bufferIndex] used up, shift to next one
                    this.byteOffsetInCurrentBuffer = 0;
                    this.bufferIndex++;
                }
                else {
                    this.byteOffsetInCurrentBuffer = end;
                }
                this.pushedBytesLength += remaining;
                i += remaining;
            }
        }
        if (outBuffers.length > 1) {
            this.push(Buffer.concat(outBuffers));
        }
        else if (outBuffers.length === 1) {
            this.push(outBuffers[0]);
        }
    }
}

// Copyright (c) Microsoft Corporation.
/**
 * maxBufferLength is max size of each buffer in the pooled buffers.
 */
// Can't use import as Typescript doesn't recognize "buffer".
const maxBufferLength = require("buffer").constants.MAX_LENGTH;
/**
 * This class provides a buffer container which conceptually has no hard size limit.
 * It accepts a capacity, an array of input buffers and the total length of input data.
 * It will allocate an internal "buffer" of the capacity and fill the data in the input buffers
 * into the internal "buffer" serially with respect to the total length.
 * Then by calling PooledBuffer.getReadableStream(), you can get a readable stream
 * assembled from all the data in the internal "buffer".
 */
class PooledBuffer {
    constructor(capacity, buffers, totalLength) {
        /**
         * Internal buffers used to keep the data.
         * Each buffer has a length of the maxBufferLength except last one.
         */
        this.buffers = [];
        this.capacity = capacity;
        this._size = 0;
        // allocate
        const bufferNum = Math.ceil(capacity / maxBufferLength);
        for (let i = 0; i < bufferNum; i++) {
            let len = i === bufferNum - 1 ? capacity % maxBufferLength : maxBufferLength;
            if (len === 0) {
                len = maxBufferLength;
            }
            this.buffers.push(Buffer.allocUnsafe(len));
        }
        if (buffers) {
            this.fill(buffers, totalLength);
        }
    }
    /**
     * The size of the data contained in the pooled buffers.
     */
    get size() {
        return this._size;
    }
    /**
     * Fill the internal buffers with data in the input buffers serially
     * with respect to the total length and the total capacity of the internal buffers.
     * Data copied will be shift out of the input buffers.
     *
     * @param buffers - Input buffers containing the data to be filled in the pooled buffer
     * @param totalLength - Total length of the data to be filled in.
     *
     */
    fill(buffers, totalLength) {
        this._size = Math.min(this.capacity, totalLength);
        let i = 0, j = 0, targetOffset = 0, sourceOffset = 0, totalCopiedNum = 0;
        while (totalCopiedNum < this._size) {
            const source = buffers[i];
            const target = this.buffers[j];
            const copiedNum = source.copy(target, targetOffset, sourceOffset);
            totalCopiedNum += copiedNum;
            sourceOffset += copiedNum;
            targetOffset += copiedNum;
            if (sourceOffset === source.length) {
                i++;
                sourceOffset = 0;
            }
            if (targetOffset === target.length) {
                j++;
                targetOffset = 0;
            }
        }
        // clear copied from source buffers
        buffers.splice(0, i);
        if (buffers.length > 0) {
            buffers[0] = buffers[0].slice(sourceOffset);
        }
    }
    /**
     * Get the readable stream assembled from all the data in the internal buffers.
     *
     */
    getReadableStream() {
        return new BuffersStream(this.buffers, this.size);
    }
}

// Copyright (c) Microsoft Corporation.
/**
 * This class accepts a Node.js Readable stream as input, and keeps reading data
 * from the stream into the internal buffer structure, until it reaches maxBuffers.
 * Every available buffer will try to trigger outgoingHandler.
 *
 * The internal buffer structure includes an incoming buffer array, and a outgoing
 * buffer array. The incoming buffer array includes the "empty" buffers can be filled
 * with new incoming data. The outgoing array includes the filled buffers to be
 * handled by outgoingHandler. Every above buffer size is defined by parameter bufferSize.
 *
 * NUM_OF_ALL_BUFFERS = BUFFERS_IN_INCOMING + BUFFERS_IN_OUTGOING + BUFFERS_UNDER_HANDLING
 *
 * NUM_OF_ALL_BUFFERS lesser than or equal to maxBuffers
 *
 * PERFORMANCE IMPROVEMENT TIPS:
 * 1. Input stream highWaterMark is better to set a same value with bufferSize
 *    parameter, which will avoid Buffer.concat() operations.
 * 2. concurrency should set a smaller value than maxBuffers, which is helpful to
 *    reduce the possibility when a outgoing handler waits for the stream data.
 *    in this situation, outgoing handlers are blocked.
 *    Outgoing queue shouldn't be empty.
 */
class BufferScheduler {
    /**
     * Creates an instance of BufferScheduler.
     *
     * @param readable - A Node.js Readable stream
     * @param bufferSize - Buffer size of every maintained buffer
     * @param maxBuffers - How many buffers can be allocated
     * @param outgoingHandler - An async function scheduled to be
     *                                          triggered when a buffer fully filled
     *                                          with stream data
     * @param concurrency - Concurrency of executing outgoingHandlers (>0)
     * @param encoding - [Optional] Encoding of Readable stream when it's a string stream
     */
    constructor(readable, bufferSize, maxBuffers, outgoingHandler, concurrency, encoding) {
        /**
         * An internal event emitter.
         */
        this.emitter = new events.EventEmitter();
        /**
         * An internal offset marker to track data offset in bytes of next outgoingHandler.
         */
        this.offset = 0;
        /**
         * An internal marker to track whether stream is end.
         */
        this.isStreamEnd = false;
        /**
         * An internal marker to track whether stream or outgoingHandler returns error.
         */
        this.isError = false;
        /**
         * How many handlers are executing.
         */
        this.executingOutgoingHandlers = 0;
        /**
         * How many buffers have been allocated.
         */
        this.numBuffers = 0;
        /**
         * Because this class doesn't know how much data every time stream pops, which
         * is defined by highWaterMarker of the stream. So BufferScheduler will cache
         * data received from the stream, when data in unresolvedDataArray exceeds the
         * blockSize defined, it will try to concat a blockSize of buffer, fill into available
         * buffers from incoming and push to outgoing array.
         */
        this.unresolvedDataArray = [];
        /**
         * How much data consisted in unresolvedDataArray.
         */
        this.unresolvedLength = 0;
        /**
         * The array includes all the available buffers can be used to fill data from stream.
         */
        this.incoming = [];
        /**
         * The array (queue) includes all the buffers filled from stream data.
         */
        this.outgoing = [];
        if (bufferSize <= 0) {
            throw new RangeError(`bufferSize must be larger than 0, current is ${bufferSize}`);
        }
        if (maxBuffers <= 0) {
            throw new RangeError(`maxBuffers must be larger than 0, current is ${maxBuffers}`);
        }
        if (concurrency <= 0) {
            throw new RangeError(`concurrency must be larger than 0, current is ${concurrency}`);
        }
        this.bufferSize = bufferSize;
        this.maxBuffers = maxBuffers;
        this.readable = readable;
        this.outgoingHandler = outgoingHandler;
        this.concurrency = concurrency;
        this.encoding = encoding;
    }
    /**
     * Start the scheduler, will return error when stream of any of the outgoingHandlers
     * returns error.
     *
     */
    async do() {
        return new Promise((resolve, reject) => {
            this.readable.on("data", (data) => {
                data = typeof data === "string" ? Buffer.from(data, this.encoding) : data;
                this.appendUnresolvedData(data);
                if (!this.resolveData()) {
                    this.readable.pause();
                }
            });
            this.readable.on("error", (err) => {
                this.emitter.emit("error", err);
            });
            this.readable.on("end", () => {
                this.isStreamEnd = true;
                this.emitter.emit("checkEnd");
            });
            this.emitter.on("error", (err) => {
                this.isError = true;
                this.readable.pause();
                reject(err);
            });
            this.emitter.on("checkEnd", () => {
                if (this.outgoing.length > 0) {
                    this.triggerOutgoingHandlers();
                    return;
                }
                if (this.isStreamEnd && this.executingOutgoingHandlers === 0) {
                    if (this.unresolvedLength > 0 && this.unresolvedLength < this.bufferSize) {
                        const buffer = this.shiftBufferFromUnresolvedDataArray();
                        this.outgoingHandler(() => buffer.getReadableStream(), buffer.size, this.offset)
                            .then(resolve)
                            .catch(reject);
                    }
                    else if (this.unresolvedLength >= this.bufferSize) {
                        return;
                    }
                    else {
                        resolve();
                    }
                }
            });
        });
    }
    /**
     * Insert a new data into unresolved array.
     *
     * @param data -
     */
    appendUnresolvedData(data) {
        this.unresolvedDataArray.push(data);
        this.unresolvedLength += data.length;
    }
    /**
     * Try to shift a buffer with size in blockSize. The buffer returned may be less
     * than blockSize when data in unresolvedDataArray is less than bufferSize.
     *
     */
    shiftBufferFromUnresolvedDataArray(buffer) {
        if (!buffer) {
            buffer = new PooledBuffer(this.bufferSize, this.unresolvedDataArray, this.unresolvedLength);
        }
        else {
            buffer.fill(this.unresolvedDataArray, this.unresolvedLength);
        }
        this.unresolvedLength -= buffer.size;
        return buffer;
    }
    /**
     * Resolve data in unresolvedDataArray. For every buffer with size in blockSize
     * shifted, it will try to get (or allocate a buffer) from incoming, and fill it,
     * then push it into outgoing to be handled by outgoing handler.
     *
     * Return false when available buffers in incoming are not enough, else true.
     *
     * @returns Return false when buffers in incoming are not enough, else true.
     */
    resolveData() {
        while (this.unresolvedLength >= this.bufferSize) {
            let buffer;
            if (this.incoming.length > 0) {
                buffer = this.incoming.shift();
                this.shiftBufferFromUnresolvedDataArray(buffer);
            }
            else {
                if (this.numBuffers < this.maxBuffers) {
                    buffer = this.shiftBufferFromUnresolvedDataArray();
                    this.numBuffers++;
                }
                else {
                    // No available buffer, wait for buffer returned
                    return false;
                }
            }
            this.outgoing.push(buffer);
            this.triggerOutgoingHandlers();
        }
        return true;
    }
    /**
     * Try to trigger a outgoing handler for every buffer in outgoing. Stop when
     * concurrency reaches.
     */
    async triggerOutgoingHandlers() {
        let buffer;
        do {
            if (this.executingOutgoingHandlers >= this.concurrency) {
                return;
            }
            buffer = this.outgoing.shift();
            if (buffer) {
                this.triggerOutgoingHandler(buffer);
            }
        } while (buffer);
    }
    /**
     * Trigger a outgoing handler for a buffer shifted from outgoing.
     *
     * @param buffer -
     */
    async triggerOutgoingHandler(buffer) {
        const bufferLength = buffer.size;
        this.executingOutgoingHandlers++;
        this.offset += bufferLength;
        try {
            await this.outgoingHandler(() => buffer.getReadableStream(), bufferLength, this.offset - bufferLength);
        }
        catch (err) {
            this.emitter.emit("error", err);
            return;
        }
        this.executingOutgoingHandlers--;
        this.reuseBuffer(buffer);
        this.emitter.emit("checkEnd");
    }
    /**
     * Return buffer used by outgoing handler into incoming.
     *
     * @param buffer -
     */
    reuseBuffer(buffer) {
        this.incoming.push(buffer);
        if (!this.isError && this.resolveData() && !this.isStreamEnd) {
            this.readable.resume();
        }
    }
}

// Copyright (c) Microsoft Corporation.
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * UserDelegationKeyCredential is only used for generation of user delegation SAS.
 * @see https://docs.microsoft.com/en-us/rest/api/storageservices/create-user-delegation-sas
 */
class UserDelegationKeyCredential {
    /**
     * Creates an instance of UserDelegationKeyCredential.
     * @param accountName -
     * @param userDelegationKey -
     */
    constructor(accountName, userDelegationKey) {
        this.accountName = accountName;
        this.userDelegationKey = userDelegationKey;
        this.key = Buffer.from(userDelegationKey.value, "base64");
    }
    /**
     * Generates a hash signature for an HTTP request or for a SAS.
     *
     * @param stringToSign -
     */
    computeHMACSHA256(stringToSign) {
        // console.log(`stringToSign: ${JSON.stringify(stringToSign)}`);
        return crypto.createHmac("sha256", this.key)
            .update(stringToSign, "utf8")
            .digest("base64");
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * This is a helper class to construct a string representing the permissions granted by a ServiceSAS. Setting
 * a value to true means that any SAS which uses these permissions will grant permissions for that operation. Once all
 * the values are set, this should be serialized with toString and set as the permissions field on a
 * {@link DataLakeSASSignatureValues} object. It is possible to construct the permissions string without this class, but
 * the order of the permissions is particular and this class guarantees correctness.
 */
class DataLakeSASPermissions {
    constructor() {
        /**
         * Specifies Read access granted.
         */
        this.read = false;
        /**
         * Specifies Add access granted.
         */
        this.add = false;
        /**
         * Specifies Create access granted.
         */
        this.create = false;
        /**
         * Specifies Write access granted.
         */
        this.write = false;
        /**
         * Specifies Delete access granted.
         */
        this.delete = false;
        /**
         * Specifies Move access granted.
         */
        this.move = false;
        /**
         * Specifies Execute access granted.
         */
        this.execute = false;
        /**
         * Specifies Ownership access granted, which allows the caller to set owner, owning group,
         * or act as the owner when renaming or deleting a blob (file or directory) within a folder
         * that has the sticky bit set.
         */
        this.manageOwnership = false;
        /**
         * Specifies Permission access granted, which allows the caller to set permissions and
         * POSIX ACLs on blobs (files and directories).
         */
        this.manageAccessControl = false;
    }
    /**
     * Creates a {@link DataLakeSASPermissions} from the specified permissions string. This method will throw an
     * Error if it encounters a character that does not correspond to a valid permission.
     *
     * @param permissions -
     */
    static parse(permissions) {
        const blobSASPermissions = new DataLakeSASPermissions();
        for (const char of permissions) {
            switch (char) {
                case "r":
                    blobSASPermissions.read = true;
                    break;
                case "a":
                    blobSASPermissions.add = true;
                    break;
                case "c":
                    blobSASPermissions.create = true;
                    break;
                case "w":
                    blobSASPermissions.write = true;
                    break;
                case "d":
                    blobSASPermissions.delete = true;
                    break;
                case "m":
                    blobSASPermissions.move = true;
                    break;
                case "e":
                    blobSASPermissions.execute = true;
                    break;
                case "o":
                    blobSASPermissions.manageOwnership = true;
                    break;
                case "p":
                    blobSASPermissions.manageAccessControl = true;
                    break;
                default:
                    throw new RangeError(`Invalid permission: ${char}`);
            }
        }
        return blobSASPermissions;
    }
    /**
     * Converts the given permissions to a string. Using this method will guarantee the permissions are in an
     * order accepted by the service.
     *
     * @returns A string which represents the DataLakeSASPermissions
     */
    toString() {
        const permissions = [];
        if (this.read) {
            permissions.push("r");
        }
        if (this.add) {
            permissions.push("a");
        }
        if (this.create) {
            permissions.push("c");
        }
        if (this.write) {
            permissions.push("w");
        }
        if (this.delete) {
            permissions.push("d");
        }
        if (this.move) {
            permissions.push("m");
        }
        if (this.execute) {
            permissions.push("e");
        }
        if (this.manageOwnership) {
            permissions.push("o");
        }
        if (this.manageAccessControl) {
            permissions.push("p");
        }
        return permissions.join("");
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * This is a helper class to construct a string representing the permissions granted by a ServiceSAS to a container.
 * Setting a value to true means that any SAS which uses these permissions will grant permissions for that operation.
 * Once all the values are set, this should be serialized with toString and set as the permissions field on a
 * {@link DataLakeSASSignatureValues} object. It is possible to construct the permissions string without this class, but
 * the order of the permissions is particular and this class guarantees correctness.
 */
class FileSystemSASPermissions {
    constructor() {
        /**
         * Specifies Read access granted.
         */
        this.read = false;
        /**
         * Specifies Add access granted.
         */
        this.add = false;
        /**
         * Specifies Create access granted.
         */
        this.create = false;
        /**
         * Specifies Write access granted.
         */
        this.write = false;
        /**
         * Specifies Delete access granted.
         */
        this.delete = false;
        /**
         * Specifies List access granted.
         */
        this.list = false;
        /**
         * Specifies Move access granted.
         */
        this.move = false;
        /**
         * Specifies Execute access granted.
         */
        this.execute = false;
        /**
         * Specifies Ownership access granted, which allows the caller to set owner, owning group,
         * or act as the owner when renaming or deleting a blob (file or directory) within a folder
         * that has the sticky bit set.
         */
        this.manageOwnership = false;
        /**
         * Specifies Permission access granted, which allows the caller to set permissions and
         * POSIX ACLs on blobs (files and directories).
         */
        this.manageAccessControl = false;
    }
    /**
     * Creates an {@link FileSystemSASPermissions} from the specified permissions string. This method will throw an
     * Error if it encounters a character that does not correspond to a valid permission.
     *
     * @param permissions -
     */
    static parse(permissions) {
        const containerSASPermissions = new FileSystemSASPermissions();
        for (const char of permissions) {
            switch (char) {
                case "r":
                    containerSASPermissions.read = true;
                    break;
                case "a":
                    containerSASPermissions.add = true;
                    break;
                case "c":
                    containerSASPermissions.create = true;
                    break;
                case "w":
                    containerSASPermissions.write = true;
                    break;
                case "d":
                    containerSASPermissions.delete = true;
                    break;
                case "l":
                    containerSASPermissions.list = true;
                    break;
                case "m":
                    containerSASPermissions.move = true;
                    break;
                case "e":
                    containerSASPermissions.execute = true;
                    break;
                case "o":
                    containerSASPermissions.manageOwnership = true;
                    break;
                case "p":
                    containerSASPermissions.manageAccessControl = true;
                    break;
                default:
                    throw new RangeError(`Invalid permission ${char}`);
            }
        }
        return containerSASPermissions;
    }
    /**
     * Converts the given permissions to a string. Using this method will guarantee the permissions are in an
     * order accepted by the service.
     *
     * The order of the characters should be as specified here to ensure correctness.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas
     *
     */
    toString() {
        const permissions = [];
        if (this.read) {
            permissions.push("r");
        }
        if (this.add) {
            permissions.push("a");
        }
        if (this.create) {
            permissions.push("c");
        }
        if (this.write) {
            permissions.push("w");
        }
        if (this.delete) {
            permissions.push("d");
        }
        if (this.list) {
            permissions.push("l");
        }
        if (this.move) {
            permissions.push("m");
        }
        if (this.execute) {
            permissions.push("e");
        }
        if (this.manageOwnership) {
            permissions.push("o");
        }
        if (this.manageAccessControl) {
            permissions.push("p");
        }
        return permissions.join("");
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * Generate SasIPRange format string. For example:
 *
 * "8.8.8.8" or "1.1.1.1-255.255.255.255"
 *
 * @param ipRange -
 */
function ipRangeToString(ipRange) {
    return ipRange.end ? `${ipRange.start}-${ipRange.end}` : ipRange.start;
}

(function (SASProtocol) {
    /**
     * Protocol that allows HTTPS only
     */
    SASProtocol["Https"] = "https";
    /**
     * Protocol that allows both HTTPS and HTTP
     */
    SASProtocol["HttpsAndHttp"] = "https,http";
})(exports.SASProtocol || (exports.SASProtocol = {}));
/**
 * Represents the components that make up an Azure Storage SAS' query parameters. This type is not constructed directly
 * by the user; it is only generated by the {@link AccountSASSignatureValues} and {@link BlobSASSignatureValues}
 * types. Once generated, it can be encoded into a {@link String} and appended to a URL directly (though caution should
 * be taken here in case there are existing query parameters, which might affect the appropriate means of appending
 * these query parameters).
 *
 * NOTE: Instances of this class are immutable.
 */
class SASQueryParameters {
    constructor(version, signature, permissionsOrOptions, services, resourceTypes, protocol, startsOn, expiresOn, ipRange, identifier, resource, cacheControl, contentDisposition, contentEncoding, contentLanguage, contentType, userDelegationKey, directoryDepth, preauthorizedAgentObjectId, agentObjectId, correlationId) {
        this.version = version;
        this.signature = signature;
        if (permissionsOrOptions !== undefined && typeof permissionsOrOptions !== "string") {
            // SASQueryParametersOptions
            const options = permissionsOrOptions;
            this.services = options.services;
            this.resourceTypes = options.resourceTypes;
            this.expiresOn = options.expiresOn;
            this.permissions = options.permissions;
            this.protocol = options.protocol;
            this.startsOn = options.startsOn;
            this.ipRangeInner = options.ipRange;
            this.identifier = options.identifier;
            this.resource = options.resource;
            this.cacheControl = options.cacheControl;
            this.contentDisposition = options.contentDisposition;
            this.contentEncoding = options.contentEncoding;
            this.contentLanguage = options.contentLanguage;
            this.contentType = options.contentType;
            this.directoryDepth = options.directoryDepth;
            this.preauthorizedAgentObjectId = options.preauthorizedAgentObjectId;
            this.agentObjectId = options.agentObjectId;
            this.correlationId = options.correlationId;
            if (options.userDelegationKey) {
                this.signedOid = options.userDelegationKey.signedObjectId;
                this.signedTenantId = options.userDelegationKey.signedTenantId;
                this.signedStartsOn = options.userDelegationKey.signedStartsOn;
                this.signedExpiresOn = options.userDelegationKey.signedExpiresOn;
                this.signedService = options.userDelegationKey.signedService;
                this.signedVersion = options.userDelegationKey.signedVersion;
            }
        }
        else {
            this.services = services;
            this.resourceTypes = resourceTypes;
            this.expiresOn = expiresOn;
            this.permissions = permissionsOrOptions;
            this.protocol = protocol;
            this.startsOn = startsOn;
            this.ipRangeInner = ipRange;
            this.identifier = identifier;
            this.resource = resource;
            this.cacheControl = cacheControl;
            this.contentDisposition = contentDisposition;
            this.contentEncoding = contentEncoding;
            this.contentLanguage = contentLanguage;
            this.contentType = contentType;
            this.directoryDepth = directoryDepth;
            this.preauthorizedAgentObjectId = preauthorizedAgentObjectId;
            this.agentObjectId = agentObjectId;
            this.correlationId = correlationId;
            if (userDelegationKey) {
                this.signedOid = userDelegationKey.signedObjectId;
                this.signedTenantId = userDelegationKey.signedTenantId;
                this.signedStartsOn = userDelegationKey.signedStartsOn;
                this.signedExpiresOn = userDelegationKey.signedExpiresOn;
                this.signedService = userDelegationKey.signedService;
                this.signedVersion = userDelegationKey.signedVersion;
            }
        }
    }
    /**
     * Optional. IP range allowed for this SAS.
     *
     * @readonly
     */
    get ipRange() {
        if (this.ipRangeInner) {
            return {
                end: this.ipRangeInner.end,
                start: this.ipRangeInner.start
            };
        }
        return undefined;
    }
    /**
     * Encodes all SAS query parameters into a string that can be appended to a URL.
     *
     */
    toString() {
        var _a;
        const params = [
            "sv",
            "ss",
            "srt",
            "spr",
            "st",
            "se",
            "sip",
            "si",
            "skoid",
            "sktid",
            "skt",
            "ske",
            "sks",
            "skv",
            "sr",
            "sp",
            "sig",
            "rscc",
            "rscd",
            "rsce",
            "rscl",
            "rsct",
            "sdd",
            "saoid",
            "suoid",
            "scid"
        ];
        const queries = [];
        for (const param of params) {
            switch (param) {
                case "sv":
                    this.tryAppendQueryParameter(queries, param, this.version);
                    break;
                case "ss":
                    this.tryAppendQueryParameter(queries, param, this.services);
                    break;
                case "srt":
                    this.tryAppendQueryParameter(queries, param, this.resourceTypes);
                    break;
                case "spr":
                    this.tryAppendQueryParameter(queries, param, this.protocol);
                    break;
                case "st":
                    this.tryAppendQueryParameter(queries, param, this.startsOn ? truncatedISO8061Date(this.startsOn, false) : undefined);
                    break;
                case "se":
                    this.tryAppendQueryParameter(queries, param, this.expiresOn ? truncatedISO8061Date(this.expiresOn, false) : undefined);
                    break;
                case "sip":
                    this.tryAppendQueryParameter(queries, param, this.ipRange ? ipRangeToString(this.ipRange) : undefined);
                    break;
                case "si":
                    this.tryAppendQueryParameter(queries, param, this.identifier);
                    break;
                case "skoid": // Signed object ID
                    this.tryAppendQueryParameter(queries, param, this.signedOid);
                    break;
                case "sktid": // Signed tenant ID
                    this.tryAppendQueryParameter(queries, param, this.signedTenantId);
                    break;
                case "skt": // Signed key start time
                    this.tryAppendQueryParameter(queries, param, this.signedStartsOn ? truncatedISO8061Date(this.signedStartsOn, false) : undefined);
                    break;
                case "ske": // Signed key expiry time
                    this.tryAppendQueryParameter(queries, param, this.signedExpiresOn ? truncatedISO8061Date(this.signedExpiresOn, false) : undefined);
                    break;
                case "sks": // Signed key service
                    this.tryAppendQueryParameter(queries, param, this.signedService);
                    break;
                case "skv": // Signed key version
                    this.tryAppendQueryParameter(queries, param, this.signedVersion);
                    break;
                case "sr":
                    this.tryAppendQueryParameter(queries, param, this.resource);
                    break;
                case "sp":
                    this.tryAppendQueryParameter(queries, param, this.permissions);
                    break;
                case "sig":
                    this.tryAppendQueryParameter(queries, param, this.signature);
                    break;
                case "rscc":
                    this.tryAppendQueryParameter(queries, param, this.cacheControl);
                    break;
                case "rscd":
                    this.tryAppendQueryParameter(queries, param, this.contentDisposition);
                    break;
                case "rsce":
                    this.tryAppendQueryParameter(queries, param, this.contentEncoding);
                    break;
                case "rscl":
                    this.tryAppendQueryParameter(queries, param, this.contentLanguage);
                    break;
                case "rsct":
                    this.tryAppendQueryParameter(queries, param, this.contentType);
                    break;
                case "sdd":
                    this.tryAppendQueryParameter(queries, param, (_a = this.directoryDepth) === null || _a === void 0 ? void 0 : _a.toString());
                    break;
                case "saoid":
                    this.tryAppendQueryParameter(queries, param, this.preauthorizedAgentObjectId);
                    break;
                case "suoid":
                    this.tryAppendQueryParameter(queries, param, this.agentObjectId);
                    break;
                case "scid":
                    this.tryAppendQueryParameter(queries, param, this.correlationId);
                    break;
            }
        }
        return queries.join("&");
    }
    /**
     * A private helper method used to filter and append query key/value pairs into an array.
     *
     * @param queries -
     * @param key -
     * @param value -
     */
    tryAppendQueryParameter(queries, key, value) {
        if (!value) {
            return;
        }
        key = encodeURIComponent(key);
        value = encodeURIComponent(value);
        if (key.length > 0 && value.length > 0) {
            queries.push(`${key}=${value}`);
        }
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * This is a helper class to construct a string representing the permissions granted by a ServiceSAS to a directory.
 * Setting a value to true means that any SAS which uses these permissions will grant permissions for that operation.
 * Once all the values are set, this should be serialized with toString and set as the permissions field on a
 * {@link DataLakeSASSignatureValues} object. It is possible to construct the permissions string without this class, but
 * the order of the permissions is particular and this class guarantees correctness.
 */
class DirectorySASPermissions {
    constructor() {
        /**
         * Specifies Read access granted.
         */
        this.read = false;
        /**
         * Specifies Add access granted.
         */
        this.add = false;
        /**
         * Specifies Create access granted.
         */
        this.create = false;
        /**
         * Specifies Write access granted.
         */
        this.write = false;
        /**
         * Specifies Delete access granted.
         */
        this.delete = false;
        /**
         * Specifies List access granted.
         */
        this.list = false;
        /**
         * Specifies Move access granted.
         */
        this.move = false;
        /**
         * Specifies Execute access granted.
         */
        this.execute = false;
        /**
         * Specifies Ownership access granted, which allows the caller to set owner, owning group,
         * or act as the owner when renaming or deleting a blob (file or directory) within a folder
         * that has the sticky bit set.
         */
        this.manageOwnership = false;
        /**
         * Specifies Permission access granted, which allows the caller to set permissions and
         * POSIX ACLs on blobs (files and directories).
         */
        this.manageAccessControl = false;
    }
    /**
     * Creates an {@link DirectorySASPermissions} from the specified permissions string. This method will throw an
     * Error if it encounters a character that does not correspond to a valid permission.
     *
     * @param permissions -
     */
    static parse(permissions) {
        const directorySASPermissions = new DirectorySASPermissions();
        for (const char of permissions) {
            switch (char) {
                case "r":
                    directorySASPermissions.read = true;
                    break;
                case "a":
                    directorySASPermissions.add = true;
                    break;
                case "c":
                    directorySASPermissions.create = true;
                    break;
                case "w":
                    directorySASPermissions.write = true;
                    break;
                case "d":
                    directorySASPermissions.delete = true;
                    break;
                case "l":
                    directorySASPermissions.list = true;
                    break;
                case "m":
                    directorySASPermissions.move = true;
                    break;
                case "e":
                    directorySASPermissions.execute = true;
                    break;
                case "o":
                    directorySASPermissions.manageOwnership = true;
                    break;
                case "p":
                    directorySASPermissions.manageAccessControl = true;
                    break;
                default:
                    throw new RangeError(`Invalid permission ${char}`);
            }
        }
        return directorySASPermissions;
    }
    /**
     * Converts the given permissions to a string. Using this method will guarantee the permissions are in an
     * order accepted by the service.
     *
     * The order of the characters should be as specified here to ensure correctness.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas
     *
     */
    toString() {
        const permissions = [];
        if (this.read) {
            permissions.push("r");
        }
        if (this.add) {
            permissions.push("a");
        }
        if (this.create) {
            permissions.push("c");
        }
        if (this.write) {
            permissions.push("w");
        }
        if (this.delete) {
            permissions.push("d");
        }
        if (this.list) {
            permissions.push("l");
        }
        if (this.move) {
            permissions.push("m");
        }
        if (this.execute) {
            permissions.push("e");
        }
        if (this.manageOwnership) {
            permissions.push("o");
        }
        if (this.manageAccessControl) {
            permissions.push("p");
        }
        return permissions.join("");
    }
}

// Copyright (c) Microsoft Corporation.
function generateDataLakeSASQueryParameters(dataLakeSASSignatureValues, sharedKeyCredentialOrUserDelegationKey, accountName) {
    const version = dataLakeSASSignatureValues.version
        ? dataLakeSASSignatureValues.version
        : SERVICE_VERSION;
    const sharedKeyCredential = sharedKeyCredentialOrUserDelegationKey instanceof StorageSharedKeyCredential
        ? sharedKeyCredentialOrUserDelegationKey
        : undefined;
    let userDelegationKeyCredential;
    if (sharedKeyCredential === undefined && accountName !== undefined) {
        userDelegationKeyCredential = new UserDelegationKeyCredential(accountName, sharedKeyCredentialOrUserDelegationKey);
    }
    if (sharedKeyCredential === undefined && userDelegationKeyCredential === undefined) {
        throw TypeError("Invalid sharedKeyCredential, userDelegationKey or accountName.");
    }
    // Version 2018-11-09 adds support for the signed resource and signed blob snapshot time fields.
    // https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas#constructing-the-signature-string
    if (version >= "2018-11-09") {
        if (sharedKeyCredential !== undefined) {
            return generateBlobSASQueryParameters20181109(dataLakeSASSignatureValues, sharedKeyCredential);
        }
        else {
            // Version 2020-02-10 delegation SAS signature construction includes preauthorizedAgentObjectId, agentObjectId, correlationId.
            if (version >= "2020-02-10") {
                return generateBlobSASQueryParametersUDK20200210(dataLakeSASSignatureValues, userDelegationKeyCredential);
            }
            else {
                return generateBlobSASQueryParametersUDK20181109(dataLakeSASSignatureValues, userDelegationKeyCredential);
            }
        }
    }
    if (version >= "2015-04-05") {
        if (sharedKeyCredential !== undefined) {
            return generateBlobSASQueryParameters20150405(dataLakeSASSignatureValues, sharedKeyCredential);
        }
        else {
            throw new RangeError("'version' must be >= '2018-11-09' when generating user delegation SAS using user delegation key.");
        }
    }
    throw new RangeError("'version' must be >= '2015-04-05'.");
}
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 * IMPLEMENTATION FOR API VERSION FROM 2015-04-05 AND BEFORE 2018-11-09.
 *
 * Creates an instance of SASQueryParameters.
 *
 * Only accepts required settings needed to create a SAS. For optional settings please
 * set corresponding properties directly, such as permissions, startsOn and identifier.
 *
 * WARNING: When identifier is not provided, permissions and expiresOn are required.
 * You MUST assign value to identifier or expiresOn & permissions manually if you initial with
 * this constructor.
 *
 * @param dataLakeSASSignatureValues -
 * @param sharedKeyCredential -
 */
function generateBlobSASQueryParameters20150405(dataLakeSASSignatureValues, sharedKeyCredential) {
    if (!dataLakeSASSignatureValues.identifier &&
        !(dataLakeSASSignatureValues.permissions && dataLakeSASSignatureValues.expiresOn)) {
        throw new RangeError("Must provide 'permissions' and 'expiresOn' for DataLake SAS generation when 'identifier' is not provided.");
    }
    const version = dataLakeSASSignatureValues.version
        ? dataLakeSASSignatureValues.version
        : SERVICE_VERSION;
    dataLakeSASSignatureValues = SASSignatureValuesSanityCheckAndAutofill(dataLakeSASSignatureValues, version);
    let resource = "c";
    if (dataLakeSASSignatureValues.pathName) {
        resource = "b";
    }
    // Calling parse and toString guarantees the proper ordering and throws on invalid characters.
    let verifiedPermissions;
    if (dataLakeSASSignatureValues.permissions) {
        if (dataLakeSASSignatureValues.pathName) {
            verifiedPermissions = DataLakeSASPermissions.parse(dataLakeSASSignatureValues.permissions.toString()).toString();
        }
        else {
            verifiedPermissions = FileSystemSASPermissions.parse(dataLakeSASSignatureValues.permissions.toString()).toString();
        }
    }
    // Signature is generated on the un-url-encoded values.
    const stringToSign = [
        verifiedPermissions ? verifiedPermissions : "",
        dataLakeSASSignatureValues.startsOn
            ? truncatedISO8061Date(dataLakeSASSignatureValues.startsOn, false)
            : "",
        dataLakeSASSignatureValues.expiresOn
            ? truncatedISO8061Date(dataLakeSASSignatureValues.expiresOn, false)
            : "",
        getCanonicalName(sharedKeyCredential.accountName, dataLakeSASSignatureValues.fileSystemName, dataLakeSASSignatureValues.pathName),
        dataLakeSASSignatureValues.identifier,
        dataLakeSASSignatureValues.ipRange ? ipRangeToString(dataLakeSASSignatureValues.ipRange) : "",
        dataLakeSASSignatureValues.protocol ? dataLakeSASSignatureValues.protocol : "",
        version,
        dataLakeSASSignatureValues.cacheControl ? dataLakeSASSignatureValues.cacheControl : "",
        dataLakeSASSignatureValues.contentDisposition
            ? dataLakeSASSignatureValues.contentDisposition
            : "",
        dataLakeSASSignatureValues.contentEncoding ? dataLakeSASSignatureValues.contentEncoding : "",
        dataLakeSASSignatureValues.contentLanguage ? dataLakeSASSignatureValues.contentLanguage : "",
        dataLakeSASSignatureValues.contentType ? dataLakeSASSignatureValues.contentType : ""
    ].join("\n");
    const signature = sharedKeyCredential.computeHMACSHA256(stringToSign);
    return new SASQueryParameters(version, signature, verifiedPermissions, undefined, undefined, dataLakeSASSignatureValues.protocol, dataLakeSASSignatureValues.startsOn, dataLakeSASSignatureValues.expiresOn, dataLakeSASSignatureValues.ipRange, dataLakeSASSignatureValues.identifier, resource, dataLakeSASSignatureValues.cacheControl, dataLakeSASSignatureValues.contentDisposition, dataLakeSASSignatureValues.contentEncoding, dataLakeSASSignatureValues.contentLanguage, dataLakeSASSignatureValues.contentType);
}
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 * IMPLEMENTATION FOR API VERSION FROM 2018-11-09.
 *
 * Creates an instance of SASQueryParameters.
 *
 * Only accepts required settings needed to create a SAS. For optional settings please
 * set corresponding properties directly, such as permissions, startsOn and identifier.
 *
 * WARNING: When identifier is not provided, permissions and expiresOn are required.
 * You MUST assign value to identifier or expiresOn & permissions manually if you initial with
 * this constructor.
 *
 * @param dataLakeSASSignatureValues -
 * @param sharedKeyCredential -
 */
function generateBlobSASQueryParameters20181109(dataLakeSASSignatureValues, sharedKeyCredential) {
    if (!dataLakeSASSignatureValues.identifier &&
        !(dataLakeSASSignatureValues.permissions && dataLakeSASSignatureValues.expiresOn)) {
        throw new RangeError("Must provide 'permissions' and 'expiresOn' for Blob SAS generation when 'identifier' is not provided.");
    }
    const version = dataLakeSASSignatureValues.version
        ? dataLakeSASSignatureValues.version
        : SERVICE_VERSION;
    dataLakeSASSignatureValues = SASSignatureValuesSanityCheckAndAutofill(dataLakeSASSignatureValues, version);
    let resource = "c";
    if (dataLakeSASSignatureValues.pathName) {
        if (dataLakeSASSignatureValues.isDirectory) {
            resource = "d";
        }
        else {
            resource = "b";
            if (dataLakeSASSignatureValues.snapshotTime) {
                resource = "bs";
            }
        }
    }
    // Calling parse and toString guarantees the proper ordering and throws on invalid characters.
    let verifiedPermissions;
    if (dataLakeSASSignatureValues.permissions) {
        if (dataLakeSASSignatureValues.pathName) {
            if (dataLakeSASSignatureValues.isDirectory) {
                verifiedPermissions = DirectorySASPermissions.parse(dataLakeSASSignatureValues.permissions.toString()).toString();
            }
            else {
                verifiedPermissions = DataLakeSASPermissions.parse(dataLakeSASSignatureValues.permissions.toString()).toString();
            }
        }
        else {
            verifiedPermissions = FileSystemSASPermissions.parse(dataLakeSASSignatureValues.permissions.toString()).toString();
        }
    }
    // Signature is generated on the un-url-encoded values.
    const stringToSign = [
        verifiedPermissions ? verifiedPermissions : "",
        dataLakeSASSignatureValues.startsOn
            ? truncatedISO8061Date(dataLakeSASSignatureValues.startsOn, false)
            : "",
        dataLakeSASSignatureValues.expiresOn
            ? truncatedISO8061Date(dataLakeSASSignatureValues.expiresOn, false)
            : "",
        getCanonicalName(sharedKeyCredential.accountName, dataLakeSASSignatureValues.fileSystemName, dataLakeSASSignatureValues.pathName),
        dataLakeSASSignatureValues.identifier,
        dataLakeSASSignatureValues.ipRange ? ipRangeToString(dataLakeSASSignatureValues.ipRange) : "",
        dataLakeSASSignatureValues.protocol ? dataLakeSASSignatureValues.protocol : "",
        version,
        resource,
        dataLakeSASSignatureValues.snapshotTime,
        dataLakeSASSignatureValues.cacheControl ? dataLakeSASSignatureValues.cacheControl : "",
        dataLakeSASSignatureValues.contentDisposition
            ? dataLakeSASSignatureValues.contentDisposition
            : "",
        dataLakeSASSignatureValues.contentEncoding ? dataLakeSASSignatureValues.contentEncoding : "",
        dataLakeSASSignatureValues.contentLanguage ? dataLakeSASSignatureValues.contentLanguage : "",
        dataLakeSASSignatureValues.contentType ? dataLakeSASSignatureValues.contentType : ""
    ].join("\n");
    const signature = sharedKeyCredential.computeHMACSHA256(stringToSign);
    return new SASQueryParameters(version, signature, verifiedPermissions, undefined, undefined, dataLakeSASSignatureValues.protocol, dataLakeSASSignatureValues.startsOn, dataLakeSASSignatureValues.expiresOn, dataLakeSASSignatureValues.ipRange, dataLakeSASSignatureValues.identifier, resource, dataLakeSASSignatureValues.cacheControl, dataLakeSASSignatureValues.contentDisposition, dataLakeSASSignatureValues.contentEncoding, dataLakeSASSignatureValues.contentLanguage, dataLakeSASSignatureValues.contentType, undefined, dataLakeSASSignatureValues.directoryDepth);
}
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 * IMPLEMENTATION FOR API VERSION FROM 2018-11-09.
 *
 * Creates an instance of SASQueryParameters.
 *
 * Only accepts required settings needed to create a SAS. For optional settings please
 * set corresponding properties directly, such as permissions, startsOn.
 *
 * WARNING: identifier will be ignored, permissions and expiresOn are required.
 *
 * @param dataLakeSASSignatureValues -
 * @param userDelegationKeyCredential -
 */
function generateBlobSASQueryParametersUDK20181109(dataLakeSASSignatureValues, userDelegationKeyCredential) {
    if (!dataLakeSASSignatureValues.permissions || !dataLakeSASSignatureValues.expiresOn) {
        throw new RangeError("Must provide 'permissions' and 'expiresOn' for Blob SAS generation when generating user delegation SAS.");
    }
    const version = dataLakeSASSignatureValues.version
        ? dataLakeSASSignatureValues.version
        : SERVICE_VERSION;
    dataLakeSASSignatureValues = SASSignatureValuesSanityCheckAndAutofill(dataLakeSASSignatureValues, version);
    let resource = "c";
    if (dataLakeSASSignatureValues.pathName) {
        if (dataLakeSASSignatureValues.isDirectory) {
            resource = "d";
        }
        else {
            resource = "b";
            if (dataLakeSASSignatureValues.snapshotTime) {
                resource = "bs";
            }
        }
    }
    // Calling parse and toString guarantees the proper ordering and throws on invalid characters.
    let verifiedPermissions;
    if (dataLakeSASSignatureValues.permissions) {
        if (dataLakeSASSignatureValues.pathName) {
            if (dataLakeSASSignatureValues.isDirectory) {
                verifiedPermissions = DirectorySASPermissions.parse(dataLakeSASSignatureValues.permissions.toString()).toString();
            }
            else {
                verifiedPermissions = DataLakeSASPermissions.parse(dataLakeSASSignatureValues.permissions.toString()).toString();
            }
        }
        else {
            verifiedPermissions = FileSystemSASPermissions.parse(dataLakeSASSignatureValues.permissions.toString()).toString();
        }
    }
    // Signature is generated on the un-url-encoded values.
    const stringToSign = [
        verifiedPermissions ? verifiedPermissions : "",
        dataLakeSASSignatureValues.startsOn
            ? truncatedISO8061Date(dataLakeSASSignatureValues.startsOn, false)
            : "",
        dataLakeSASSignatureValues.expiresOn
            ? truncatedISO8061Date(dataLakeSASSignatureValues.expiresOn, false)
            : "",
        getCanonicalName(userDelegationKeyCredential.accountName, dataLakeSASSignatureValues.fileSystemName, dataLakeSASSignatureValues.pathName),
        userDelegationKeyCredential.userDelegationKey.signedObjectId,
        userDelegationKeyCredential.userDelegationKey.signedTenantId,
        userDelegationKeyCredential.userDelegationKey.signedStartsOn
            ? truncatedISO8061Date(userDelegationKeyCredential.userDelegationKey.signedStartsOn, false)
            : "",
        userDelegationKeyCredential.userDelegationKey.signedExpiresOn
            ? truncatedISO8061Date(userDelegationKeyCredential.userDelegationKey.signedExpiresOn, false)
            : "",
        userDelegationKeyCredential.userDelegationKey.signedService,
        userDelegationKeyCredential.userDelegationKey.signedVersion,
        dataLakeSASSignatureValues.ipRange ? ipRangeToString(dataLakeSASSignatureValues.ipRange) : "",
        dataLakeSASSignatureValues.protocol ? dataLakeSASSignatureValues.protocol : "",
        version,
        resource,
        dataLakeSASSignatureValues.snapshotTime,
        dataLakeSASSignatureValues.cacheControl,
        dataLakeSASSignatureValues.contentDisposition,
        dataLakeSASSignatureValues.contentEncoding,
        dataLakeSASSignatureValues.contentLanguage,
        dataLakeSASSignatureValues.contentType
    ].join("\n");
    const signature = userDelegationKeyCredential.computeHMACSHA256(stringToSign);
    return new SASQueryParameters(version, signature, verifiedPermissions, undefined, undefined, dataLakeSASSignatureValues.protocol, dataLakeSASSignatureValues.startsOn, dataLakeSASSignatureValues.expiresOn, dataLakeSASSignatureValues.ipRange, dataLakeSASSignatureValues.identifier, resource, dataLakeSASSignatureValues.cacheControl, dataLakeSASSignatureValues.contentDisposition, dataLakeSASSignatureValues.contentEncoding, dataLakeSASSignatureValues.contentLanguage, dataLakeSASSignatureValues.contentType, userDelegationKeyCredential.userDelegationKey, dataLakeSASSignatureValues.directoryDepth, dataLakeSASSignatureValues.preauthorizedAgentObjectId, dataLakeSASSignatureValues.agentObjectId, dataLakeSASSignatureValues.correlationId);
}
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 * IMPLEMENTATION FOR API VERSION FROM 2020-02-10.
 *
 * Creates an instance of SASQueryParameters.
 *
 * Only accepts required settings needed to create a SAS. For optional settings please
 * set corresponding properties directly, such as permissions, startsOn.
 *
 * WARNING: identifier will be ignored, permissions and expiresOn are required.
 *
 * @param dataLakeSASSignatureValues -
 * @param userDelegationKeyCredential -
 */
function generateBlobSASQueryParametersUDK20200210(dataLakeSASSignatureValues, userDelegationKeyCredential) {
    if (!dataLakeSASSignatureValues.permissions || !dataLakeSASSignatureValues.expiresOn) {
        throw new RangeError("Must provide 'permissions' and 'expiresOn' for Blob SAS generation when generating user delegation SAS.");
    }
    const version = dataLakeSASSignatureValues.version
        ? dataLakeSASSignatureValues.version
        : SERVICE_VERSION;
    dataLakeSASSignatureValues = SASSignatureValuesSanityCheckAndAutofill(dataLakeSASSignatureValues, version);
    let resource = "c";
    if (dataLakeSASSignatureValues.pathName) {
        if (dataLakeSASSignatureValues.isDirectory) {
            resource = "d";
        }
        else {
            resource = "b";
            if (dataLakeSASSignatureValues.snapshotTime) {
                resource = "bs";
            }
        }
    }
    // Calling parse and toString guarantees the proper ordering and throws on invalid characters.
    let verifiedPermissions;
    if (dataLakeSASSignatureValues.permissions) {
        if (dataLakeSASSignatureValues.pathName) {
            if (dataLakeSASSignatureValues.isDirectory) {
                verifiedPermissions = DirectorySASPermissions.parse(dataLakeSASSignatureValues.permissions.toString()).toString();
            }
            else {
                verifiedPermissions = DataLakeSASPermissions.parse(dataLakeSASSignatureValues.permissions.toString()).toString();
            }
        }
        else {
            verifiedPermissions = FileSystemSASPermissions.parse(dataLakeSASSignatureValues.permissions.toString()).toString();
        }
    }
    // Signature is generated on the un-url-encoded values.
    const stringToSign = [
        verifiedPermissions ? verifiedPermissions : "",
        dataLakeSASSignatureValues.startsOn
            ? truncatedISO8061Date(dataLakeSASSignatureValues.startsOn, false)
            : "",
        dataLakeSASSignatureValues.expiresOn
            ? truncatedISO8061Date(dataLakeSASSignatureValues.expiresOn, false)
            : "",
        getCanonicalName(userDelegationKeyCredential.accountName, dataLakeSASSignatureValues.fileSystemName, dataLakeSASSignatureValues.pathName),
        userDelegationKeyCredential.userDelegationKey.signedObjectId,
        userDelegationKeyCredential.userDelegationKey.signedTenantId,
        userDelegationKeyCredential.userDelegationKey.signedStartsOn
            ? truncatedISO8061Date(userDelegationKeyCredential.userDelegationKey.signedStartsOn, false)
            : "",
        userDelegationKeyCredential.userDelegationKey.signedExpiresOn
            ? truncatedISO8061Date(userDelegationKeyCredential.userDelegationKey.signedExpiresOn, false)
            : "",
        userDelegationKeyCredential.userDelegationKey.signedService,
        userDelegationKeyCredential.userDelegationKey.signedVersion,
        dataLakeSASSignatureValues.preauthorizedAgentObjectId,
        dataLakeSASSignatureValues.agentObjectId,
        dataLakeSASSignatureValues.correlationId,
        dataLakeSASSignatureValues.ipRange ? ipRangeToString(dataLakeSASSignatureValues.ipRange) : "",
        dataLakeSASSignatureValues.protocol ? dataLakeSASSignatureValues.protocol : "",
        version,
        resource,
        dataLakeSASSignatureValues.snapshotTime,
        dataLakeSASSignatureValues.cacheControl,
        dataLakeSASSignatureValues.contentDisposition,
        dataLakeSASSignatureValues.contentEncoding,
        dataLakeSASSignatureValues.contentLanguage,
        dataLakeSASSignatureValues.contentType
    ].join("\n");
    const signature = userDelegationKeyCredential.computeHMACSHA256(stringToSign);
    return new SASQueryParameters(version, signature, verifiedPermissions, undefined, undefined, dataLakeSASSignatureValues.protocol, dataLakeSASSignatureValues.startsOn, dataLakeSASSignatureValues.expiresOn, dataLakeSASSignatureValues.ipRange, dataLakeSASSignatureValues.identifier, resource, dataLakeSASSignatureValues.cacheControl, dataLakeSASSignatureValues.contentDisposition, dataLakeSASSignatureValues.contentEncoding, dataLakeSASSignatureValues.contentLanguage, dataLakeSASSignatureValues.contentType, userDelegationKeyCredential.userDelegationKey, dataLakeSASSignatureValues.directoryDepth, dataLakeSASSignatureValues.preauthorizedAgentObjectId, dataLakeSASSignatureValues.agentObjectId, dataLakeSASSignatureValues.correlationId);
}
function getCanonicalName(accountName, containerName, blobName) {
    // FileSystem: "/blob/account/fileSystemName"
    // File:       "/blob/account/fileSystemName/fileName"
    const elements = [`/blob/${accountName}/${containerName}`];
    if (blobName) {
        elements.push(`/${blobName}`);
    }
    return elements.join("");
}
function SASSignatureValuesSanityCheckAndAutofill(dataLakeSASSignatureValues, version) {
    var _a;
    if (version < "2020-02-10" &&
        (dataLakeSASSignatureValues.isDirectory || dataLakeSASSignatureValues.directoryDepth)) {
        throw RangeError("'version' must be >= '2020-02-10' to support directory SAS.");
    }
    if (dataLakeSASSignatureValues.isDirectory && dataLakeSASSignatureValues.pathName === undefined) {
        throw RangeError("Must provide 'pathName' when 'isDirectory' is true.");
    }
    if (dataLakeSASSignatureValues.directoryDepth !== undefined &&
        (!Number.isInteger(dataLakeSASSignatureValues.directoryDepth) ||
            dataLakeSASSignatureValues.directoryDepth < 0)) {
        throw RangeError("'directoryDepth' must be a non-negative interger.");
    }
    if (dataLakeSASSignatureValues.isDirectory &&
        dataLakeSASSignatureValues.directoryDepth === undefined) {
        // calculate directoryDepth from pathName
        if (dataLakeSASSignatureValues.pathName === "/") {
            dataLakeSASSignatureValues.directoryDepth = 0;
        }
        else {
            dataLakeSASSignatureValues.directoryDepth = (_a = dataLakeSASSignatureValues.pathName) === null || _a === void 0 ? void 0 : _a.split("/").filter((x) => x !== "").length;
        }
    }
    if (version < "2020-02-10" &&
        dataLakeSASSignatureValues.permissions &&
        (dataLakeSASSignatureValues.permissions.move ||
            dataLakeSASSignatureValues.permissions.execute ||
            dataLakeSASSignatureValues.permissions.manageOwnership ||
            dataLakeSASSignatureValues.permissions.manageAccessControl)) {
        throw RangeError("'version' must be >= '2020-02-10' when providing m, e, o or p permission.");
    }
    if (version < "2020-02-10" &&
        (dataLakeSASSignatureValues.preauthorizedAgentObjectId ||
            dataLakeSASSignatureValues.agentObjectId ||
            dataLakeSASSignatureValues.correlationId)) {
        throw RangeError("'version' must be >= '2020-02-10' when providing 'preauthorizedAgentObjectId', 'agentObjectId' or 'correlationId'.");
    }
    if (dataLakeSASSignatureValues.preauthorizedAgentObjectId &&
        dataLakeSASSignatureValues.agentObjectId) {
        throw RangeError("'preauthorizedAgentObjectId' or 'agentObjectId' shouldn't be specified at the same time.");
    }
    if (dataLakeSASSignatureValues.snapshotTime && version < "2018-11-09") {
        throw RangeError("'version' must be >= '2018-11-09' when provided 'snapshotTime'.");
    }
    if (dataLakeSASSignatureValues.pathName === undefined &&
        dataLakeSASSignatureValues.snapshotTime) {
        throw RangeError("Must provide 'blobName' when provided 'snapshotTime'.");
    }
    return dataLakeSASSignatureValues;
}

// Copyright (c) Microsoft Corporation.
/**
 * States for Batch.
 */
var BatchStates;
(function (BatchStates) {
    BatchStates[BatchStates["Good"] = 0] = "Good";
    BatchStates[BatchStates["Error"] = 1] = "Error";
})(BatchStates || (BatchStates = {}));
/**
 * Batch provides basic parallel execution with concurrency limits.
 * Will stop execute left operations when one of the executed operation throws an error.
 * But Batch cannot cancel ongoing operations, you need to cancel them by yourself.
 */
class Batch {
    /**
     * Creates an instance of Batch.
     * @param concurrency -
     */
    constructor(concurrency = 5) {
        /**
         * Number of active operations under execution.
         */
        this.actives = 0;
        /**
         * Number of completed operations under execution.
         */
        this.completed = 0;
        /**
         * Offset of next operation to be executed.
         */
        this.offset = 0;
        /**
         * Operation array to be executed.
         */
        this.operations = [];
        /**
         * States of Batch. When an error happens, state will turn into error.
         * Batch will stop execute left operations.
         */
        this.state = BatchStates.Good;
        if (concurrency < 1) {
            throw new RangeError("concurrency must be larger than 0");
        }
        this.concurrency = concurrency;
        this.emitter = new events.EventEmitter();
    }
    /**
     * Add a operation into queue.
     *
     * @param operation -
     */
    addOperation(operation) {
        this.operations.push(async () => {
            try {
                this.actives++;
                await operation();
                this.actives--;
                this.completed++;
                this.parallelExecute();
            }
            catch (error) {
                this.emitter.emit("error", error);
            }
        });
    }
    /**
     * Start execute operations in the queue.
     *
     */
    async do() {
        if (this.operations.length === 0) {
            return Promise.resolve();
        }
        this.parallelExecute();
        return new Promise((resolve, reject) => {
            this.emitter.on("finish", resolve);
            this.emitter.on("error", (error) => {
                this.state = BatchStates.Error;
                reject(error);
            });
        });
    }
    /**
     * Get next operation to be executed. Return null when reaching ends.
     *
     */
    nextOperation() {
        if (this.offset < this.operations.length) {
            return this.operations[this.offset++];
        }
        return null;
    }
    /**
     * Start execute operations. One one the most important difference between
     * this method with do() is that do() wraps as an sync method.
     *
     */
    parallelExecute() {
        if (this.state === BatchStates.Error) {
            return;
        }
        if (this.completed >= this.operations.length) {
            this.emitter.emit("finish");
            return;
        }
        while (this.actives < this.concurrency) {
            const operation = this.nextOperation();
            if (operation) {
                operation();
            }
            else {
                return;
            }
        }
    }
}

/**
 * An error thrown when an operation is interrupted and can be continued later on.
 */
class DataLakeAclChangeFailedError extends Error {
    constructor(error, continuationToken) {
        super(error.message);
        this.name = "DataLakeAclChangeFailedError";
        this.innerError = error;
        this.continuationToken = continuationToken;
        Object.setPrototypeOf(this, DataLakeAclChangeFailedError.prototype);
    }
}

// Copyright (c) Microsoft Corporation.
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * Promisified version of fs.stat().
 */
const fsStat = util.promisify(fs.stat);
const fsCreateReadStream = fs.createReadStream;

// Copyright (c) Microsoft Corporation.
/**
 * A DataLakePathClient represents a URL to the Azure Storage path (directory or file).
 */
class DataLakePathClient extends StorageClient {
    constructor(url, credentialOrPipeline, 
    // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options */
    options) {
        if (credentialOrPipeline instanceof Pipeline) {
            super(url, credentialOrPipeline);
        }
        else {
            let credential;
            if (credentialOrPipeline === undefined) {
                credential = new AnonymousCredential();
            }
            else {
                credential = credentialOrPipeline;
            }
            const pipeline = newPipeline(credential, options);
            super(url, pipeline);
        }
        this.pathContext = new Path$1(this.storageClientContext);
        this.blobClient = new storageBlob.BlobClient(this.blobEndpointUrl, this.pipeline);
    }
    /**
     * SetAccessControlRecursiveInternal operation sets the Access Control on a path and sub paths.
     *
     * @param mode - Mode \"set\" sets POSIX access control rights on files and directories,
     *                                                 Mode \"modify\" modifies one or more POSIX access control rights that pre-exist on files and directories,
     *                                                 Mode \"remove\" removes one or more POSIX access control rights that were present earlier on files and directories.
     * @param acl - The POSIX access control list for the file or directory.
     * @param options - Optional. Options
     */
    async setAccessControlRecursiveInternal(mode, acl, options = {}) {
        if (options.maxBatches !== undefined && options.maxBatches < 1) {
            throw RangeError(`Options maxBatches must be larger than 0.`);
        }
        if (options.batchSize !== undefined && options.batchSize < 1) {
            throw RangeError(`Options batchSize must be larger than 0.`);
        }
        const { span, updatedOptions } = createSpan(`DataLakePathClient-setAccessControlRecursiveInternal`, options);
        const result = {
            counters: {
                failedChangesCount: 0,
                changedDirectoriesCount: 0,
                changedFilesCount: 0
            },
            continuationToken: undefined
        };
        try {
            let continuationToken = options.continuationToken;
            let batchCounter = 0;
            let reachMaxBatches = false;
            do {
                let response;
                try {
                    response = await this.pathContext.setAccessControlRecursive(mode, Object.assign(Object.assign(Object.assign({}, options), { acl: toAclString(acl), maxRecords: options.batchSize, continuation: continuationToken, forceFlag: options.continueOnFailure }), convertTracingToRequestOptionsBase(updatedOptions)));
                }
                catch (e) {
                    throw new DataLakeAclChangeFailedError(e, continuationToken);
                }
                batchCounter++;
                continuationToken = response.continuation;
                // Update result
                result.continuationToken = continuationToken;
                result.counters.failedChangesCount += response.failureCount || 0;
                result.counters.changedDirectoriesCount += response.directoriesSuccessful || 0;
                result.counters.changedFilesCount += response.filesSuccessful || 0;
                // Progress event call back
                if (options.onProgress) {
                    const progress = {
                        batchFailures: toAccessControlChangeFailureArray(response.failedEntries),
                        batchCounters: {
                            failedChangesCount: response.failureCount || 0,
                            changedDirectoriesCount: response.directoriesSuccessful || 0,
                            changedFilesCount: response.filesSuccessful || 0
                        },
                        aggregateCounters: result.counters,
                        continuationToken: continuationToken
                    };
                    options.onProgress(progress);
                }
                reachMaxBatches =
                    options.maxBatches === undefined ? false : batchCounter >= options.maxBatches;
            } while (continuationToken && !reachMaxBatches);
            return result;
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Name of current file system.
     *
     * @readonly
     */
    get fileSystemName() {
        return this.blobClient.containerName;
    }
    /**
     * Name of current path (directory or file).
     *
     * @readonly
     */
    get name() {
        return this.blobClient.name;
    }
    /**
     * Convert current DataLakePathClient to DataLakeDirectoryClient if current path is a directory.
     *
     */
    // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-subclients */
    toDirectoryClient() {
        return new DataLakeDirectoryClient(this.dfsEndpointUrl, this.pipeline);
    }
    /**
     * Convert current DataLakePathClient to DataLakeFileClient if current path is a file.
     *
     */
    // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-subclients */
    toFileClient() {
        return new DataLakeFileClient(this.dfsEndpointUrl, this.pipeline);
    }
    /**
     * Get a {@link DataLakeLeaseClient} that manages leases on the path (directory or file).
     *
     * @param proposeLeaseId - Optional. Initial proposed lease Id.
     */
    getDataLakeLeaseClient(proposeLeaseId) {
        return new DataLakeLeaseClient(this.blobClient.getBlobLeaseClient(proposeLeaseId));
    }
    /**
     * Create a directory or path.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
     *
     * @param resourceType - Resource type, "directory" or "file".
     * @param options - Optional. Options when creating path.
     */
    async create(resourceType, options = {}) {
        options.conditions = options.conditions || {};
        const { span, updatedOptions } = createSpan("DataLakePathClient-create", options);
        try {
            return await this.pathContext.create(Object.assign(Object.assign(Object.assign({}, options), { resource: resourceType, leaseAccessConditions: options.conditions, modifiedAccessConditions: options.conditions, properties: toProperties(options.metadata) }), convertTracingToRequestOptionsBase(updatedOptions)));
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Create a directory or file. If the resource already exists, it is not changed.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/create
     *
     * @param resourceType - Resource type, "directory" or "file".
     * @param options -
     */
    async createIfNotExists(resourceType, options = {}) {
        var _a, _b;
        const { span, updatedOptions } = createSpan("DataLakePathClient-createIfNotExists", options);
        try {
            const conditions = { ifNoneMatch: ETagAny };
            const res = await this.create(resourceType, Object.assign(Object.assign({}, options), { conditions, tracingOptions: updatedOptions.tracingOptions }));
            return Object.assign({ succeeded: true }, res);
        }
        catch (e) {
            if (((_a = e.details) === null || _a === void 0 ? void 0 : _a.errorCode) === "PathAlreadyExists") {
                span.setStatus({
                    code: coreTracing.SpanStatusCode.ERROR,
                    message: "Expected exception when creating a blob only if it does not already exist."
                });
                return Object.assign(Object.assign({ succeeded: false }, (_b = e.response) === null || _b === void 0 ? void 0 : _b.parsedHeaders), { _response: e.response });
            }
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Returns true if the Data Lake file represented by this client exists; false otherwise.
     *
     * NOTE: use this function with care since an existing file might be deleted by other clients or
     * applications. Vice versa new files might be added by other clients or applications after this
     * function completes.
     *
     * @param options - options to Exists operation.
     */
    async exists(options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeFileClient-exists", options);
        try {
            return await this.blobClient.exists(updatedOptions);
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Delete current path (directory or file).
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete
     *
     * @param recursive - Required and valid only when the resource is a directory. If "true", all paths beneath the directory will be deleted.
     * @param options - Optional. Options when deleting path.
     */
    async delete(recursive, options = {}) {
        options.conditions = options.conditions || {};
        const { span, updatedOptions } = createSpan("DataLakePathClient-delete", options);
        try {
            let continuation;
            let response;
            // How to handle long delete loop?
            do {
                response = await this.pathContext.delete(Object.assign(Object.assign({ continuation,
                    recursive, leaseAccessConditions: options.conditions, modifiedAccessConditions: options.conditions }, convertTracingToRequestOptionsBase(updatedOptions)), { abortSignal: options.abortSignal }));
                continuation = response.continuation;
            } while (continuation !== undefined && continuation !== "");
            return response;
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Delete current path (directory or file) if it exists.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/delete
     *
     * @param recursive - Required and valid only when the resource is a directory. If "true", all paths beneath the directory will be deleted.
     * @param options -
     */
    async deleteIfExists(recursive, options = {}) {
        var _a, _b;
        options.conditions = options.conditions || {};
        const { span, updatedOptions } = createSpan("DataLakePathClient-deleteIfExists", options);
        try {
            const res = await this.delete(recursive, updatedOptions);
            return Object.assign({ succeeded: true }, res);
        }
        catch (e) {
            if (((_a = e.details) === null || _a === void 0 ? void 0 : _a.errorCode) === "PathNotFound") {
                span.setStatus({
                    code: coreTracing.SpanStatusCode.ERROR,
                    message: "Expected exception when deleting a directory or file only if it exists."
                });
                return Object.assign(Object.assign({ succeeded: false }, (_b = e.response) === null || _b === void 0 ? void 0 : _b.parsedHeaders), { _response: e.response });
            }
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Returns the access control data for a path (directory of file).
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/getproperties
     *
     * @param options - Optional. Options when getting file access control.
     */
    async getAccessControl(options = {}) {
        options.conditions = options.conditions || {};
        const { span, updatedOptions } = createSpan("DataLakePathClient-getAccessControl", options);
        try {
            const response = await this.pathContext.getProperties(Object.assign(Object.assign({ action: "getAccessControl", upn: options.userPrincipalName, leaseAccessConditions: options.conditions, modifiedAccessConditions: options.conditions }, convertTracingToRequestOptionsBase(updatedOptions)), { abortSignal: options.abortSignal }));
            return toPathGetAccessControlResponse(response);
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Set the access control data for a path (directory of file).
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update
     *
     * @param acl - The POSIX access control list for the file or directory.
     * @param options - Optional. Options when setting path access control.
     */
    async setAccessControl(acl, options = {}) {
        options.conditions = options.conditions || {};
        const { span, updatedOptions } = createSpan("DataLakePathClient-setAccessControl", options);
        try {
            return await this.pathContext.setAccessControl(Object.assign(Object.assign(Object.assign({}, options), { acl: toAclString(acl), leaseAccessConditions: options.conditions, modifiedAccessConditions: options.conditions }), convertTracingToRequestOptionsBase(updatedOptions)));
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Sets the Access Control on a path and sub paths.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update
     *
     * @param acl - The POSIX access control list for the file or directory.
     * @param options - Optional. Options
     */
    async setAccessControlRecursive(acl, options = {}) {
        const { span, updatedOptions } = createSpan("DataLakePathClient-setAccessControlRecursive", options);
        try {
            return this.setAccessControlRecursiveInternal("set", acl, updatedOptions);
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Modifies the Access Control on a path and sub paths.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update
     *
     * @param acl - The POSIX access control list for the file or directory.
     * @param options - Optional. Options
     */
    async updateAccessControlRecursive(acl, options = {}) {
        const { span, updatedOptions } = createSpan("DataLakePathClient-updateAccessControlRecursive", options);
        try {
            return this.setAccessControlRecursiveInternal("modify", acl, updatedOptions);
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Removes the Access Control on a path and sub paths.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update
     *
     * @param acl - The POSIX access control list for the file or directory.
     * @param options - Optional. Options
     */
    async removeAccessControlRecursive(acl, options = {}) {
        const { span, updatedOptions } = createSpan("DataLakePathClient-removeAccessControlRecursive", options);
        try {
            return this.setAccessControlRecursiveInternal("remove", acl, updatedOptions);
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Sets the file permissions on a path.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update
     *
     * @param permissions - The POSIX access permissions for the file owner, the file owning group, and others.
     * @param options - Optional. Options when setting path permissions.
     */
    async setPermissions(permissions, options = {}) {
        options.conditions = options.conditions || {};
        const { span, updatedOptions } = createSpan("DataLakePathClient-setPermissions", options);
        try {
            return await this.pathContext.setAccessControl(Object.assign(Object.assign(Object.assign({}, options), { permissions: toPermissionsString(permissions), leaseAccessConditions: options.conditions, modifiedAccessConditions: options.conditions }), convertTracingToRequestOptionsBase(updatedOptions)));
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Returns all user-defined metadata, standard HTTP properties, and system properties
     * for the path (directory or file).
     *
     * WARNING: The `metadata` object returned in the response will have its keys in lowercase, even if
     * they originally contained uppercase characters. This differs from the metadata keys returned by
     * the methods of {@link DataLakeFileSystemClient} that list paths using the `includeMetadata` option, which
     * will retain their original casing.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob-properties
     *
     * @param options - Optional. Options when getting path properties.
     */
    async getProperties(options = {}) {
        const { span, updatedOptions } = createSpan("DataLakePathClient-getProperties", options);
        try {
            return await this.blobClient.getProperties(Object.assign(Object.assign({}, options), { customerProvidedKey: undefined, tracingOptions: updatedOptions.tracingOptions }));
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Sets system properties on the path (directory or file).
     *
     * If no value provided, or no value provided for the specified blob HTTP headers,
     * these blob HTTP headers without a value will be cleared.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-blob-properties
     *
     * @param httpHeaders -
     * @param options -
     */
    async setHttpHeaders(httpHeaders, options = {}) {
        const { span, updatedOptions } = createSpan("DataLakePathClient-setHttpHeaders", options);
        try {
            return await this.blobClient.setHTTPHeaders({
                blobCacheControl: httpHeaders.cacheControl,
                blobContentType: httpHeaders.contentType,
                blobContentMD5: httpHeaders.contentMD5,
                blobContentEncoding: httpHeaders.contentEncoding,
                blobContentLanguage: httpHeaders.contentLanguage,
                blobContentDisposition: httpHeaders.contentDisposition
            }, updatedOptions);
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Sets user-defined metadata for the specified path (directory of file) as one or more name-value pairs.
     *
     * If no option provided, or no metadata defined in the parameter, the path
     * metadata will be removed.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-blob-metadata
     *
     * @param metadata - Optional. Replace existing metadata with this value.
     *                              If no value provided the existing metadata will be removed.
     * @param options - Optional. Options when setting path metadata.
     */
    async setMetadata(metadata, options = {}) {
        const { span, updatedOptions } = createSpan("DataLakePathClient-setMetadata", options);
        try {
            return await this.blobClient.setMetadata(metadata, Object.assign(Object.assign({}, options), { customerProvidedKey: undefined, tracingOptions: updatedOptions.tracingOptions }));
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    async move(destinationPathOrFileSystem, destinationPathOrOptions, options) {
        let destinationFileSystem = this.fileSystemName;
        let destinationPath = destinationPathOrFileSystem;
        if (typeof destinationPathOrOptions === "string") {
            destinationFileSystem = destinationPathOrFileSystem;
            destinationPath = destinationPathOrOptions;
            options = options || {};
        }
        else {
            options = destinationPathOrOptions || {};
        }
        options.conditions = options.conditions || {};
        options.destinationConditions = options.destinationConditions || {};
        const { span, updatedOptions } = createSpan("DataLakePathClient-move", options);
        const renameSource = getURLPathAndQuery(this.dfsEndpointUrl);
        const split = destinationPath.split("?");
        let destinationUrl;
        if (split.length === 2) {
            const renameDestination = `/${destinationFileSystem}/${split[0]}`;
            destinationUrl = setURLPath(this.dfsEndpointUrl, renameDestination);
            destinationUrl = setURLQueries(destinationUrl, split[1]);
        }
        else if (split.length === 1) {
            const renameDestination = `/${destinationFileSystem}/${destinationPath}`;
            destinationUrl = setURLPath(this.dfsEndpointUrl, renameDestination);
        }
        else {
            throw new RangeError("Destination path should not contain more than one query string");
        }
        const destPathClient = new DataLakePathClient(destinationUrl, this.pipeline);
        try {
            return await destPathClient.pathContext.create(Object.assign(Object.assign({ mode: "legacy", // By default
                renameSource, sourceLeaseId: options.conditions.leaseId, leaseAccessConditions: options.destinationConditions, sourceModifiedAccessConditions: {
                    sourceIfMatch: options.conditions.ifMatch,
                    sourceIfNoneMatch: options.conditions.ifNoneMatch,
                    sourceIfModifiedSince: options.conditions.ifModifiedSince,
                    sourceIfUnmodifiedSince: options.conditions.ifUnmodifiedSince
                }, modifiedAccessConditions: options.destinationConditions }, convertTracingToRequestOptionsBase(updatedOptions)), { abortSignal: options.abortSignal }));
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
}
/**
 * A DataLakeDirectoryClient represents a URL to the Azure Storage directory.
 */
class DataLakeDirectoryClient extends DataLakePathClient {
    async create(resourceTypeOrOptions, options = {}) {
        if (resourceTypeOrOptions === "directory") {
            return super.create(resourceTypeOrOptions, options);
        }
        if (resourceTypeOrOptions === "file") {
            throw TypeError(`DataLakeDirectoryClient:create() resourceType cannot be ${resourceTypeOrOptions}. Refer to DataLakeFileClient for file creation.`);
        }
        options = resourceTypeOrOptions || {};
        options.conditions = options.conditions || {};
        const { span, updatedOptions } = createSpan("DataLakeDirectoryClient-create", options);
        try {
            return await super.create("directory", Object.assign(Object.assign({}, options), { tracingOptions: Object.assign(Object.assign({}, options.tracingOptions), convertTracingToRequestOptionsBase(updatedOptions)) }));
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    async createIfNotExists(resourceTypeOrOptions, options = {}) {
        if (resourceTypeOrOptions === "file") {
            throw TypeError(`DataLakeDirectoryClient:createIfNotExists() resourceType cannot be ${resourceTypeOrOptions}. Refer to DataLakeFileClient for file creation.`);
        }
        if (resourceTypeOrOptions !== "directory") {
            options = resourceTypeOrOptions || {};
        }
        const { span, updatedOptions } = createSpan("DataLakeDirectoryClient-createIfNotExists", options);
        try {
            return await super.createIfNotExists("directory", Object.assign(Object.assign({}, options), { tracingOptions: Object.assign(Object.assign({}, options.tracingOptions), convertTracingToRequestOptionsBase(updatedOptions)) }));
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Creates a {@link DataLakeDirectoryClient} object under current directory.
     *
     * @param subdirectoryName - Subdirectory name.
     */
    getSubdirectoryClient(subdirectoryName) {
        return new DataLakeDirectoryClient(appendToURLPath(this.url, encodeURIComponent(subdirectoryName)), this.pipeline);
    }
    /**
     * Creates a {@link DataLakeFileClient} object under current directory.
     *
     * @param fileName -
     */
    // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-subclients */
    getFileClient(fileName) {
        return new DataLakeFileClient(appendToURLPath(this.url, encodeURIComponent(fileName)), this.pipeline);
    }
    /**
     * Only available for clients constructed with a shared key credential.
     *
     * Generates a Service Shared Access Signature (SAS) URI based on the client properties
     * and parameters passed in. The SAS is signed by the shared key credential of the client.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas
     *
     * @param options - Optional parameters.
     * @returns The SAS URI consisting of the URI to the resource represented by this client, followed by the generated SAS token.
     */
    generateSasUrl(options) {
        return new Promise((resolve) => {
            if (!(this.credential instanceof StorageSharedKeyCredential)) {
                throw RangeError("Can only generate the SAS when the client is initialized with a shared key credential");
            }
            const sas = generateDataLakeSASQueryParameters(Object.assign({ fileSystemName: this.fileSystemName, pathName: this.name, isDirectory: true }, options), this.credential).toString();
            resolve(appendToURLQuery(this.url, sas));
        });
    }
}
/**
 * A DataLakeFileClient represents a URL to the Azure Storage file.
 */
class DataLakeFileClient extends DataLakePathClient {
    constructor(url, credentialOrPipeline, 
    // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options */
    options) {
        if (credentialOrPipeline instanceof Pipeline) {
            super(url, credentialOrPipeline);
        }
        else {
            let credential;
            if (credentialOrPipeline === undefined) {
                credential = new AnonymousCredential();
            }
            else {
                credential = credentialOrPipeline;
            }
            const pipeline = newPipeline(credential, options);
            super(url, pipeline);
        }
        this.pathContextInternal = new Path$1(this.storageClientContext);
        this.blockBlobClientInternal = new storageBlob.BlockBlobClient(this.blobEndpointUrl, this.pipeline);
        this.pathContextInternalToBlobEndpoint = new Path$1(this.storageClientContextToBlobEndpoint);
    }
    async create(resourceTypeOrOptions, options = {}) {
        if (resourceTypeOrOptions === "file") {
            return super.create(resourceTypeOrOptions, options);
        }
        if (resourceTypeOrOptions === "directory") {
            throw TypeError(`DataLakeFileClient:create() resourceType cannot be ${resourceTypeOrOptions}. Refer to DataLakeDirectoryClient for directory creation.`);
        }
        options = resourceTypeOrOptions || {};
        options.conditions = options.conditions || {};
        const { span, updatedOptions } = createSpan("DataLakeFileClient-create", options);
        try {
            return await super.create("file", Object.assign(Object.assign({}, options), { tracingOptions: Object.assign(Object.assign({}, options.tracingOptions), convertTracingToRequestOptionsBase(updatedOptions)) }));
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    async createIfNotExists(resourceTypeOrOptions, options = {}) {
        if (resourceTypeOrOptions === "directory") {
            throw TypeError(`DataLakeFileClient:createIfNotExists() resourceType cannot be ${resourceTypeOrOptions}. Refer to DataLakeDirectoryClient for directory creation.`);
        }
        if (resourceTypeOrOptions !== "file") {
            options = resourceTypeOrOptions || {};
        }
        const { span, updatedOptions } = createSpan("DataLakeFileClient-createIfNotExists", options);
        try {
            return await super.createIfNotExists("file", Object.assign(Object.assign({}, options), { tracingOptions: Object.assign(Object.assign({}, options.tracingOptions), convertTracingToRequestOptionsBase(updatedOptions)) }));
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Downloads a file from the service, including its metadata and properties.
     *
     * * In Node.js, data returns in a Readable stream readableStreamBody
     * * In browsers, data returns in a promise contentAsBlob
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob
     *
     * * Example usage (Node.js):
     *
     * ```js
     * // Download and convert a file to a string
     * const downloadResponse = await fileClient.read();
     * const downloaded = await streamToBuffer(downloadResponse.readableStreamBody);
     * console.log("Downloaded file content:", downloaded.toString());
     *
     * async function streamToBuffer(readableStream) {
     *   return new Promise((resolve, reject) => {
     *     const chunks = [];
     *     readableStream.on("data", (data) => {
     *       chunks.push(data instanceof Buffer ? data : Buffer.from(data));
     *     });
     *     readableStream.on("end", () => {
     *       resolve(Buffer.concat(chunks));
     *     });
     *     readableStream.on("error", reject);
     *   });
     * }
     * ```
     *
     * Example usage (browser):
     *
     * ```js
     * // Download and convert a file to a string
     * const downloadResponse = await fileClient.read();
     * const downloaded = await blobToString(await downloadResponse.contentAsBlob);
     * console.log("Downloaded file content", downloaded);
     *
     * async function blobToString(blob: Blob): Promise<string> {
     *   const fileReader = new FileReader();
     *   return new Promise<string>((resolve, reject) => {
     *     fileReader.onloadend = (ev: any) => {
     *       resolve(ev.target!.result);
     *     };
     *     fileReader.onerror = reject;
     *     fileReader.readAsText(blob);
     *   });
     * }
     * ```
     *
     * @param offset - Optional. Offset to read file, default value is 0.
     * @param count - Optional. How many bytes to read, default will read from offset to the end.
     * @param options - Optional. Options when reading file.
     */
    async read(offset = 0, count, options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeFileClient-read", options);
        try {
            const rawResponse = await this.blockBlobClientInternal.download(offset, count, updatedOptions);
            const response = rawResponse;
            if (!coreHttp.isNode && !response.contentAsBlob) {
                response.contentAsBlob = rawResponse.blobBody;
            }
            response.fileContentMD5 = rawResponse.blobContentMD5;
            response._response.parsedHeaders.fileContentMD5 =
                rawResponse._response.parsedHeaders.blobContentMD5;
            delete rawResponse.blobContentMD5;
            delete rawResponse._response.parsedHeaders.blobContentMD5;
            return response;
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Uploads data to be appended to a file. Data can only be appended to a file.
     * To apply perviously uploaded data to a file, call flush.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/datalakestoragegen2/path/update
     *
     * @param body - Content to be uploaded.
     * @param offset - Append offset in bytes.
     * @param length - Length of content to append in bytes.
     * @param options - Optional. Options when appending data.
     */
    async append(body, offset, length, options = {}) {
        options.conditions = options.conditions || {};
        const { span, updatedOptions } = createSpan("DataLakeFileClient-append", options);
        try {
            return await this.pathContextInternal.appendData(body, Object.assign({ pathHttpHeaders: {
                    contentMD5: options.transactionalContentMD5
                }, abortSignal: options.abortSignal, position: offset, contentLength: length, leaseAccessConditions: options.conditions, requestOptions: {
                    onUploadProgress: options.onProgress
                } }, convertTracingToRequestOptionsBase(updatedOptions)));
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Flushes (writes) previously appended data to a file.
     *
     * @param position - File position to flush.
     *                          This parameter allows the caller to upload data in parallel and control the order in which it is appended to the file.
     *                          It is required when uploading data to be appended to the file and when flushing previously uploaded data to the file.
     *                          The value must be the position where the data is to be appended. Uploaded data is not immediately flushed, or written,
     *                          to the file. To flush, the previously uploaded data must be contiguous, the position parameter must be specified and
     *                          equal to the length of the file after all data has been written, and there must not be a request entity body included
     *                          with the request.
     * @param options - Optional. Options when flushing data.
     */
    async flush(position, options = {}) {
        options.conditions = options.conditions || {};
        const { span, updatedOptions } = createSpan("DataLakeFileClient-flush", options);
        try {
            return await this.pathContextInternal.flushData(Object.assign(Object.assign(Object.assign({}, options), { position, contentLength: 0, leaseAccessConditions: options.conditions, modifiedAccessConditions: options.conditions }), convertTracingToRequestOptionsBase(updatedOptions)));
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    // high level functions
    /**
     * ONLY AVAILABLE IN NODE.JS RUNTIME.
     *
     * Uploads a local file to a Data Lake file.
     *
     * @param filePath - Full path of the local file
     * @param options -
     */
    async uploadFile(filePath, 
    // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options */
    options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeFileClient-uploadFile", options);
        try {
            const size = (await fsStat(filePath)).size;
            return await this.uploadSeekableInternal((offset, contentSize) => {
                return () => fsCreateReadStream(filePath, {
                    autoClose: true,
                    end: offset + contentSize - 1,
                    start: offset
                });
            }, size, updatedOptions);
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Uploads a Buffer(Node.js)/Blob/ArrayBuffer/ArrayBufferView to a File.
     *
     * @param data - Buffer(Node), Blob, ArrayBuffer or ArrayBufferView
     * @param options -
     */
    async upload(data, options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeFileClient-upload", options);
        try {
            if (true) {
                let buffer;
                if (data instanceof Buffer) {
                    buffer = data;
                }
                else if (data instanceof ArrayBuffer) {
                    buffer = Buffer.from(data);
                }
                else {
                    data = data;
                    buffer = Buffer.from(data.buffer, data.byteOffset, data.byteLength);
                }
                return this.uploadSeekableInternal((offset, size) => buffer.slice(offset, offset + size), buffer.length, updatedOptions);
            }
            else {
                const browserBlob = new Blob([data]);
                return this.uploadSeekableInternal((offset, size) => browserBlob.slice(offset, offset + size), browserBlob.size, updatedOptions);
            }
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    async uploadSeekableInternal(bodyFactory, size, options = {}) {
        var _a;
        const { span, updatedOptions } = createSpan("DataLakeFileClient-uploadData", options);
        try {
            if (size > FILE_MAX_SIZE_BYTES) {
                throw new RangeError(`size must be <= ${FILE_MAX_SIZE_BYTES}.`);
            }
            // Create the file.
            const createRes = this.create({
                abortSignal: options.abortSignal,
                metadata: options.metadata,
                permissions: options.permissions,
                umask: options.umask,
                conditions: options.conditions,
                pathHttpHeaders: options.pathHttpHeaders,
                tracingOptions: updatedOptions.tracingOptions
            });
            // append() with empty data would return error, so do not continue
            if (size === 0) {
                return await createRes;
            }
            else {
                await createRes;
            }
            // After the File is Create, Lease ID is the only valid request parameter.
            options.conditions = { leaseId: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.leaseId };
            if (!options.chunkSize) {
                options.chunkSize = Math.ceil(size / BLOCK_BLOB_MAX_BLOCKS);
                if (options.chunkSize < FILE_UPLOAD_DEFAULT_CHUNK_SIZE) {
                    options.chunkSize = FILE_UPLOAD_DEFAULT_CHUNK_SIZE;
                }
            }
            if (options.chunkSize < 1 || options.chunkSize > FILE_UPLOAD_MAX_CHUNK_SIZE) {
                throw new RangeError(`chunkSize option must be >= 1 and <= ${FILE_UPLOAD_MAX_CHUNK_SIZE}`);
            }
            if (!options.maxConcurrency) {
                options.maxConcurrency = DEFAULT_HIGH_LEVEL_CONCURRENCY;
            }
            if (options.maxConcurrency <= 0) {
                throw new RangeError(`maxConcurrency must be > 0.`);
            }
            if (!options.singleUploadThreshold) {
                options.singleUploadThreshold = FILE_MAX_SINGLE_UPLOAD_THRESHOLD;
            }
            if (options.singleUploadThreshold < 1 ||
                options.singleUploadThreshold > FILE_MAX_SINGLE_UPLOAD_THRESHOLD) {
                throw new RangeError(`singleUploadThreshold option must be >= 1 and <= ${FILE_MAX_SINGLE_UPLOAD_THRESHOLD}`);
            }
            // When buffer length <= singleUploadThreshold, this method will use one append/flush call to finish the upload.
            if (size <= options.singleUploadThreshold) {
                await this.append(bodyFactory(0, size), 0, size, {
                    abortSignal: options.abortSignal,
                    conditions: options.conditions,
                    onProgress: options.onProgress,
                    tracingOptions: updatedOptions.tracingOptions
                });
                return await this.flush(size, {
                    abortSignal: options.abortSignal,
                    conditions: options.conditions,
                    close: options.close,
                    pathHttpHeaders: options.pathHttpHeaders,
                    tracingOptions: updatedOptions.tracingOptions
                });
            }
            const numBlocks = Math.floor((size - 1) / options.chunkSize) + 1;
            if (numBlocks > BLOCK_BLOB_MAX_BLOCKS) {
                throw new RangeError(`The data's size is too big or the chunkSize is too small;` +
                    `the number of chunks must be <= ${BLOCK_BLOB_MAX_BLOCKS}`);
            }
            let transferProgress = 0;
            const batch = new Batch(options.maxConcurrency);
            for (let i = 0; i < numBlocks; i++) {
                batch.addOperation(async () => {
                    const start = options.chunkSize * i;
                    const end = i === numBlocks - 1 ? size : start + options.chunkSize;
                    const contentLength = end - start;
                    await this.append(bodyFactory(start, contentLength), start, contentLength, {
                        abortSignal: options.abortSignal,
                        conditions: options.conditions,
                        tracingOptions: updatedOptions.tracingOptions
                    });
                    transferProgress += contentLength;
                    if (options.onProgress) {
                        options.onProgress({ loadedBytes: transferProgress });
                    }
                });
            }
            await batch.do();
            return await this.flush(size, {
                abortSignal: options.abortSignal,
                conditions: options.conditions,
                close: options.close,
                pathHttpHeaders: options.pathHttpHeaders,
                tracingOptions: updatedOptions.tracingOptions
            });
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * ONLY AVAILABLE IN NODE.JS RUNTIME.
     *
     * Uploads a Node.js Readable stream into a Data Lake file.
     * This method will try to create a file, then starts uploading chunk by chunk.
     * Please make sure potential size of stream doesn't exceed FILE_MAX_SIZE_BYTES and
     * potential number of chunks doesn't exceed BLOCK_BLOB_MAX_BLOCKS.
     *
     * PERFORMANCE IMPROVEMENT TIPS:
     * * Input stream highWaterMark is better to set a same value with options.chunkSize
     *   parameter, which will avoid Buffer.concat() operations.
     *
     * @param stream - Node.js Readable stream.
     * @param options -
     */
    async uploadStream(stream, options = {}) {
        var _a;
        const { span, updatedOptions } = createSpan("DataLakeFileClient-uploadStream", options);
        try {
            // Create the file
            await this.create({
                abortSignal: options.abortSignal,
                metadata: options.metadata,
                permissions: options.permissions,
                umask: options.umask,
                conditions: options.conditions,
                pathHttpHeaders: options.pathHttpHeaders,
                tracingOptions: updatedOptions.tracingOptions
            });
            // After the File is Create, Lease ID is the only valid request parameter.
            options.conditions = { leaseId: (_a = options.conditions) === null || _a === void 0 ? void 0 : _a.leaseId };
            if (!options.chunkSize) {
                options.chunkSize = FILE_UPLOAD_DEFAULT_CHUNK_SIZE;
            }
            if (options.chunkSize < 1 || options.chunkSize > FILE_UPLOAD_MAX_CHUNK_SIZE) {
                throw new RangeError(`chunkSize option must be >= 1 and <= ${FILE_UPLOAD_MAX_CHUNK_SIZE}`);
            }
            if (!options.maxConcurrency) {
                options.maxConcurrency = DEFAULT_HIGH_LEVEL_CONCURRENCY;
            }
            if (options.maxConcurrency <= 0) {
                throw new RangeError(`maxConcurrency must be > 0.`);
            }
            let transferProgress = 0;
            const scheduler = new BufferScheduler(stream, options.chunkSize, options.maxConcurrency, async (body, length, offset) => {
                await this.append(body, offset, length, {
                    abortSignal: options.abortSignal,
                    conditions: options.conditions,
                    tracingOptions: updatedOptions.tracingOptions
                });
                // Update progress after block is successfully uploaded to server, in case of block trying
                transferProgress += length;
                if (options.onProgress) {
                    options.onProgress({ loadedBytes: transferProgress });
                }
            }, 
            // concurrency should set a smaller value than maxConcurrency, which is helpful to
            // reduce the possibility when a outgoing handler waits for stream data, in
            // this situation, outgoing handlers are blocked.
            // Outgoing queue shouldn't be empty.
            Math.ceil((options.maxConcurrency / 4) * 3));
            await scheduler.do();
            return await this.flush(transferProgress, {
                abortSignal: options.abortSignal,
                conditions: options.conditions,
                close: options.close,
                pathHttpHeaders: options.pathHttpHeaders,
                tracingOptions: updatedOptions.tracingOptions
            });
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    async readToBuffer(bufferOrOffset, offsetOrCount, countOrOptions, optOptions = {}) {
        let buffer = undefined;
        let offset = 0;
        let count = 0;
        let options = optOptions;
        if (bufferOrOffset instanceof Buffer) {
            buffer = bufferOrOffset;
            offset = offsetOrCount || 0;
            count = typeof countOrOptions === "number" ? countOrOptions : 0;
        }
        else {
            offset = typeof bufferOrOffset === "number" ? bufferOrOffset : 0;
            count = typeof offsetOrCount === "number" ? offsetOrCount : 0;
            options = countOrOptions || {};
        }
        const { span, updatedOptions } = createSpan("DataLakeFileClient-readToBuffer", options);
        try {
            if (buffer) {
                return await this.blockBlobClientInternal.downloadToBuffer(buffer, offset, count, Object.assign(Object.assign({}, options), { maxRetryRequestsPerBlock: options.maxRetryRequestsPerChunk, blockSize: options.chunkSize, tracingOptions: updatedOptions.tracingOptions }));
            }
            else {
                return await this.blockBlobClientInternal.downloadToBuffer(offset, count, Object.assign(Object.assign({}, options), { maxRetryRequestsPerBlock: options.maxRetryRequestsPerChunk, blockSize: options.chunkSize, tracingOptions: updatedOptions.tracingOptions }));
            }
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * ONLY AVAILABLE IN NODE.JS RUNTIME.
     *
     * Downloads a Data Lake file to a local file.
     * Fails if the the given file path already exits.
     * Offset and count are optional, pass 0 and undefined respectively to download the entire file.
     *
     * @param filePath -
     * @param offset - From which position of the file to download.
     * @param count - How much data to be downloaded. Will download to the end when passing undefined.
     * @param options - Options to read Data Lake file.
     * @returns The response data for file read operation,
     *                                      but with readableStreamBody set to undefined since its
     *                                      content is already read and written into a local file
     *                                      at the specified path.
     */
    async readToFile(filePath, offset = 0, count, options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeFileClient-readToFile", options);
        try {
            return await this.blockBlobClientInternal.downloadToFile(filePath, offset, count, updatedOptions);
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Quick query for a JSON or CSV formatted file.
     *
     * Example usage (Node.js):
     *
     * ```js
     * // Query and convert a file to a string
     * const queryResponse = await fileClient.query("select * from BlobStorage");
     * const downloaded = (await streamToBuffer(queryResponse.readableStreamBody)).toString();
     * console.log("Query file content:", downloaded);
     *
     * async function streamToBuffer(readableStream) {
     *   return new Promise((resolve, reject) => {
     *     const chunks = [];
     *     readableStream.on("data", (data) => {
     *       chunks.push(data instanceof Buffer ? data : Buffer.from(data));
     *     });
     *     readableStream.on("end", () => {
     *       resolve(Buffer.concat(chunks));
     *     });
     *     readableStream.on("error", reject);
     *   });
     * }
     * ```
     *
     * @param query -
     * @param options -
     */
    async query(query, options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeFileClient-query", options);
        try {
            const rawResponse = await this.blockBlobClientInternal.query(query, updatedOptions);
            const response = rawResponse;
            if (!coreHttp.isNode && !response.contentAsBlob) {
                response.contentAsBlob = rawResponse.blobBody;
            }
            response.fileContentMD5 = rawResponse.blobContentMD5;
            response._response.parsedHeaders.fileContentMD5 =
                rawResponse._response.parsedHeaders.blobContentMD5;
            delete rawResponse.blobContentMD5;
            delete rawResponse._response.parsedHeaders.blobContentMD5;
            return response;
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Sets an expiry time on a file, once that time is met the file is deleted.
     *
     * @param mode -
     * @param options -
     */
    async setExpiry(mode, options = {}) {
        var _a;
        const { span, updatedOptions } = createSpan("DataLakeFileClient-setExpiry", options);
        try {
            let expiresOn = undefined;
            if (mode === "RelativeToNow" || mode === "RelativeToCreation") {
                if (!options.timeToExpireInMs) {
                    throw new Error(`Should specify options.timeToExpireInMs when using mode ${mode}.`);
                }
                // MINOR: need check against <= 2**64, but JS number has the precision problem.
                expiresOn = Math.round(options.timeToExpireInMs).toString();
            }
            if (mode === "Absolute") {
                if (!options.expiresOn) {
                    throw new Error(`Should specify options.expiresOn when using mode ${mode}.`);
                }
                const now = new Date();
                if (!(options.expiresOn.getTime() > now.getTime())) {
                    throw new Error(`options.expiresOn should be later than now: ${now.toUTCString()} when using mode ${mode}, but is ${(_a = options.expiresOn) === null || _a === void 0 ? void 0 : _a.toUTCString()}`);
                }
                expiresOn = options.expiresOn.toUTCString();
            }
            const adaptedOptions = Object.assign(Object.assign({}, options), { expiresOn });
            return await this.pathContextInternalToBlobEndpoint.setExpiry(mode, Object.assign(Object.assign({}, adaptedOptions), { tracingOptions: updatedOptions.tracingOptions }));
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Only available for clients constructed with a shared key credential.
     *
     * Generates a Service Shared Access Signature (SAS) URI based on the client properties
     * and parameters passed in. The SAS is signed by the shared key credential of the client.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas
     *
     * @param options - Optional parameters.
     * @returns The SAS URI consisting of the URI to the resource represented by this client, followed by the generated SAS token.
     */
    generateSasUrl(options) {
        return new Promise((resolve) => {
            if (!(this.credential instanceof StorageSharedKeyCredential)) {
                throw RangeError("Can only generate the SAS when the client is initialized with a shared key credential");
            }
            const sas = generateDataLakeSASQueryParameters(Object.assign({ fileSystemName: this.fileSystemName, pathName: this.name }, options), this.credential).toString();
            resolve(appendToURLQuery(this.url, sas));
        });
    }
}

// Copyright (c) Microsoft Corporation.
/**
 * A PathClientInternal represents a URL to the Azure Storage path (directory or file) to
 * help to construct a path client to expose Path context with blob endpoint.
 */
class PathClientInternal extends DataLakePathClient {
    /**
     * Creates an instance of DataLakePathClient from url and pipeline.
     *
     * @param url - A Client string pointing to Azure Storage data lake path (directory or file), such as
     *                     "https://myaccount.dfs.core.windows.net/filesystem/directory" or "https://myaccount.dfs.core.windows.net/filesystem/file".
     *                     You can append a SAS if using AnonymousCredential, such as "https://myaccount.dfs.core.windows.net/filesystem/directory?sasString".
     * @param pipeline - Call newPipeline() to create a default
     *                            pipeline, or provide a customized pipeline.
     */
    constructor(url, pipeline) {
        super(url, pipeline);
        this.blobPathContext = new Path$1(this.storageClientContextToBlobEndpoint);
    }
}

/**
 * A DataLakeFileSystemClient represents a URL to the Azure Storage file system
 * allowing you to manipulate its directories and files.
 */
class DataLakeFileSystemClient extends StorageClient {
    constructor(url, credentialOrPipeline, 
    // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options */
    options) {
        if (credentialOrPipeline instanceof Pipeline) {
            super(url, credentialOrPipeline);
        }
        else {
            let credential;
            if (credentialOrPipeline === undefined) {
                credential = new AnonymousCredential();
            }
            else {
                credential = credentialOrPipeline;
            }
            const pipeline = newPipeline(credential, options);
            super(url, pipeline);
        }
        this.fileSystemContext = new FileSystem$1(this.storageClientContext);
        this.fileSystemContextToBlobEndpoint = new FileSystem$1(this.storageClientContextToBlobEndpoint);
        this.blobContainerClient = new storageBlob.ContainerClient(this.blobEndpointUrl, this.pipeline);
    }
    /**
     * Name of current file system.
     *
     * @readonly
     */
    get name() {
        return this.blobContainerClient.containerName;
    }
    /**
     * Creates a {@link DataLakeDirectoryClient} object under current file system.
     *
     * @param directoryName -
     */
    // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-subclients */
    getDirectoryClient(directoryName) {
        return new DataLakeDirectoryClient(appendToURLPath(this.url, encodeURIComponent(directoryName)), this.pipeline);
    }
    /**
     * Creates a {@link DataLakeFileClient} object under current file system.
     *
     * @param fileName -
     */
    // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-subclients */
    getFileClient(fileName) {
        return new DataLakeFileClient(appendToURLPath(this.url, encodeURIComponent(fileName)), this.pipeline);
    }
    /**
     * Get a {@link DataLakeLeaseClient} that manages leases on the file system.
     *
     * @param proposeLeaseId - Optional. Initial proposed lease Id.
     */
    getDataLakeLeaseClient(proposeLeaseId) {
        return new DataLakeLeaseClient(this.blobContainerClient.getBlobLeaseClient(proposeLeaseId));
    }
    /**
     * Creates a new file system under the specified account. If the file system with
     * the same name already exists, the operation fails.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/create-container
     *
     * @param options - Optional. Options when creating file system.
     */
    async create(options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeFileSystemClient-create", options);
        try {
            return await this.blobContainerClient.create(Object.assign(Object.assign({}, options), { access: toContainerPublicAccessType(options.access), tracingOptions: updatedOptions.tracingOptions }));
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Creates a new file system under the specified account. If the file system with
     * the same name already exists, it is not changed.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/create-container
     *
     * @param options -
     */
    async createIfNotExists(options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeFileSystemClient-createIfNotExists", options);
        try {
            return await this.blobContainerClient.createIfNotExists(Object.assign(Object.assign({}, options), { access: toContainerPublicAccessType(options.access), tracingOptions: updatedOptions.tracingOptions }));
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Returns true if the File system represented by this client exists; false otherwise.
     *
     * NOTE: use this function with care since an existing file system might be deleted by other clients or
     * applications. Vice versa new file system with the same name might be added by other clients or
     * applications after this function completes.
     *
     * @param options -
     */
    async exists(options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeFileSystemClient-exists", options);
        try {
            return await this.blobContainerClient.exists(updatedOptions);
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Delete current file system.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/delete-container
     *
     * @param options - Optional. Options when deleting file system.
     */
    async delete(options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeFileSystemClient-delete", options);
        try {
            return await this.blobContainerClient.delete(Object.assign(Object.assign({}, options), { tracingOptions: updatedOptions.tracingOptions }));
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Delete current file system if it exists.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/delete-container
     *
     * @param options -
     */
    async deleteIfExists(options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeFileSystemClient-deleteIfExists", options);
        try {
            return await this.blobContainerClient.deleteIfExists(updatedOptions);
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Returns all user-defined metadata and system properties for the specified
     * file system.
     *
     * WARNING: The `metadata` object returned in the response will have its keys in lowercase, even if
     * they originally contained uppercase characters. This differs from the metadata keys returned by
     * the `listFileSystems` method of {@link DataLakeServiceClient} using the `includeMetadata` option, which
     * will retain their original casing.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-container-properties
     *
     * @param options - Optional. Options when getting file system properties.
     */
    async getProperties(options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeFileSystemClient-getProperties", options);
        try {
            const rawResponse = await this.blobContainerClient.getProperties(Object.assign(Object.assign({}, options), { tracingOptions: updatedOptions.tracingOptions }));
            // Transfer and rename blobPublicAccess to publicAccess
            const response = rawResponse;
            response.publicAccess = toPublicAccessType(rawResponse.blobPublicAccess);
            response._response.parsedHeaders.publicAccess = response.publicAccess;
            delete rawResponse.blobPublicAccess;
            delete rawResponse._response.parsedHeaders.blobPublicAccess;
            return response;
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Sets one or more user-defined name-value pairs for the specified file system.
     *
     * If no option provided, or no metadata defined in the parameter, the file system
     * metadata will be removed.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-container-metadata
     *
     * @param metadata - Replace existing metadata with this value.
     *                              If no value provided the existing metadata will be removed.
     * @param options - Optional. Options when setting file system metadata.
     */
    async setMetadata(metadata, options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeFileSystemClient-setMetadata", options);
        try {
            return await this.blobContainerClient.setMetadata(metadata, Object.assign(Object.assign({}, options), { tracingOptions: updatedOptions.tracingOptions }));
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Gets the permissions for the specified file system. The permissions indicate
     * whether file system data may be accessed publicly.
     *
     * WARNING: JavaScript Date will potentially lose precision when parsing startsOn and expiresOn strings.
     * For example, new Date("2018-12-31T03:44:23.8827891Z").toISOString() will get "2018-12-31T03:44:23.882Z".
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-container-acl
     *
     * @param options - Optional. Options when getting file system access policy.
     */
    async getAccessPolicy(options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeFileSystemClient-getAccessPolicy", options);
        try {
            const rawResponse = await this.blobContainerClient.getAccessPolicy(Object.assign(Object.assign({}, options), { tracingOptions: updatedOptions.tracingOptions }));
            // Transfer and rename blobPublicAccess to publicAccess
            const response = rawResponse;
            response.publicAccess = toPublicAccessType(rawResponse.blobPublicAccess);
            response._response.parsedHeaders.publicAccess = response.publicAccess;
            delete rawResponse.blobPublicAccess;
            delete rawResponse._response.parsedHeaders.blobPublicAccess;
            return response;
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Sets the permissions for the specified file system. The permissions indicate
     * whether directories or files in a file system may be accessed publicly.
     *
     * When you set permissions for a file system, the existing permissions are replaced.
     * If no access or containerAcl provided, the existing file system ACL will be
     * removed.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-container-acl
     *
     * @param access - Optional. The level of public access to data in the file system.
     * @param fileSystemAcl - Optional. Array of elements each having a unique Id and details of the access policy.
     * @param options - Optional. Options when setting file system access policy.
     */
    async setAccessPolicy(access, fileSystemAcl, options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeFileSystemClient-setAccessPolicy", options);
        try {
            return await this.blobContainerClient.setAccessPolicy(toContainerPublicAccessType(access), fileSystemAcl, Object.assign(Object.assign({}, options), { tracingOptions: updatedOptions.tracingOptions }));
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Returns an async iterable iterator to list all the paths (directories and files)
     * under the specified file system.
     *
     * .byPage() returns an async iterable iterator to list the paths in pages.
     *
     * Example using `for await` syntax:
     *
     * ```js
     * // Get the fileSystemClient before you run these snippets,
     * // Can be obtained from `serviceClient.getFileSystemClient("<your-filesystem-name>");`
     * let i = 1;
     * for await (const path of fileSystemClient.listPaths()) {
     *   console.log(`Path ${i++}: ${path.name}, isDirectory?: ${path.isDirectory}`);
     * }
     * ```
     *
     * Example using `iter.next()`:
     *
     * ```js
     * let i = 1;
     * let iter = fileSystemClient.listPaths();
     * let pathItem = await iter.next();
     * while (!pathItem.done) {
     *   console.log(`Path ${i++}: ${pathItem.value.name}, isDirectory?: ${pathItem.value.isDirectory}`);
     *   pathItem = await iter.next();
     * }
     * ```
     *
     * Example using `byPage()`:
     *
     * ```js
     * // passing optional maxPageSize in the page settings
     * let i = 1;
     * for await (const response of fileSystemClient.listPaths().byPage({ maxPageSize: 20 })) {
     *   for (const path of response.pathItems) {
     *     console.log(`Path ${i++}: ${path.name}, isDirectory?: ${path.isDirectory}`);
     *   }
     * }
     * ```
     *
     * Example using paging with a marker:
     *
     * ```js
     * let i = 1;
     * let iterator = fileSystemClient.listPaths().byPage({ maxPageSize: 2 });
     * let response = (await iterator.next()).value;
     *
     * // Prints 2 path names
     * for (const path of response.pathItems) {
     *   console.log(`Path ${i++}: ${path.name}, isDirectory?: ${path.isDirectory}`);
     * }
     *
     * // Gets next marker
     * let marker = response.continuationToken;
     *
     * // Passing next marker as continuationToken
     *
     * iterator = fileSystemClient.listPaths().byPage({ continuationToken: marker, maxPageSize: 10 });
     * response = (await iterator.next()).value;
     *
     * // Prints 10 path names
     * for (const path of response.pathItems) {
     *   console.log(`Path ${i++}: ${path.name}, isDirectory?: ${path.isDirectory}`);
     * }
     * ```
     *
     * @see https://docs.microsoft.com/rest/api/storageservices/list-blobs
     *
     * @param options - Optional. Options when listing paths.
     */
    listPaths(options = {}) {
        options.path = options.path === "" ? undefined : options.path;
        const iter = this.listItems(options);
        return {
            next() {
                return iter.next();
            },
            [Symbol.asyncIterator]() {
                return this;
            },
            byPage: (settings = {}) => {
                return this.listSegments(settings.continuationToken, Object.assign({ maxResults: settings.maxPageSize }, options));
            }
        };
    }
    listItems(options = {}) {
        return tslib.__asyncGenerator(this, arguments, function* listItems_1() {
            var e_1, _a;
            try {
                for (var _b = tslib.__asyncValues(this.listSegments(undefined, options)), _c; _c = yield tslib.__await(_b.next()), !_c.done;) {
                    const response = _c.value;
                    yield tslib.__await(yield* tslib.__asyncDelegator(tslib.__asyncValues(response.pathItems || [])));
                }
            }
            catch (e_1_1) { e_1 = { error: e_1_1 }; }
            finally {
                try {
                    if (_c && !_c.done && (_a = _b.return)) yield tslib.__await(_a.call(_b));
                }
                finally { if (e_1) throw e_1.error; }
            }
        });
    }
    listSegments(continuation, options = {}) {
        return tslib.__asyncGenerator(this, arguments, function* listSegments_1() {
            let response;
            if (!!continuation || continuation === undefined) {
                do {
                    response = yield tslib.__await(this.listPathsSegment(continuation, options));
                    continuation = response.continuation;
                    yield yield tslib.__await(response);
                } while (continuation);
            }
        });
    }
    async listPathsSegment(continuation, options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeFileSystemClient-listPathsSegment", options);
        try {
            const rawResponse = await this.fileSystemContext.listPaths(options.recursive || false, Object.assign(Object.assign(Object.assign({ continuation }, options), { upn: options.userPrincipalName }), convertTracingToRequestOptionsBase(updatedOptions)));
            const response = rawResponse;
            response.pathItems = [];
            for (const path of rawResponse.paths || []) {
                response.pathItems.push(Object.assign(Object.assign({}, path), { permissions: toPermissions(path.permissions) }));
            }
            delete rawResponse.paths;
            return response;
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Returns an async iterable iterator to list all the paths (directories and files)
     * under the specified file system.
     *
     * .byPage() returns an async iterable iterator to list the paths in pages.
     *
     * Example using `for await` syntax:
     *
     * ```js
     * // Get the fileSystemClient before you run these snippets,
     * // Can be obtained from `serviceClient.getFileSystemClient("<your-filesystem-name>");`
     * let i = 1;
     * for await (const deletePath of fileSystemClient.listDeletedPaths()) {
     *   console.log(`Path ${i++}: ${deletePath.name}`);
     * }
     * ```
     *
     * Example using `iter.next()`:
     *
     * ```js
     * let i = 1;
     * let iter = fileSystemClient.listDeletedPaths();
     * let deletedPathItem = await iter.next();
     * while (!deletedPathItem.done) {
     *   console.log(`Path ${i++}: ${deletedPathItem.value.name}`);
     *   pathItem = await iter.next();
     * }
     * ```
     *
     * Example using `byPage()`:
     *
     * ```js
     * // passing optional maxPageSize in the page settings
     * let i = 1;
     * for await (const response of fileSystemClient.listDeletedPaths().byPage({ maxPageSize: 20 })) {
     *   for (const deletePath of response.pathItems) {
     *     console.log(`Path ${i++}: ${deletePath.name}`);
     *   }
     * }
     * ```
     *
     * Example using paging with a marker:
     *
     * ```js
     * let i = 1;
     * let iterator = fileSystemClient.listDeletedPaths().byPage({ maxPageSize: 2 });
     * let response = (await iterator.next()).value;
     *
     * // Prints 2 path names
     * for (const path of response.pathItems) {
     *   console.log(`Path ${i++}: ${path.name}}`);
     * }
     *
     * // Gets next marker
     * let marker = response.continuationToken;
     *
     * // Passing next marker as continuationToken
     *
     * iterator = fileSystemClient.listDeletedPaths().byPage({ continuationToken: marker, maxPageSize: 10 });
     * response = (await iterator.next()).value;
     *
     * // Prints 10 path names
     * for (const deletePath of response.deletedPathItems) {
     *   console.log(`Path ${i++}: ${deletePath.name}`);
     * }
     * ```
     *
     * @see https://docs.microsoft.com/rest/api/storageservices/list-blobs
     *
     * @param options - Optional. Options when listing deleted paths.
     */
    listDeletedPaths(options = {}) {
        const iter = this.listDeletedItems(options);
        return {
            next() {
                return iter.next();
            },
            [Symbol.asyncIterator]() {
                return this;
            },
            byPage: (settings = {}) => {
                return this.listDeletedSegments(settings.continuationToken, Object.assign({ maxResults: settings.maxPageSize }, options));
            }
        };
    }
    listDeletedItems(options = {}) {
        return tslib.__asyncGenerator(this, arguments, function* listDeletedItems_1() {
            var e_2, _a;
            try {
                for (var _b = tslib.__asyncValues(this.listDeletedSegments(undefined, options)), _c; _c = yield tslib.__await(_b.next()), !_c.done;) {
                    const response = _c.value;
                    yield tslib.__await(yield* tslib.__asyncDelegator(tslib.__asyncValues(response.pathItems || [])));
                }
            }
            catch (e_2_1) { e_2 = { error: e_2_1 }; }
            finally {
                try {
                    if (_c && !_c.done && (_a = _b.return)) yield tslib.__await(_a.call(_b));
                }
                finally { if (e_2) throw e_2.error; }
            }
        });
    }
    listDeletedSegments(continuation, options = {}) {
        return tslib.__asyncGenerator(this, arguments, function* listDeletedSegments_1() {
            let response;
            if (!!continuation || continuation === undefined) {
                do {
                    response = yield tslib.__await(this.listDeletedPathsSegment(continuation, options));
                    continuation = response.continuation;
                    yield yield tslib.__await(response);
                } while (continuation);
            }
        });
    }
    async listDeletedPathsSegment(continuation, options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeFileSystemClient-listDeletedPathsSegment", options);
        try {
            const rawResponse = await this.fileSystemContextToBlobEndpoint.listBlobHierarchySegment(Object.assign(Object.assign(Object.assign({ marker: continuation }, options), { prefix: options.prefix === "" ? undefined : options.prefix }), convertTracingToRequestOptionsBase(updatedOptions)));
            const response = rawResponse;
            response.pathItems = [];
            for (const path of rawResponse.segment.blobItems || []) {
                response.pathItems.push({
                    name: path.name,
                    deletionId: path.deletionId,
                    deletedOn: path.properties.deletedTime,
                    remainingRetentionDays: path.properties.remainingRetentionDays
                });
            }
            if (!(response.nextMarker === undefined || response.nextMarker === "")) {
                response.continuation = response.nextMarker;
            }
            return response;
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Restores a soft deleted path.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/undelete-blob
     *
     * @param deletedPath - Required.  The path of the deleted path.
     *
     * @param deletionId - Required.  The deletion ID associated with the soft deleted path.
     *
     */
    async undeletePath(deletedPath, deletionId, options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeFileSystemClient-undeletePath", options);
        try {
            const pathClient = new PathClientInternal(appendToURLPath(this.blobEndpointUrl, encodeURIComponent(deletedPath)), this.pipeline);
            const rawResponse = await pathClient.blobPathContext.undelete(Object.assign(Object.assign({ undeleteSource: "?" + DeletionIdKey + "=" + deletionId }, options), { tracingOptions: updatedOptions.tracingOptions }));
            if (rawResponse.resourceType === PathResultTypeConstants.DirectoryResourceType) {
                return Object.assign({ pathClient: this.getDirectoryClient(deletedPath) }, rawResponse);
            }
            else {
                return Object.assign({ pathClient: this.getFileClient(deletedPath) }, rawResponse);
            }
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Only available for DataLakeFileSystemClient constructed with a shared key credential.
     *
     * Generates a Service Shared Access Signature (SAS) URI based on the client properties
     * and parameters passed in. The SAS is signed by the shared key credential of the client.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-a-service-sas
     *
     * @param options - Optional parameters.
     * @returns The SAS URI consisting of the URI to the resource represented by this client, followed by the generated SAS token.
     */
    generateSasUrl(options) {
        return new Promise((resolve) => {
            if (!(this.credential instanceof StorageSharedKeyCredential)) {
                throw RangeError("Can only generate the SAS when the client is initialized with a shared key credential");
            }
            const sas = generateDataLakeSASQueryParameters(Object.assign({ fileSystemName: this.name }, options), this.credential).toString();
            resolve(appendToURLQuery(this.url, sas));
        });
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * This is a helper class to construct a string representing the permissions granted by an AccountSAS. Setting a value
 * to true means that any SAS which uses these permissions will grant permissions for that operation. Once all the
 * values are set, this should be serialized with toString and set as the permissions field on an
 * {@link AccountSASSignatureValues} object. It is possible to construct the permissions string without this class, but
 * the order of the permissions is particular and this class guarantees correctness.
 */
class AccountSASPermissions {
    constructor() {
        /**
         * Permission to read resources and list queues and tables granted.
         */
        this.read = false;
        /**
         * Permission to write resources granted.
         */
        this.write = false;
        /**
         * Permission to delete blobs and files granted.
         */
        this.delete = false;
        /**
         * Permission to list blob containers, blobs, shares, directories, and files granted.
         */
        this.list = false;
        /**
         * Permission to add messages, table entities, and append to blobs granted.
         */
        this.add = false;
        /**
         * Permission to create blobs and files granted.
         */
        this.create = false;
        /**
         * Permissions to update messages and table entities granted.
         */
        this.update = false;
        /**
         * Permission to get and delete messages granted.
         */
        this.process = false;
    }
    /**
     * Parse initializes the AccountSASPermissions fields from a string.
     *
     * @param permissions -
     */
    static parse(permissions) {
        const accountSASPermissions = new AccountSASPermissions();
        for (const c of permissions) {
            switch (c) {
                case "r":
                    accountSASPermissions.read = true;
                    break;
                case "w":
                    accountSASPermissions.write = true;
                    break;
                case "d":
                    accountSASPermissions.delete = true;
                    break;
                case "l":
                    accountSASPermissions.list = true;
                    break;
                case "a":
                    accountSASPermissions.add = true;
                    break;
                case "c":
                    accountSASPermissions.create = true;
                    break;
                case "u":
                    accountSASPermissions.update = true;
                    break;
                case "p":
                    accountSASPermissions.process = true;
                    break;
                default:
                    throw new RangeError(`Invalid permission character: ${c}`);
            }
        }
        return accountSASPermissions;
    }
    /**
     * Produces the SAS permissions string for an Azure Storage account.
     * Call this method to set AccountSASSignatureValues Permissions field.
     *
     * Using this method will guarantee the resource types are in
     * an order accepted by the service.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-an-account-sas
     *
     */
    toString() {
        // The order of the characters should be as specified here to ensure correctness:
        // https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-an-account-sas
        // Use a string array instead of string concatenating += operator for performance
        const permissions = [];
        if (this.read) {
            permissions.push("r");
        }
        if (this.write) {
            permissions.push("w");
        }
        if (this.delete) {
            permissions.push("d");
        }
        if (this.list) {
            permissions.push("l");
        }
        if (this.add) {
            permissions.push("a");
        }
        if (this.create) {
            permissions.push("c");
        }
        if (this.update) {
            permissions.push("u");
        }
        if (this.process) {
            permissions.push("p");
        }
        return permissions.join("");
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * This is a helper class to construct a string representing the resources accessible by an AccountSAS. Setting a value
 * to true means that any SAS which uses these permissions will grant access to that resource type. Once all the
 * values are set, this should be serialized with toString and set as the resources field on an
 * {@link AccountSASSignatureValues} object. It is possible to construct the resources string without this class, but
 * the order of the resources is particular and this class guarantees correctness.
 */
class AccountSASResourceTypes {
    constructor() {
        /**
         * Permission to access service level APIs granted.
         */
        this.service = false;
        /**
         * Permission to access container level APIs (Blob Containers, Tables, Queues, File Shares, File Systems) granted.
         */
        this.container = false;
        /**
         * Permission to access object level APIs (Blobs, Table Entities, Queue Messages, Files, Directories) granted.
         */
        this.object = false;
    }
    /**
     * Creates an {@link AccountSASResourceTypes} from the specified resource types string. This method will throw an
     * Error if it encounters a character that does not correspond to a valid resource type.
     *
     * @param resourceTypes -
     */
    static parse(resourceTypes) {
        const accountSASResourceTypes = new AccountSASResourceTypes();
        for (const c of resourceTypes) {
            switch (c) {
                case "s":
                    accountSASResourceTypes.service = true;
                    break;
                case "c":
                    accountSASResourceTypes.container = true;
                    break;
                case "o":
                    accountSASResourceTypes.object = true;
                    break;
                default:
                    throw new RangeError(`Invalid resource type: ${c}`);
            }
        }
        return accountSASResourceTypes;
    }
    /**
     * Converts the given resource types to a string.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-an-account-sas
     *
     */
    toString() {
        const resourceTypes = [];
        if (this.service) {
            resourceTypes.push("s");
        }
        if (this.container) {
            resourceTypes.push("c");
        }
        if (this.object) {
            resourceTypes.push("o");
        }
        return resourceTypes.join("");
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * This is a helper class to construct a string representing the services accessible by an AccountSAS. Setting a value
 * to true means that any SAS which uses these permissions will grant access to that service. Once all the
 * values are set, this should be serialized with toString and set as the services field on an
 * {@link AccountSASSignatureValues} object. It is possible to construct the services string without this class, but
 * the order of the services is particular and this class guarantees correctness.
 */
class AccountSASServices {
    constructor() {
        /**
         * Permission to access blob and data lake resources granted.
         */
        this.blob = false;
        /**
         * Permission to access file resources granted.
         */
        this.file = false;
        /**
         * Permission to access queue resources granted.
         */
        this.queue = false;
        /**
         * Permission to access table resources granted.
         */
        this.table = false;
    }
    /**
     * Creates an {@link AccountSASServices} from the specified services string. This method will throw an
     * Error if it encounters a character that does not correspond to a valid service.
     *
     * @param services -
     */
    static parse(services) {
        const accountSASServices = new AccountSASServices();
        for (const c of services) {
            switch (c) {
                case "b":
                    accountSASServices.blob = true;
                    break;
                case "f":
                    accountSASServices.file = true;
                    break;
                case "q":
                    accountSASServices.queue = true;
                    break;
                case "t":
                    accountSASServices.table = true;
                    break;
                default:
                    throw new RangeError(`Invalid service character: ${c}`);
            }
        }
        return accountSASServices;
    }
    /**
     * Converts the given services to a string.
     *
     */
    toString() {
        const services = [];
        if (this.blob) {
            services.push("b");
        }
        if (this.table) {
            services.push("t");
        }
        if (this.queue) {
            services.push("q");
        }
        if (this.file) {
            services.push("f");
        }
        return services.join("");
    }
}

// Copyright (c) Microsoft Corporation.
/**
 * ONLY AVAILABLE IN NODE.JS RUNTIME.
 *
 * Generates a {@link SASQueryParameters} object which contains all SAS query parameters needed to make an actual
 * REST request.
 *
 * @see https://docs.microsoft.com/en-us/rest/api/storageservices/constructing-an-account-sas
 *
 * @param accountSASSignatureValues -
 * @param sharedKeyCredential -
 */
function generateAccountSASQueryParameters(accountSASSignatureValues, sharedKeyCredential) {
    const version = accountSASSignatureValues.version
        ? accountSASSignatureValues.version
        : SERVICE_VERSION;
    const parsedPermissions = AccountSASPermissions.parse(accountSASSignatureValues.permissions.toString());
    const parsedServices = AccountSASServices.parse(accountSASSignatureValues.services).toString();
    const parsedResourceTypes = AccountSASResourceTypes.parse(accountSASSignatureValues.resourceTypes).toString();
    const stringToSign = [
        sharedKeyCredential.accountName,
        parsedPermissions,
        parsedServices,
        parsedResourceTypes,
        accountSASSignatureValues.startsOn
            ? truncatedISO8061Date(accountSASSignatureValues.startsOn, false)
            : "",
        truncatedISO8061Date(accountSASSignatureValues.expiresOn, false),
        accountSASSignatureValues.ipRange ? ipRangeToString(accountSASSignatureValues.ipRange) : "",
        accountSASSignatureValues.protocol ? accountSASSignatureValues.protocol : "",
        version,
        "" // Account SAS requires an additional newline character
    ].join("\n");
    const signature = sharedKeyCredential.computeHMACSHA256(stringToSign);
    return new SASQueryParameters(version, signature, parsedPermissions.toString(), parsedServices, parsedResourceTypes, accountSASSignatureValues.protocol, accountSASSignatureValues.startsOn, accountSASSignatureValues.expiresOn, accountSASSignatureValues.ipRange);
}

// Copyright (c) Microsoft Corporation.
/**
 * DataLakeServiceClient allows you to manipulate Azure
 * Data Lake service resources and file systems. The storage account provides
 * the top-level namespace for the Data Lake service.
 */
class DataLakeServiceClient extends StorageClient {
    constructor(url, credentialOrPipeline, 
    // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options */
    options) {
        if (credentialOrPipeline instanceof Pipeline) {
            super(url, credentialOrPipeline);
        }
        else {
            let credential;
            if (credentialOrPipeline === undefined) {
                credential = new AnonymousCredential();
            }
            else {
                credential = credentialOrPipeline;
            }
            const pipeline = newPipeline(credential, options);
            super(url, pipeline);
        }
        // this.serviceContext = new Service(this.storageClientContext);
        this.blobServiceClient = new storageBlob.BlobServiceClient(this.blobEndpointUrl, this.pipeline);
    }
    /**
     *
     * Creates an instance of DataLakeServiceClient from connection string.
     *
     * @param connectionString - Account connection string or a SAS connection string of an Azure storage account.
     *                                  [ Note - Account connection string can only be used in NODE.JS runtime. ]
     *                                  Account connection string example -
     *                                  `DefaultEndpointsProtocol=https;AccountName=myaccount;AccountKey=accountKey;EndpointSuffix=core.windows.net`
     *                                  SAS connection string example -
     *                                  `BlobEndpoint=https://myaccount.blob.core.windows.net/;QueueEndpoint=https://myaccount.queue.core.windows.net/;FileEndpoint=https://myaccount.file.core.windows.net/;TableEndpoint=https://myaccount.table.core.windows.net/;SharedAccessSignature=sasString`
     * @param options - Optional. Options to configure the HTTP pipeline.
     */
    // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options */
    static fromConnectionString(connectionString, 
    // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-options */
    options) {
        options = options || {};
        const extractedCreds = extractConnectionStringParts(connectionString);
        if (extractedCreds.kind === "AccountConnString") {
            {
                const sharedKeyCredential = new StorageSharedKeyCredential(extractedCreds.accountName, extractedCreds.accountKey);
                options.proxyOptions = coreHttp.getDefaultProxySettings(extractedCreds.proxyUri);
                const pipeline = newPipeline(sharedKeyCredential, options);
                return new DataLakeServiceClient(toDfsEndpointUrl(extractedCreds.url), pipeline);
            }
        }
        else if (extractedCreds.kind === "SASConnString") {
            const pipeline = newPipeline(new AnonymousCredential(), options);
            return new DataLakeServiceClient(toDfsEndpointUrl(extractedCreds.url) + "?" + extractedCreds.accountSas, pipeline);
        }
        else {
            throw new Error("Connection string must be either an Account connection string or a SAS connection string");
        }
    }
    /**
     * Creates a {@link DataLakeFileSystemClient} object.
     *
     * @param fileSystemName - File system name.
     */
    // Legacy, no way to fix the eslint error without breaking. Disable the rule for this line.
    /* eslint-disable-next-line @azure/azure-sdk/ts-naming-subclients */
    getFileSystemClient(fileSystemName) {
        return new DataLakeFileSystemClient(appendToURLPath(this.url, encodeURIComponent(fileSystemName)), this.pipeline);
    }
    /**
     * ONLY AVAILABLE WHEN USING BEARER TOKEN AUTHENTICATION (TokenCredential).
     *
     * Retrieves a user delegation key for the Data Lake service. This is only a valid operation when using
     * bearer token authentication.
     *
     * @example
     * ```js
     * // Generate user delegation SAS for a file system
     * const userDelegationKey = await dataLakeServiceClient.getUserDelegationKey(startsOn, expiresOn);
     * const fileSystemSAS = generateDataLakeSASQueryParameters({
     *     fileSystemName, // Required
     *     permissions: FileSystemSASPermissions.parse("racwdl"), // Required
     *     startsOn, // Required. Date type
     *     expiresOn, // Optional. Date type
     *     ipRange: { start: "0.0.0.0", end: "255.255.255.255" }, // Optional
     *     protocol: SASProtocol.HttpsAndHttp, // Optional
     *     version: "2018-11-09" // Must greater than or equal to 2018-11-09 to generate user delegation SAS
     *   },
     *   userDelegationKey, // UserDelegationKey
     *   accountName
     * ).toString();
     * ```
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-user-delegation-key
     *
     * @param startsOn - The start time for the user delegation SAS. Must be within 7 days of the current time.
     * @param expiresOn - The end time for the user delegation SAS. Must be within 7 days of the current time.
     * @param options -
     */
    async getUserDelegationKey(startsOn, expiresOn, options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeServiceClient-getUserDelegationKey", options);
        try {
            return await this.blobServiceClient.getUserDelegationKey(startsOn, expiresOn, updatedOptions);
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Returns an async iterable iterator to list all the file systems
     * under the specified account.
     *
     * .byPage() returns an async iterable iterator to list the file systems in pages.
     *
     * Example using `for await` syntax:
     *
     * ```js
     * let i = 1;
     * for await (const fileSystem of serviceClient.listFileSystems()) {
     *   console.log(`FileSystem ${i++}: ${fileSystem.name}`);
     * }
     * ```
     *
     * Example using `iter.next()`:
     *
     * ```js
     * let i = 1;
     * const iter = serviceClient.listFileSystems();
     * let fileSystemItem = await iter.next();
     * while (!fileSystemItem.done) {
     *   console.log(`FileSystem ${i++}: ${fileSystemItem.value.name}`);
     *   fileSystemItem = await iter.next();
     * }
     * ```
     *
     * Example using `byPage()`:
     *
     * ```js
     * // passing optional maxPageSize in the page settings
     * let i = 1;
     * for await (const response of serviceClient.listFileSystems().byPage({ maxPageSize: 20 })) {
     *   if (response.fileSystemItems) {
     *     for (const fileSystem of response.fileSystemItems) {
     *       console.log(`FileSystem ${i++}: ${fileSystem.name}`);
     *     }
     *   }
     * }
     * ```
     *
     * Example using paging with a marker:
     *
     * ```js
     * let i = 1;
     * let iterator = serviceClient.listFileSystems().byPage({ maxPageSize: 2 });
     * let response = (await iterator.next()).value;
     *
     * // Prints 2 file system names
     * if (response.fileSystemItems) {
     *   for (const fileSystem of response.fileSystemItems) {
     *     console.log(`FileSystem ${i++}: ${fileSystem.name}`);
     *   }
     * }
     *
     * // Gets next marker
     * let marker = response.continuationToken;
     * // Passing next marker as continuationToken
     * iterator = serviceClient
     *   .listContainers()
     *   .byPage({ continuationToken: marker, maxPageSize: 10 });
     * response = (await iterator.next()).value;
     *
     * // Prints 10 file system names
     * if (response.fileSystemItems) {
     *   for (const fileSystem of response.fileSystemItems) {
     *      console.log(`FileSystem ${i++}: ${fileSystem.name}`);
     *   }
     * }
     * ```
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/list-containers2
     *
     * @param options -
     */
    listFileSystems(options = {}) {
        return toFileSystemPagedAsyncIterableIterator(this.blobServiceClient.listContainers(options));
    }
    // public async createFileSystem(): Promise<DataLakeFileSystemClient> {
    //   throw Error("NotImplemented");
    // }
    // public async deleteFileSystem(fileSystem: string): Promise<ServiceDeleteFileSystemResponse> {
    //   throw Error("NotImplemented");
    // }
    /**
     * Only available for DataLakeServiceClient constructed with a shared key credential.
     *
     * Generates an account Shared Access Signature (SAS) URI based on the client properties
     * and parameters passed in. The SAS is signed by the shared key credential of the client.
     *
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/create-account-sas
     *
     * @param expiresOn - Optional. The time at which the shared access signature becomes invalid. Default to an hour later if not specified.
     * @param permissions - Specifies the list of permissions to be associated with the SAS.
     * @param resourceTypes - Specifies the resource types associated with the shared access signature.
     * @param options - Optional parameters.
     * @returns An account SAS URI consisting of the URI to the resource represented by this client, followed by the generated SAS token.
     */
    generateAccountSasUrl(expiresOn, permissions = AccountSASPermissions.parse("r"), resourceTypes = "sco", options = {}) {
        if (!(this.credential instanceof StorageSharedKeyCredential)) {
            throw RangeError("Can only generate the account SAS when the client is initialized with a shared key credential");
        }
        if (expiresOn === undefined) {
            const now = new Date();
            expiresOn = new Date(now.getTime() + 3600 * 1000);
        }
        const sas = generateAccountSASQueryParameters(Object.assign({ permissions,
            expiresOn,
            resourceTypes, services: AccountSASServices.parse("b").toString() }, options), this.credential).toString();
        return appendToURLQuery(this.url, sas);
    }
    /**
     * Renames an existing File System.
     *
     * @param sourceFileSystemName - The name of the source File System.
     * @param destinationContainerName - The new name of the File System.
     * @param options - Options to configure File System Rename operation.
     */
    /* eslint-disable-next-line @typescript-eslint/ban-ts-comment */
    // @ts-ignore Need to hide this interface for now. Make it public and turn on the live tests for it when the service is ready.
    async renameFileSystem(sourceFileSystemName, destinationFileSystemName, options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeServiceClient-renameFileSystem", options);
        try {
            // const res = await this.blobServiceClient.renameContainer(
            const res = await this.blobServiceClient["renameContainer"](sourceFileSystemName, destinationFileSystemName, updatedOptions);
            const fileSystemClient = this.getFileSystemClient(destinationFileSystemName);
            return {
                fileSystemClient,
                fileSystemRenameResponse: res.containerRenameResponse
            };
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Restore a previously deleted File System.
     * This API is only functional if Container Soft Delete is enabled for the storage account.
     *
     * @param deletedFileSystemName - The name of the source File System.
     * @param deleteFileSystemVersion - The new name of the File System.
     * @param options - Options to configure File System Restore operation.
     */
    async undeleteFileSystem(deletedFileSystemName, deleteFileSystemVersion, options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeServiceClient-undeleteFileSystem", options);
        try {
            const res = await this.blobServiceClient.undeleteContainer(deletedFileSystemName, deleteFileSystemVersion, Object.assign(Object.assign({}, options), { destinationContainerName: options.destinationFileSystemName, tracingOptions: updatedOptions.tracingOptions }));
            const fileSystemClient = this.getFileSystemClient(options.destinationFileSystemName || deletedFileSystemName);
            return {
                fileSystemClient,
                fileSystemUndeleteResponse: res.containerUndeleteResponse
            };
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Gets the properties of a storage account’s Blob service endpoint, including properties
     * for Storage Analytics and CORS (Cross-Origin Resource Sharing) rules.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/get-blob-service-properties
     *
     * @param options - Options to the Service Get Properties operation.
     * @returns Response data for the Service Get Properties operation.
     */
    async getProperties(options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeServiceClient-getProperties", options);
        try {
            return await this.blobServiceClient.getProperties({
                abortSignal: options.abortSignal,
                tracingOptions: updatedOptions.tracingOptions
            });
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
    /**
     * Sets properties for a storage account’s Blob service endpoint, including properties
     * for Storage Analytics, CORS (Cross-Origin Resource Sharing) rules and soft delete settings.
     * @see https://docs.microsoft.com/en-us/rest/api/storageservices/set-blob-service-properties
     *
     * @param properties -
     * @param options - Options to the Service Set Properties operation.
     * @returns Response data for the Service Set Properties operation.
     */
    async setProperties(properties, options = {}) {
        const { span, updatedOptions } = createSpan("DataLakeServiceClient-setProperties", options);
        try {
            return await this.blobServiceClient.setProperties(properties, {
                abortSignal: options.abortSignal,
                tracingOptions: updatedOptions.tracingOptions
            });
        }
        catch (e) {
            span.setStatus({
                code: coreTracing.SpanStatusCode.ERROR,
                message: e.message
            });
            throw e;
        }
        finally {
            span.end();
        }
    }
}

// Keeping these for backward compatibility when we changed to use string unions.
(function (PathGetPropertiesAction) {
    PathGetPropertiesAction["GetAccessControl"] = "getAccessControl";
    PathGetPropertiesAction["GetStatus"] = "getStatus";
})(exports.PathGetPropertiesAction || (exports.PathGetPropertiesAction = {}));
(function (PathRenameMode) {
    PathRenameMode["Legacy"] = "legacy";
    PathRenameMode["Posix"] = "posix";
})(exports.PathRenameMode || (exports.PathRenameMode = {}));
(function (PathResourceType) {
    PathResourceType["Directory"] = "directory";
    PathResourceType["File"] = "file";
})(exports.PathResourceType || (exports.PathResourceType = {}));
/** *********************************************************/
/** DataLakeLeaseClient option and response related models */
/** *********************************************************/

Object.defineProperty(exports, 'BaseRequestPolicy', {
    enumerable: true,
    get: function () {
        return coreHttp.BaseRequestPolicy;
    }
});
Object.defineProperty(exports, 'HttpHeaders', {
    enumerable: true,
    get: function () {
        return coreHttp.HttpHeaders;
    }
});
Object.defineProperty(exports, 'RequestPolicyOptions', {
    enumerable: true,
    get: function () {
        return coreHttp.RequestPolicyOptions;
    }
});
Object.defineProperty(exports, 'RestError', {
    enumerable: true,
    get: function () {
        return coreHttp.RestError;
    }
});
Object.defineProperty(exports, 'WebResource', {
    enumerable: true,
    get: function () {
        return coreHttp.WebResource;
    }
});
Object.defineProperty(exports, 'deserializationPolicy', {
    enumerable: true,
    get: function () {
        return coreHttp.deserializationPolicy;
    }
});
exports.AccountSASPermissions = AccountSASPermissions;
exports.AccountSASResourceTypes = AccountSASResourceTypes;
exports.AccountSASServices = AccountSASServices;
exports.AnonymousCredential = AnonymousCredential;
exports.AnonymousCredentialPolicy = AnonymousCredentialPolicy;
exports.Credential = Credential;
exports.CredentialPolicy = CredentialPolicy;
exports.DataLakeAclChangeFailedError = DataLakeAclChangeFailedError;
exports.DataLakeDirectoryClient = DataLakeDirectoryClient;
exports.DataLakeFileClient = DataLakeFileClient;
exports.DataLakeFileSystemClient = DataLakeFileSystemClient;
exports.DataLakeLeaseClient = DataLakeLeaseClient;
exports.DataLakePathClient = DataLakePathClient;
exports.DataLakeSASPermissions = DataLakeSASPermissions;
exports.DataLakeServiceClient = DataLakeServiceClient;
exports.DirectorySASPermissions = DirectorySASPermissions;
exports.FileSystemSASPermissions = FileSystemSASPermissions;
exports.Pipeline = Pipeline;
exports.SASQueryParameters = SASQueryParameters;
exports.StorageBrowserPolicy = StorageBrowserPolicy;
exports.StorageBrowserPolicyFactory = StorageBrowserPolicyFactory;
exports.StorageOAuthScopes = StorageOAuthScopes;
exports.StorageRetryPolicy = StorageRetryPolicy;
exports.StorageRetryPolicyFactory = StorageRetryPolicyFactory;
exports.StorageSharedKeyCredential = StorageSharedKeyCredential;
exports.StorageSharedKeyCredentialPolicy = StorageSharedKeyCredentialPolicy;
exports.ToBlobEndpointHostMappings = ToBlobEndpointHostMappings;
exports.ToDfsEndpointHostMappings = ToDfsEndpointHostMappings;
exports.generateAccountSASQueryParameters = generateAccountSASQueryParameters;
exports.generateDataLakeSASQueryParameters = generateDataLakeSASQueryParameters;
exports.logger = logger;
exports.newPipeline = newPipeline;
//# sourceMappingURL=index.js.map
